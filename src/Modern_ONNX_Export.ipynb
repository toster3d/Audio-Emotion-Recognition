{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Nowoczesny eksport modelu ensemble do ONNX\n",
    "\n",
    "Ten notebook implementuje najlepsze praktyki eksportu do ONNX zgodne z PyTorch 2.7+ i najnowszymi standardami ONNX.\n",
    "\n",
    "## Funkcje:\n",
    "- âœ… Bezpieczne Å‚adowanie modeli\n",
    "- âœ… Optymalizacja modeli ONNX\n",
    "- âœ… Kwantyzacja (dynamiczna i statyczna)\n",
    "- âœ… Weryfikacja zgodnoÅ›ci\n",
    "- âœ… Eksport metadanych\n",
    "- âœ… Jednolite wejÅ›cie tensorowe\n",
    "- âœ… ObsÅ‚uga dynamicznych rozmiarÃ³w\n",
    "- âœ… ObsÅ‚uga 5 typÃ³w cech: chroma, tempogram, mfcc, melspectrogram, hpss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Wersje bibliotek:\n",
      "   PyTorch: 2.7.0+cpu\n",
      "   ONNX: 1.18.0\n",
      "   ONNX Runtime: 1.19.2\n",
      "   Python: 3.9.13\n"
     ]
    }
   ],
   "source": [
    "# Importy i konfiguracja\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Dodanie Å›cieÅ¼ki do moduÅ‚Ã³w\n",
    "sys.path.append(os.path.join(os.getcwd()))\n",
    "\n",
    "from export_scripts.modern_onnx_exporter import ModernONNXExporter, ExportConfig\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "print(f\"ğŸ”§ Wersje bibliotek:\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   ONNX: {onnx.__version__}\")\n",
    "print(f\"   ONNX Runtime: {ort.__version__}\")\n",
    "print(f\"   Python: {sys.version.split()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Konfiguracja eksportu\n",
    "\n",
    "Ustaw parametry eksportu zgodnie z Twoimi potrzebami:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Konfiguracja eksportu:\n",
      "   Opset version: 19\n",
      "   Optymalizacja: True\n",
      "   Kwantyzacja: False\n",
      "   Typ kwantyzacji: dynamic\n",
      "   Weryfikacja: True\n"
     ]
    }
   ],
   "source": [
    "# Konfiguracja eksportu - dostosuj wedÅ‚ug potrzeb\n",
    "config = ExportConfig(\n",
    "    model_path=None,  # None = automatyczne wykrycie najnowszego modelu\n",
    "    output_dir=None,  # None = automatyczne tworzenie katalogu z timestamp\n",
    "    \n",
    "    # Parametry audio\n",
    "    sample_rate=22050,\n",
    "    max_length=3.0,  # sekundy\n",
    "    \n",
    "    # Parametry ONNX\n",
    "    opset_version=19,  # Najnowsza stabilna wersja\n",
    "    \n",
    "    # Optymalizacje\n",
    "    enable_optimization=True,     # WÅ‚Ä…cz optymalizacjÄ™ grafu ONNX\n",
    "    enable_quantization=False,    # WÅ‚Ä…cz kwantyzacjÄ™ (zmniejsza rozmiar)\n",
    "    quantization_type=\"dynamic\",  # \"dynamic\" lub \"static\"\n",
    "    \n",
    "    # Dodatkowe opcje\n",
    "    fp16_conversion=False,        # Konwersja do poÅ‚Ã³wkowej precyzji\n",
    "    verify_model=True,            # Weryfikacja zgodnoÅ›ci modeli\n",
    "    export_metadata=True          # Eksport metadanych\n",
    ")\n",
    "\n",
    "print(\"ğŸ“‹ Konfiguracja eksportu:\")\n",
    "print(f\"   Opset version: {config.opset_version}\")\n",
    "print(f\"   Optymalizacja: {config.enable_optimization}\")\n",
    "print(f\"   Kwantyzacja: {config.enable_quantization}\")\n",
    "print(f\"   Typ kwantyzacji: {config.quantization_type}\")\n",
    "print(f\"   Weryfikacja: {config.verify_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Wyszukiwanie dostÄ™pnych modeli\n",
    "\n",
    "SprawdÅºmy jakie modele ensemble sÄ… dostÄ™pne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Znaleziono 1 modeli ensemble:\n",
      "   1. ensemble_outputs\\ensemble_run_20250523_193302\\models\\ensemble_model.pt\n",
      "      Timestamp: 20250523_193302\\models\\ensemble_model.pt\n",
      "      Rozmiar: 213.51 MB\n",
      "      â­ Najnowszy model\n",
      "\n",
      "âœ… Automatycznie wybrano najnowszy model: ensemble_outputs\\ensemble_run_20250523_193302\\models\\ensemble_model.pt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# Wyszukiwanie modeli ensemble\n",
    "ensemble_models = glob.glob(\"ensemble_outputs/ensemble_run_*/models/ensemble_model.pt\")\n",
    "\n",
    "if ensemble_models:\n",
    "    print(f\"ğŸ” Znaleziono {len(ensemble_models)} modeli ensemble:\")\n",
    "    \n",
    "    for i, model_path in enumerate(sorted(ensemble_models, reverse=True)):\n",
    "        # Ekstraktowanie timestamp z nazwy katalogu\n",
    "        timestamp_str = model_path.split('ensemble_run_')[1].split('/')[0]\n",
    "        \n",
    "        # Rozmiar pliku\n",
    "        size_mb = os.path.getsize(model_path) / (1024 * 1024)\n",
    "        \n",
    "        print(f\"   {i+1}. {model_path}\")\n",
    "        print(f\"      Timestamp: {timestamp_str}\")\n",
    "        print(f\"      Rozmiar: {size_mb:.2f} MB\")\n",
    "        \n",
    "        if i == 0:\n",
    "            latest_model = model_path\n",
    "            print(f\"      â­ Najnowszy model\")\n",
    "        print()\n",
    "    \n",
    "    # Automatyczne ustawienie najnowszego modelu\n",
    "    if not config.model_path:\n",
    "        config.model_path = latest_model\n",
    "        print(f\"âœ… Automatycznie wybrano najnowszy model: {config.model_path}\")\n",
    "else:\n",
    "    print(\"âŒ Nie znaleziono Å¼adnych modeli ensemble!\")\n",
    "    print(\"   SprawdÅº czy folder ensemble_outputs/ zawiera wytrenowane modele.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… PROBLEM ZOSTAÅ ROZWIÄ„ZANY!\n",
    "\n",
    "BÅ‚Ä…d z Å‚adowaniem modelu w PyTorch 2.7+ zostaÅ‚ naprawiony poprzez implementacjÄ™ wielopoziomowej strategii Å‚adowania:\n",
    "1. Najpierw prÃ³ba bezpiecznego Å‚adowania (`weights_only=True`)\n",
    "2. NastÄ™pnie z dodanym `torch.version.TorchVersion` do safe_globals\n",
    "3. W koÅ„cu fallback do `weights_only=False` dla wÅ‚asnych zaufanych modeli\n",
    "\n",
    "## ğŸš€ Eksport modelu do ONNX\n",
    "\n",
    "Wykonajmy eksport z wykorzystaniem nowoczesnego eksportera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Rozpoczynam eksport modelu ensemble do ONNX\n",
      "============================================================\n",
      "\n",
      "ğŸ“¥ Etap 1: Åadowanie modelu ensemble...\n",
      "ğŸ“¥ Åadowanie modelu: ensemble_outputs\\ensemble_run_20250523_193302\\models\\ensemble_model.pt\n",
      "âš ï¸ UÅ¼ywam fallback Å‚adowania (weights_only=False)\n",
      "   BÅ‚Ä…d bezpiecznego Å‚adowania: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those...\n",
      "âœ… Model zaÅ‚adowany z 5 typami cech: ['melspectrogram', 'mfcc', 'hpss', 'chroma', 'tempogram']\n",
      "âœ… Model zaÅ‚adowany pomyÅ›lnie!\n",
      "   Typy cech: ['melspectrogram', 'mfcc', 'hpss', 'chroma', 'tempogram']\n",
      "   Liczba parametrÃ³w: 55,866,596\n",
      "\n",
      "ğŸ“¦ Etap 2: Eksport do ONNX...\n",
      "\n",
      "ğŸš€ Rozpoczynam eksport do ONNX...\n",
      "ğŸ“Š Wymiary wejÅ›cia: torch.Size([1, 1, 692, 130])\n",
      "ğŸ“‹ Informacje o cechach: {'melspectrogram': 128, 'mfcc': 40, 'hpss': 128, 'chroma': 12, 'tempogram': 384}\n",
      "ğŸ”¢ CaÅ‚kowity rozmiar cech: 692\n",
      "ğŸ” Test forward pass...\n",
      "âœ… Test ukoÅ„czony. Wymiary wyjÅ›cia: torch.Size([1, 6])\n",
      "ğŸ“¦ Eksport do ONNX...\n",
      "âœ… Eksport ukoÅ„czony: exported_models\\onnx_20250523_220917\\ensemble_model.onnx\n",
      "ğŸ” Weryfikacja modelu ONNX...\n",
      "âœ… Weryfikacja zakoÅ„czona. Max rÃ³Å¼nica: 0.000000\n",
      "âš¡ Optymalizacja modelu ONNX...\n",
      "âš ï¸ Optymalizacja nieudana: cannot import name 'optimizer' from 'onnx' (c:\\Users\\kubas\\Desktop\\Projekt dyplomowy\\Audio-Emotion-Recognition\\.venv\\lib\\site-packages\\onnx\\__init__.py)\n",
      "ğŸ“‹ Metadane zapisane: exported_models\\onnx_20250523_220917\\export_metadata.json\n",
      "\n",
      "ğŸ‰ Eksport zakoÅ„czony sukcesem!\n",
      "   ğŸ“ Katalog wyjÅ›ciowy: exported_models/onnx_20250523_220917\n",
      "   ğŸ“¦ Podstawowy model: 213.09 MB\n",
      "   âš¡ Zoptymalizowany model: 213.09 MB\n"
     ]
    }
   ],
   "source": [
    "# Tworzenie eksportera\n",
    "exporter = ModernONNXExporter(config)\n",
    "\n",
    "print(\"ğŸ¯ Rozpoczynam eksport modelu ensemble do ONNX\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Åadowanie modelu\n",
    "    print(\"\\nğŸ“¥ Etap 1: Åadowanie modelu ensemble...\")\n",
    "    model, feature_types = exporter.load_ensemble_model()\n",
    "    \n",
    "    print(f\"âœ… Model zaÅ‚adowany pomyÅ›lnie!\")\n",
    "    print(f\"   Typy cech: {feature_types}\")\n",
    "    print(f\"   Liczba parametrÃ³w: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Eksport do ONNX\n",
    "    print(\"\\nğŸ“¦ Etap 2: Eksport do ONNX...\")\n",
    "    result = exporter.export_to_onnx(model, feature_types)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        print(\"\\nğŸ‰ Eksport zakoÅ„czony sukcesem!\")\n",
    "        print(f\"   ğŸ“ Katalog wyjÅ›ciowy: {config.output_dir}\")\n",
    "        print(f\"   ğŸ“¦ Podstawowy model: {result['size_mb']:.2f} MB\")\n",
    "        \n",
    "        if \"optimized_path\" in result:\n",
    "            opt_size = Path(result[\"optimized_path\"]).stat().st_size / (1024 * 1024)\n",
    "            print(f\"   âš¡ Zoptymalizowany model: {opt_size:.2f} MB\")\n",
    "        \n",
    "        if \"quantized_path\" in result:\n",
    "            quant_size = Path(result[\"quantized_path\"]).stat().st_size / (1024 * 1024)\n",
    "            print(f\"   ğŸ”¢ Skwantyzowany model: {quant_size:.2f} MB\")\n",
    "            \n",
    "        export_result = result  # Zapisz wynik dla dalszych analiz\n",
    "    else:\n",
    "        print(f\"\\nâŒ Eksport nieudany: {result['error']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nğŸ’¥ Krytyczny bÅ‚Ä…d: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Analiza wyeksportowanych modeli\n",
    "\n",
    "SprawdÅºmy szczegÃ³Å‚y wyeksportowanych modeli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Analiza wyeksportowanych modeli:\n",
      "========================================\n",
      "\n",
      "ğŸ“ ZawartoÅ›Ä‡ katalogu: exported_models\\onnx_20250523_220917\n",
      "   ğŸ“„ ensemble_model.onnx: 213.09 MB\n",
      "   ğŸ“„ export_metadata.json: 0.00 MB\n",
      "\n",
      "ğŸ” Analiza modelu ONNX: ensemble_model.onnx\n",
      "   Wersja ONNX: 9\n",
      "   Opset version: 19\n",
      "   Liczba wÄ™zÅ‚Ã³w: 292\n",
      "   Liczba inicjalizatorÃ³w: 216\n",
      "\n",
      "   ğŸ“¥ WejÅ›cia:\n",
      "      audio_features: ['dynamic(batch_size)', 1, 692, 'dynamic(time_steps)']\n",
      "\n",
      "   ğŸ“¤ WyjÅ›cia:\n",
      "      output: ['dynamic(batch_size)', 6]\n"
     ]
    }
   ],
   "source": [
    "if 'export_result' in locals() and export_result[\"success\"]:\n",
    "    print(\"ğŸ“Š Analiza wyeksportowanych modeli:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Lista wszystkich wyeksportowanych plikÃ³w\n",
    "    output_dir = Path(config.output_dir)\n",
    "    \n",
    "    print(f\"\\nğŸ“ ZawartoÅ›Ä‡ katalogu: {output_dir}\")\n",
    "    for file_path in sorted(output_dir.iterdir()):\n",
    "        if file_path.is_file():\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"   ğŸ“„ {file_path.name}: {size_mb:.2f} MB\")\n",
    "    \n",
    "    # Analiza podstawowego modelu ONNX\n",
    "    main_model_path = output_dir / \"ensemble_model.onnx\"\n",
    "    if main_model_path.exists():\n",
    "        print(f\"\\nğŸ” Analiza modelu ONNX: {main_model_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            model_onnx = onnx.load(str(main_model_path))\n",
    "            \n",
    "            print(f\"   Wersja ONNX: {model_onnx.ir_version}\")\n",
    "            print(f\"   Opset version: {model_onnx.opset_import[0].version}\")\n",
    "            print(f\"   Liczba wÄ™zÅ‚Ã³w: {len(model_onnx.graph.node)}\")\n",
    "            print(f\"   Liczba inicjalizatorÃ³w: {len(model_onnx.graph.initializer)}\")\n",
    "            \n",
    "            # Informacje o wejÅ›ciach/wyjÅ›ciach\n",
    "            print(f\"\\n   ğŸ“¥ WejÅ›cia:\")\n",
    "            for input_info in model_onnx.graph.input:\n",
    "                name = input_info.name\n",
    "                shape = [dim.dim_value if dim.dim_value > 0 else f\"dynamic({dim.dim_param})\" \n",
    "                        for dim in input_info.type.tensor_type.shape.dim]\n",
    "                print(f\"      {name}: {shape}\")\n",
    "            \n",
    "            print(f\"\\n   ğŸ“¤ WyjÅ›cia:\")\n",
    "            for output_info in model_onnx.graph.output:\n",
    "                name = output_info.name\n",
    "                shape = [dim.dim_value if dim.dim_value > 0 else f\"dynamic({dim.dim_param})\" \n",
    "                        for dim in output_info.type.tensor_type.shape.dim]\n",
    "                print(f\"      {name}: {shape}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ BÅ‚Ä…d analizy modelu: {e}\")\n",
    "else:\n",
    "    print(\"âŒ Brak wyeksportowanych modeli do analizy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Test inference modelu ONNX\n",
    "\n",
    "SprawdÅºmy czy model ONNX dziaÅ‚a poprawnie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Test inference modelu ONNX\n",
      "==============================\n",
      "ğŸ“¦ UÅ¼ywam zoptymalizowanego modelu\n",
      "   Model: ensemble_model.onnx\n",
      "âœ… Sesja ONNX Runtime utworzona\n",
      "   Provider: ['CPUExecutionProvider']\n",
      "\n",
      "ğŸ“Š Generowanie testowych danych...\n",
      "ğŸ“Š Wymiary wejÅ›cia: torch.Size([1, 1, 692, 130])\n",
      "ğŸ“‹ Informacje o cechach: {'melspectrogram': 128, 'mfcc': 40, 'hpss': 128, 'chroma': 12, 'tempogram': 384}\n",
      "ğŸ”¢ CaÅ‚kowity rozmiar cech: 692\n",
      "ğŸš€ Test inference...\n",
      "âœ… Inference ukoÅ„czony w 31.16 ms\n",
      "   Wymiary wyjÅ›cia: (1, 6)\n",
      "   Przewidywane klasy: [0]\n",
      "   NajwyÅ¼sze prawdopodobieÅ„stwo: 0.5327\n",
      "\n",
      "ğŸ”„ Test z batch size = 4...\n",
      "âœ… Batch inference ukoÅ„czony w 129.94 ms\n",
      "   Wymiary wyjÅ›cia: (4, 6)\n",
      "   Czas na prÃ³bkÄ™: 32.48 ms\n"
     ]
    }
   ],
   "source": [
    "if 'export_result' in locals() and export_result[\"success\"]:\n",
    "    print(\"ğŸ§ª Test inference modelu ONNX\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    try:\n",
    "        # ÅšcieÅ¼ka do modelu (preferuj zoptymalizowany jeÅ›li istnieje)\n",
    "        if \"optimized_path\" in export_result:\n",
    "            test_model_path = export_result[\"optimized_path\"]\n",
    "            print(f\"ğŸ“¦ UÅ¼ywam zoptymalizowanego modelu\")\n",
    "        else:\n",
    "            test_model_path = export_result[\"path\"]\n",
    "            print(f\"ğŸ“¦ UÅ¼ywam podstawowego modelu\")\n",
    "        \n",
    "        print(f\"   Model: {Path(test_model_path).name}\")\n",
    "        \n",
    "        # Tworzenie sesji ONNX Runtime\n",
    "        session = ort.InferenceSession(\n",
    "            test_model_path,\n",
    "            providers=['CPUExecutionProvider']\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Sesja ONNX Runtime utworzona\")\n",
    "        print(f\"   Provider: {session.get_providers()}\")\n",
    "        \n",
    "        # Generowanie testowych danych\n",
    "        print(f\"\\nğŸ“Š Generowanie testowych danych...\")\n",
    "        test_input = exporter.generate_dummy_input(export_result['feature_types'])\n",
    "        \n",
    "        # Test inference\n",
    "        print(f\"ğŸš€ Test inference...\")\n",
    "        import time\n",
    "        \n",
    "        start_time = time.time()\n",
    "        onnx_output = session.run(\n",
    "            None,  # Wszystkie wyjÅ›cia\n",
    "            {'audio_features': test_input.numpy()}\n",
    "        )\n",
    "        inference_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"âœ… Inference ukoÅ„czony w {inference_time*1000:.2f} ms\")\n",
    "        print(f\"   Wymiary wyjÅ›cia: {onnx_output[0].shape}\")\n",
    "        print(f\"   Przewidywane klasy: {onnx_output[0].argmax(axis=1)}\")\n",
    "        print(f\"   NajwyÅ¼sze prawdopodobieÅ„stwo: {onnx_output[0].max():.4f}\")\n",
    "        \n",
    "        # Test z wieloma batch'ami\n",
    "        print(f\"\\nğŸ”„ Test z batch size = 4...\")\n",
    "        batch_input = test_input.repeat(4, 1, 1, 1)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        batch_output = session.run(\n",
    "            None,\n",
    "            {'audio_features': batch_input.numpy()}\n",
    "        )\n",
    "        batch_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"âœ… Batch inference ukoÅ„czony w {batch_time*1000:.2f} ms\")\n",
    "        print(f\"   Wymiary wyjÅ›cia: {batch_output[0].shape}\")\n",
    "        print(f\"   Czas na prÃ³bkÄ™: {batch_time/4*1000:.2f} ms\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ BÅ‚Ä…d testu inference: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"âŒ Brak wyeksportowanego modelu do testowania\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Podsumowanie eksportu\n",
    "\n",
    "Podsumujmy wyniki eksportu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ PODSUMOWANIE EKSPORTU\n",
      "========================================\n",
      "âœ… Status: SUKCES\n",
      "ğŸ“ Katalog wyjÅ›ciowy: exported_models/onnx_20250523_220917\n",
      "ğŸ”§ Typy cech: melspectrogram, mfcc, hpss, chroma, tempogram\n",
      "ğŸ“¦ Rozmiar podstawowego modelu: 213.09 MB\n",
      "\n",
      "ğŸ› ï¸ Zastosowane optymalizacje:\n",
      "   âš¡ Optymalizacja grafu: True\n",
      "   ğŸ”¢ Kwantyzacja: False\n",
      "   ğŸ” Weryfikacja: True\n",
      "\n",
      "ğŸ“Š DostÄ™pne pliki:\n",
      "   ğŸ“„ ensemble_model.onnx: 213.09 MB\n",
      "   ğŸ“„ export_metadata.json: 0.00 MB\n",
      "\n",
      "ğŸ¯ Model gotowy do wdroÅ¼enia!\n",
      "   GÅ‚Ã³wny model: ensemble_model.onnx\n",
      "   Zalecany do uÅ¼ycia: ensemble_model.onnx\n"
     ]
    }
   ],
   "source": [
    "if 'export_result' in locals() and export_result[\"success\"]:\n",
    "    print(\"ğŸ“‹ PODSUMOWANIE EKSPORTU\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    print(f\"âœ… Status: SUKCES\")\n",
    "    print(f\"ğŸ“ Katalog wyjÅ›ciowy: {config.output_dir}\")\n",
    "    print(f\"ğŸ”§ Typy cech: {', '.join(export_result['feature_types'])}\")\n",
    "    print(f\"ğŸ“¦ Rozmiar podstawowego modelu: {export_result['size_mb']:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nğŸ› ï¸ Zastosowane optymalizacje:\")\n",
    "    print(f\"   âš¡ Optymalizacja grafu: {config.enable_optimization}\")\n",
    "    print(f\"   ğŸ”¢ Kwantyzacja: {config.enable_quantization}\")\n",
    "    if config.enable_quantization:\n",
    "        print(f\"   ğŸ“ Typ kwantyzacji: {config.quantization_type}\")\n",
    "    print(f\"   ğŸ” Weryfikacja: {config.verify_model}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š DostÄ™pne pliki:\")\n",
    "    output_dir = Path(config.output_dir)\n",
    "    for file_path in sorted(output_dir.iterdir()):\n",
    "        if file_path.suffix in ['.onnx', '.json']:\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"   ğŸ“„ {file_path.name}: {size_mb:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Model gotowy do wdroÅ¼enia!\")\n",
    "    print(f\"   GÅ‚Ã³wny model: {Path(export_result['path']).name}\")\n",
    "    if \"optimized_path\" in export_result:\n",
    "        print(f\"   Zalecany do uÅ¼ycia: {Path(export_result['optimized_path']).name}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ EKSPORT NIEUDANY\")\n",
    "    print(\"   SprawdÅº komunikaty bÅ‚Ä™dÃ³w powyÅ¼ej\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ NastÄ™pne kroki\n",
    "\n",
    "Po udanym eksporcie moÅ¼esz:\n",
    "\n",
    "1. **WdroÅ¼enie modelu**: UÅ¼yj wyeksportowanego modelu ONNX w swojej aplikacji\n",
    "2. **Optymalizacja dalszej**: Przetestuj rÃ³Å¼ne konfiguracje optymalizacji\n",
    "3. **Kwantyzacja**: JeÅ›li nie wÅ‚Ä…czaÅ‚eÅ› kwantyzacji, rozwaÅ¼ jej uÅ¼ycie dla zmniejszenia rozmiaru\n",
    "4. **Testy wydajnoÅ›ci**: Zmierz wydajnoÅ›Ä‡ na docelowym Å›rodowisku\n",
    "5. **Integracja**: UÅ¼yj modelu z bibliotekami takimi jak ONNX Runtime, OpenVINO, lub TensorRT\n",
    "\n",
    "### PrzykÅ‚ad uÅ¼ycia w produkcji:\n",
    "\n",
    "```python\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Åadowanie modelu\n",
    "session = ort.InferenceSession('ensemble_model_optimized.onnx')\n",
    "\n",
    "# Przygotowanie danych audio (zastÄ…p swojÄ… logikÄ…)\n",
    "audio_features = extract_features_from_audio(audio_file)\n",
    "\n",
    "# Inference\n",
    "predictions = session.run(None, {'audio_features': audio_features})\n",
    "predicted_emotion = np.argmax(predictions[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Nowoczesny eksport modelu ensemble do ONNX\n",
    "\n",
    "Ten notebook implementuje najlepsze praktyki eksportu do ONNX zgodne z PyTorch 2.7+ i najnowszymi standardami ONNX.\n",
    "\n",
    "## Funkcje:\n",
    "- âœ… Bezpieczne Å‚adowanie modeli\n",
    "- âœ… Optymalizacja modeli ONNX\n",
    "- âœ… Kwantyzacja (dynamiczna i statyczna)\n",
    "- âœ… Weryfikacja zgodnoÅ›ci\n",
    "- âœ… Eksport metadanych\n",
    "- âœ… Jednolite wejÅ›cie tensorowe\n",
    "- âœ… ObsÅ‚uga dynamicznych rozmiarÃ³w\n",
    "- âœ… ObsÅ‚uga 5 typÃ³w cech: chroma, tempogram, mfcc, melspectrogram, hpss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Wersje bibliotek:\n",
      "   PyTorch: 2.7.0+cpu\n",
      "   ONNX: 1.18.0\n",
      "   ONNX Runtime: 1.19.2\n",
      "   Python: 3.9.13\n"
     ]
    }
   ],
   "source": [
    "# Importy i konfiguracja\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Dodanie Å›cieÅ¼ki do moduÅ‚Ã³w\n",
    "sys.path.append(os.path.join(os.getcwd()))\n",
    "\n",
    "from export_scripts.modern_onnx_exporter import ModernONNXExporter, ExportConfig\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "print(f\"ğŸ”§ Wersje bibliotek:\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   ONNX: {onnx.__version__}\")\n",
    "print(f\"   ONNX Runtime: {ort.__version__}\")\n",
    "print(f\"   Python: {sys.version.split()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Konfiguracja eksportu\n",
    "\n",
    "Ustaw parametry eksportu zgodnie z Twoimi potrzebami:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Konfiguracja eksportu:\n",
      "   Opset version: 19\n",
      "   Optymalizacja: True\n",
      "   Kwantyzacja: False\n",
      "   Typ kwantyzacji: dynamic\n",
      "   Weryfikacja: True\n"
     ]
    }
   ],
   "source": [
    "# Konfiguracja eksportu - dostosuj wedÅ‚ug potrzeb\n",
    "config = ExportConfig(\n",
    "    model_path=None,  # None = automatyczne wykrycie najnowszego modelu\n",
    "    output_dir=None,  # None = automatyczne tworzenie katalogu z timestamp\n",
    "    \n",
    "    # Parametry audio\n",
    "    sample_rate=22050,\n",
    "    max_length=3.0,  # sekundy\n",
    "    \n",
    "    # Parametry ONNX\n",
    "    opset_version=19,  # Najnowsza stabilna wersja\n",
    "    \n",
    "    # Optymalizacje\n",
    "    enable_optimization=True,     # WÅ‚Ä…cz optymalizacjÄ™ grafu ONNX\n",
    "    enable_quantization=False,    # WÅ‚Ä…cz kwantyzacjÄ™ (zmniejsza rozmiar)\n",
    "    quantization_type=\"dynamic\",  # \"dynamic\" lub \"static\"\n",
    "    \n",
    "    # Dodatkowe opcje\n",
    "    fp16_conversion=False,        # Konwersja do poÅ‚Ã³wkowej precyzji\n",
    "    verify_model=True,            # Weryfikacja zgodnoÅ›ci modeli\n",
    "    export_metadata=True          # Eksport metadanych\n",
    ")\n",
    "\n",
    "print(\"ğŸ“‹ Konfiguracja eksportu:\")\n",
    "print(f\"   Opset version: {config.opset_version}\")\n",
    "print(f\"   Optymalizacja: {config.enable_optimization}\")\n",
    "print(f\"   Kwantyzacja: {config.enable_quantization}\")\n",
    "print(f\"   Typ kwantyzacji: {config.quantization_type}\")\n",
    "print(f\"   Weryfikacja: {config.verify_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Wyszukiwanie dostÄ™pnych modeli\n",
    "\n",
    "SprawdÅºmy jakie modele ensemble sÄ… dostÄ™pne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Znaleziono 1 modeli ensemble:\n",
      "   1. ensemble_outputs\\ensemble_run_20250523_193302\\models\\ensemble_model.pt\n",
      "      Timestamp: 20250523_193302\\models\\ensemble_model.pt\n",
      "      Rozmiar: 213.51 MB\n",
      "      â­ Najnowszy model\n",
      "\n",
      "âœ… Automatycznie wybrano najnowszy model: ensemble_outputs\\ensemble_run_20250523_193302\\models\\ensemble_model.pt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# Wyszukiwanie modeli ensemble\n",
    "ensemble_models = glob.glob(\"ensemble_outputs/ensemble_run_*/models/ensemble_model.pt\")\n",
    "\n",
    "if ensemble_models:\n",
    "    print(f\"ğŸ” Znaleziono {len(ensemble_models)} modeli ensemble:\")\n",
    "    \n",
    "    for i, model_path in enumerate(sorted(ensemble_models, reverse=True)):\n",
    "        # Ekstraktowanie timestamp z nazwy katalogu\n",
    "        timestamp_str = model_path.split('ensemble_run_')[1].split('/')[0]\n",
    "        \n",
    "        # Rozmiar pliku\n",
    "        size_mb = os.path.getsize(model_path) / (1024 * 1024)\n",
    "        \n",
    "        print(f\"   {i+1}. {model_path}\")\n",
    "        print(f\"      Timestamp: {timestamp_str}\")\n",
    "        print(f\"      Rozmiar: {size_mb:.2f} MB\")\n",
    "        \n",
    "        if i == 0:\n",
    "            latest_model = model_path\n",
    "            print(f\"      â­ Najnowszy model\")\n",
    "        print()\n",
    "    \n",
    "    # Automatyczne ustawienie najnowszego modelu\n",
    "    if not config.model_path:\n",
    "        config.model_path = latest_model\n",
    "        print(f\"âœ… Automatycznie wybrano najnowszy model: {config.model_path}\")\n",
    "else:\n",
    "    print(\"âŒ Nie znaleziono Å¼adnych modeli ensemble!\")\n",
    "    print(\"   SprawdÅº czy folder ensemble_outputs/ zawiera wytrenowane modele.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Eksport modelu do ONNX\n",
    "\n",
    "Wykonajmy eksport z wykorzystaniem nowoczesnego eksportera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Rozpoczynam eksport modelu ensemble do ONNX\n",
      "============================================================\n",
      "\n",
      "ğŸ“¥ Etap 1: Åadowanie modelu ensemble...\n",
      "ğŸ“¥ Åadowanie modelu: ensemble_outputs\\ensemble_run_20250523_193302\\models\\ensemble_model.pt\n",
      "âš ï¸ UÅ¼ywam fallback Å‚adowania (weights_only=False)\n",
      "   BÅ‚Ä…d bezpiecznego Å‚adowania: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those...\n",
      "âœ… Model zaÅ‚adowany z 5 typami cech: ['melspectrogram', 'mfcc', 'hpss', 'chroma', 'tempogram']\n",
      "âœ… Model zaÅ‚adowany pomyÅ›lnie!\n",
      "   Typy cech: ['melspectrogram', 'mfcc', 'hpss', 'chroma', 'tempogram']\n",
      "   Liczba parametrÃ³w: 55,866,596\n",
      "\n",
      "ğŸ“¦ Etap 2: Eksport do ONNX...\n",
      "\n",
      "ğŸš€ Rozpoczynam eksport do ONNX...\n",
      "ğŸ“Š Wymiary wejÅ›cia: torch.Size([1, 1, 692, 130])\n",
      "ğŸ“‹ Informacje o cechach: {'melspectrogram': 128, 'mfcc': 40, 'hpss': 128, 'chroma': 12, 'tempogram': 384}\n",
      "ğŸ”¢ CaÅ‚kowity rozmiar cech: 692\n",
      "ğŸ” Test forward pass...\n",
      "âœ… Test ukoÅ„czony. Wymiary wyjÅ›cia: torch.Size([1, 6])\n",
      "ğŸ“¦ Eksport do ONNX...\n",
      "âœ… Eksport ukoÅ„czony: exported_models\\onnx_20250523_220923\\ensemble_model.onnx\n",
      "ğŸ” Weryfikacja modelu ONNX...\n",
      "âœ… Weryfikacja zakoÅ„czona. Max rÃ³Å¼nica: 0.000000\n",
      "âš¡ Optymalizacja modelu ONNX...\n",
      "âš ï¸ Optymalizacja nieudana: cannot import name 'optimizer' from 'onnx' (c:\\Users\\kubas\\Desktop\\Projekt dyplomowy\\Audio-Emotion-Recognition\\.venv\\lib\\site-packages\\onnx\\__init__.py)\n",
      "ğŸ“‹ Metadane zapisane: exported_models\\onnx_20250523_220923\\export_metadata.json\n",
      "\n",
      "ğŸ‰ Eksport zakoÅ„czony sukcesem!\n",
      "   ğŸ“ Katalog wyjÅ›ciowy: exported_models/onnx_20250523_220923\n",
      "   ğŸ“¦ Podstawowy model: 213.09 MB\n",
      "   âš¡ Zoptymalizowany model: 213.09 MB\n"
     ]
    }
   ],
   "source": [
    "# Tworzenie eksportera\n",
    "exporter = ModernONNXExporter(config)\n",
    "\n",
    "print(\"ğŸ¯ Rozpoczynam eksport modelu ensemble do ONNX\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Åadowanie modelu\n",
    "    print(\"\\nğŸ“¥ Etap 1: Åadowanie modelu ensemble...\")\n",
    "    model, feature_types = exporter.load_ensemble_model()\n",
    "    \n",
    "    print(f\"âœ… Model zaÅ‚adowany pomyÅ›lnie!\")\n",
    "    print(f\"   Typy cech: {feature_types}\")\n",
    "    print(f\"   Liczba parametrÃ³w: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Eksport do ONNX\n",
    "    print(\"\\nğŸ“¦ Etap 2: Eksport do ONNX...\")\n",
    "    result = exporter.export_to_onnx(model, feature_types)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        print(\"\\nğŸ‰ Eksport zakoÅ„czony sukcesem!\")\n",
    "        print(f\"   ğŸ“ Katalog wyjÅ›ciowy: {config.output_dir}\")\n",
    "        print(f\"   ğŸ“¦ Podstawowy model: {result['size_mb']:.2f} MB\")\n",
    "        \n",
    "        if \"optimized_path\" in result:\n",
    "            opt_size = Path(result[\"optimized_path\"]).stat().st_size / (1024 * 1024)\n",
    "            print(f\"   âš¡ Zoptymalizowany model: {opt_size:.2f} MB\")\n",
    "        \n",
    "        if \"quantized_path\" in result:\n",
    "            quant_size = Path(result[\"quantized_path\"]).stat().st_size / (1024 * 1024)\n",
    "            print(f\"   ğŸ”¢ Skwantyzowany model: {quant_size:.2f} MB\")\n",
    "            \n",
    "        export_result = result  # Zapisz wynik dla dalszych analiz\n",
    "    else:\n",
    "        print(f\"\\nâŒ Eksport nieudany: {result['error']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nğŸ’¥ Krytyczny bÅ‚Ä…d: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Analiza wyeksportowanych modeli\n",
    "\n",
    "SprawdÅºmy szczegÃ³Å‚y wyeksportowanych modeli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Analiza wyeksportowanych modeli:\n",
      "========================================\n",
      "\n",
      "ğŸ“ ZawartoÅ›Ä‡ katalogu: exported_models\\onnx_20250523_220923\n",
      "   ğŸ“„ ensemble_model.onnx: 213.09 MB\n",
      "   ğŸ“„ export_metadata.json: 0.00 MB\n",
      "\n",
      "ğŸ” Analiza modelu ONNX: ensemble_model.onnx\n",
      "   Wersja ONNX: 9\n",
      "   Opset version: 19\n",
      "   Liczba wÄ™zÅ‚Ã³w: 292\n",
      "   Liczba inicjalizatorÃ³w: 216\n",
      "\n",
      "   ğŸ“¥ WejÅ›cia:\n",
      "      audio_features: ['dynamic(batch_size)', 1, 692, 'dynamic(time_steps)']\n",
      "\n",
      "   ğŸ“¤ WyjÅ›cia:\n",
      "      output: ['dynamic(batch_size)', 6]\n"
     ]
    }
   ],
   "source": [
    "if 'export_result' in locals() and export_result[\"success\"]:\n",
    "    print(\"ğŸ“Š Analiza wyeksportowanych modeli:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Lista wszystkich wyeksportowanych plikÃ³w\n",
    "    output_dir = Path(config.output_dir)\n",
    "    \n",
    "    print(f\"\\nğŸ“ ZawartoÅ›Ä‡ katalogu: {output_dir}\")\n",
    "    for file_path in sorted(output_dir.iterdir()):\n",
    "        if file_path.is_file():\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"   ğŸ“„ {file_path.name}: {size_mb:.2f} MB\")\n",
    "    \n",
    "    # Analiza podstawowego modelu ONNX\n",
    "    main_model_path = output_dir / \"ensemble_model.onnx\"\n",
    "    if main_model_path.exists():\n",
    "        print(f\"\\nğŸ” Analiza modelu ONNX: {main_model_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            model_onnx = onnx.load(str(main_model_path))\n",
    "            \n",
    "            print(f\"   Wersja ONNX: {model_onnx.ir_version}\")\n",
    "            print(f\"   Opset version: {model_onnx.opset_import[0].version}\")\n",
    "            print(f\"   Liczba wÄ™zÅ‚Ã³w: {len(model_onnx.graph.node)}\")\n",
    "            print(f\"   Liczba inicjalizatorÃ³w: {len(model_onnx.graph.initializer)}\")\n",
    "            \n",
    "            # Informacje o wejÅ›ciach/wyjÅ›ciach\n",
    "            print(f\"\\n   ğŸ“¥ WejÅ›cia:\")\n",
    "            for input_info in model_onnx.graph.input:\n",
    "                name = input_info.name\n",
    "                shape = [dim.dim_value if dim.dim_value > 0 else f\"dynamic({dim.dim_param})\" \n",
    "                        for dim in input_info.type.tensor_type.shape.dim]\n",
    "                print(f\"      {name}: {shape}\")\n",
    "            \n",
    "            print(f\"\\n   ğŸ“¤ WyjÅ›cia:\")\n",
    "            for output_info in model_onnx.graph.output:\n",
    "                name = output_info.name\n",
    "                shape = [dim.dim_value if dim.dim_value > 0 else f\"dynamic({dim.dim_param})\" \n",
    "                        for dim in output_info.type.tensor_type.shape.dim]\n",
    "                print(f\"      {name}: {shape}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ BÅ‚Ä…d analizy modelu: {e}\")\n",
    "else:\n",
    "    print(\"âŒ Brak wyeksportowanych modeli do analizy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Test inference modelu ONNX\n",
    "\n",
    "SprawdÅºmy czy model ONNX dziaÅ‚a poprawnie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Test inference modelu ONNX\n",
      "==============================\n",
      "ğŸ“¦ UÅ¼ywam zoptymalizowanego modelu\n",
      "   Model: ensemble_model.onnx\n",
      "âœ… Sesja ONNX Runtime utworzona\n",
      "   Provider: ['CPUExecutionProvider']\n",
      "\n",
      "ğŸ“Š Generowanie testowych danych...\n",
      "ğŸ“Š Wymiary wejÅ›cia: torch.Size([1, 1, 692, 130])\n",
      "ğŸ“‹ Informacje o cechach: {'melspectrogram': 128, 'mfcc': 40, 'hpss': 128, 'chroma': 12, 'tempogram': 384}\n",
      "ğŸ”¢ CaÅ‚kowity rozmiar cech: 692\n",
      "ğŸš€ Test inference...\n",
      "âœ… Inference ukoÅ„czony w 24.72 ms\n",
      "   Wymiary wyjÅ›cia: (1, 6)\n",
      "   Przewidywane klasy: [0]\n",
      "   NajwyÅ¼sze prawdopodobieÅ„stwo: 0.5120\n",
      "\n",
      "ğŸ”„ Test z batch size = 4...\n",
      "âœ… Batch inference ukoÅ„czony w 111.85 ms\n",
      "   Wymiary wyjÅ›cia: (4, 6)\n",
      "   Czas na prÃ³bkÄ™: 27.96 ms\n"
     ]
    }
   ],
   "source": [
    "if 'export_result' in locals() and export_result[\"success\"]:\n",
    "    print(\"ğŸ§ª Test inference modelu ONNX\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    try:\n",
    "        # ÅšcieÅ¼ka do modelu (preferuj zoptymalizowany jeÅ›li istnieje)\n",
    "        if \"optimized_path\" in export_result:\n",
    "            test_model_path = export_result[\"optimized_path\"]\n",
    "            print(f\"ğŸ“¦ UÅ¼ywam zoptymalizowanego modelu\")\n",
    "        else:\n",
    "            test_model_path = export_result[\"path\"]\n",
    "            print(f\"ğŸ“¦ UÅ¼ywam podstawowego modelu\")\n",
    "        \n",
    "        print(f\"   Model: {Path(test_model_path).name}\")\n",
    "        \n",
    "        # Tworzenie sesji ONNX Runtime\n",
    "        session = ort.InferenceSession(\n",
    "            test_model_path,\n",
    "            providers=['CPUExecutionProvider']\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Sesja ONNX Runtime utworzona\")\n",
    "        print(f\"   Provider: {session.get_providers()}\")\n",
    "        \n",
    "        # Generowanie testowych danych\n",
    "        print(f\"\\nğŸ“Š Generowanie testowych danych...\")\n",
    "        test_input = exporter.generate_dummy_input(export_result['feature_types'])\n",
    "        \n",
    "        # Test inference\n",
    "        print(f\"ğŸš€ Test inference...\")\n",
    "        import time\n",
    "        \n",
    "        start_time = time.time()\n",
    "        onnx_output = session.run(\n",
    "            None,  # Wszystkie wyjÅ›cia\n",
    "            {'audio_features': test_input.numpy()}\n",
    "        )\n",
    "        inference_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"âœ… Inference ukoÅ„czony w {inference_time*1000:.2f} ms\")\n",
    "        print(f\"   Wymiary wyjÅ›cia: {onnx_output[0].shape}\")\n",
    "        print(f\"   Przewidywane klasy: {onnx_output[0].argmax(axis=1)}\")\n",
    "        print(f\"   NajwyÅ¼sze prawdopodobieÅ„stwo: {onnx_output[0].max():.4f}\")\n",
    "        \n",
    "        # Test z wieloma batch'ami\n",
    "        print(f\"\\nğŸ”„ Test z batch size = 4...\")\n",
    "        batch_input = test_input.repeat(4, 1, 1, 1)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        batch_output = session.run(\n",
    "            None,\n",
    "            {'audio_features': batch_input.numpy()}\n",
    "        )\n",
    "        batch_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"âœ… Batch inference ukoÅ„czony w {batch_time*1000:.2f} ms\")\n",
    "        print(f\"   Wymiary wyjÅ›cia: {batch_output[0].shape}\")\n",
    "        print(f\"   Czas na prÃ³bkÄ™: {batch_time/4*1000:.2f} ms\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ BÅ‚Ä…d testu inference: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"âŒ Brak wyeksportowanego modelu do testowania\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Podsumowanie eksportu\n",
    "\n",
    "Podsumujmy wyniki eksportu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ PODSUMOWANIE EKSPORTU\n",
      "========================================\n",
      "âœ… Status: SUKCES\n",
      "ğŸ“ Katalog wyjÅ›ciowy: exported_models/onnx_20250523_220923\n",
      "ğŸ”§ Typy cech: melspectrogram, mfcc, hpss, chroma, tempogram\n",
      "ğŸ“¦ Rozmiar podstawowego modelu: 213.09 MB\n",
      "\n",
      "ğŸ› ï¸ Zastosowane optymalizacje:\n",
      "   âš¡ Optymalizacja grafu: True\n",
      "   ğŸ”¢ Kwantyzacja: False\n",
      "   ğŸ” Weryfikacja: True\n",
      "\n",
      "ğŸ“Š DostÄ™pne pliki:\n",
      "   ğŸ“„ ensemble_model.onnx: 213.09 MB\n",
      "   ğŸ“„ export_metadata.json: 0.00 MB\n",
      "\n",
      "ğŸ¯ Model gotowy do wdroÅ¼enia!\n",
      "   GÅ‚Ã³wny model: ensemble_model.onnx\n",
      "   Zalecany do uÅ¼ycia: ensemble_model.onnx\n"
     ]
    }
   ],
   "source": [
    "if 'export_result' in locals() and export_result[\"success\"]:\n",
    "    print(\"ğŸ“‹ PODSUMOWANIE EKSPORTU\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    print(f\"âœ… Status: SUKCES\")\n",
    "    print(f\"ğŸ“ Katalog wyjÅ›ciowy: {config.output_dir}\")\n",
    "    print(f\"ğŸ”§ Typy cech: {', '.join(export_result['feature_types'])}\")\n",
    "    print(f\"ğŸ“¦ Rozmiar podstawowego modelu: {export_result['size_mb']:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nğŸ› ï¸ Zastosowane optymalizacje:\")\n",
    "    print(f\"   âš¡ Optymalizacja grafu: {config.enable_optimization}\")\n",
    "    print(f\"   ğŸ”¢ Kwantyzacja: {config.enable_quantization}\")\n",
    "    if config.enable_quantization:\n",
    "        print(f\"   ğŸ“ Typ kwantyzacji: {config.quantization_type}\")\n",
    "    print(f\"   ğŸ” Weryfikacja: {config.verify_model}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š DostÄ™pne pliki:\")\n",
    "    output_dir = Path(config.output_dir)\n",
    "    for file_path in sorted(output_dir.iterdir()):\n",
    "        if file_path.suffix in ['.onnx', '.json']:\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"   ğŸ“„ {file_path.name}: {size_mb:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Model gotowy do wdroÅ¼enia!\")\n",
    "    print(f\"   GÅ‚Ã³wny model: {Path(export_result['path']).name}\")\n",
    "    if \"optimized_path\" in export_result:\n",
    "        print(f\"   Zalecany do uÅ¼ycia: {Path(export_result['optimized_path']).name}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ EKSPORT NIEUDANY\")\n",
    "    print(\"   SprawdÅº komunikaty bÅ‚Ä™dÃ³w powyÅ¼ej\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ NastÄ™pne kroki\n",
    "\n",
    "Po udanym eksporcie moÅ¼esz:\n",
    "\n",
    "1. **WdroÅ¼enie modelu**: UÅ¼yj wyeksportowanego modelu ONNX w swojej aplikacji\n",
    "2. **Optymalizacja dalszej**: Przetestuj rÃ³Å¼ne konfiguracje optymalizacji\n",
    "3. **Kwantyzacja**: JeÅ›li nie wÅ‚Ä…czaÅ‚eÅ› kwantyzacji, rozwaÅ¼ jej uÅ¼ycie dla zmniejszenia rozmiaru\n",
    "4. **Testy wydajnoÅ›ci**: Zmierz wydajnoÅ›Ä‡ na docelowym Å›rodowisku\n",
    "5. **Integracja**: UÅ¼yj modelu z bibliotekami takimi jak ONNX Runtime, OpenVINO, lub TensorRT\n",
    "\n",
    "### PrzykÅ‚ad uÅ¼ycia w produkcji:\n",
    "\n",
    "```python\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Åadowanie modelu\n",
    "session = ort.InferenceSession('ensemble_model_optimized.onnx')\n",
    "\n",
    "# Przygotowanie danych audio (zastÄ…p swojÄ… logikÄ…)\n",
    "audio_features = extract_features_from_audio(audio_file)\n",
    "\n",
    "# Inference\n",
    "predictions = session.run(None, {'audio_features': audio_features})\n",
    "predicted_emotion = np.argmax(predictions[0])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Audio Emotion Recognition)",
   "language": "python",
   "name": "audio-emotion-recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
