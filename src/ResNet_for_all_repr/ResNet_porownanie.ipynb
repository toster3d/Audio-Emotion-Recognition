{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importowanie niezbędnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katalog główny projektu: c:\\Users\\kubas\\Desktop\\Projekt dyplomowy\\Audio-Emotion-Recognition\n",
      "Czy katalog src istnieje: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Dodaj katalog główny projektu do sys.path\n",
    "current_dir = (\n",
    "    os.path.dirname(os.path.abspath(__file__))\n",
    "    if \"__file__\" in globals()\n",
    "    else os.getcwd()\n",
    ")\n",
    "project_root = os.path.abspath(os.path.join(current_dir, \"..\", \"..\"))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Katalog główny projektu: {project_root}\")\n",
    "print(f\"Czy katalog src istnieje: {os.path.exists(os.path.join(project_root, 'src'))}\")\n",
    "\n",
    "# Standardowe biblioteki Pythona\n",
    "import hashlib\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Biblioteki do pracy z dźwiękiem i sygnałami\n",
    "import librosa\n",
    "\n",
    "# Biblioteki naukowe i manipulacja danymi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Biblioteki do wizualizacji\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Biblioteki ML i uczenia głębokiego\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Biblioteki do przygotowania danych i oceny modelu\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Tworzenie połączonego wykresu przy użyciu subplots\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Biblioteki specyficzne dla projektu\n",
    "from src.create_data import download_and_save_dataset\n",
    "from datasets import load_from_disk\n",
    "from src.config import (\n",
    "    BATCH_SIZE,\n",
    "    DATASET_PATH,\n",
    "    DROPOUT_RATE,\n",
    "    EARLY_STOPPING_PATIENCE,\n",
    "    LEARNING_RATE,\n",
    "    MAX_LENGTH,\n",
    "    NUM_EPOCHS,\n",
    "    SEED,\n",
    "    WEIGHT_DECAY,\n",
    ")\n",
    "from src.helpers.augment_for_all_types import AugmentedAudioDataset\n",
    "from src.helpers.early_stopping import EarlyStopping\n",
    "from src.helpers.resnet_model_definition import AudioResNet\n",
    "from src.helpers.utils import find_results_directory, read_results_from_files\n",
    "from src.helpers.data_proccesing import read_emotion_results\n",
    "from src.helpers.vizualization import (\n",
    "    generate_accuracy_comparison_plot,\n",
    "    generate_emotion_visualizations,\n",
    ")\n",
    "\n",
    "# Ustawienie seed dla powtarzalności wyników\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Utworzenie katalogu dla wyników\n",
    "results_dir = \"src/ResNet_for_all_repr/feature_comparison_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczęcie ładowania datasetu z dysku...\n"
     ]
    }
   ],
   "source": [
    "# Weryfikacja istnienia folderu z danymi oraz załadowanie zbioru danych\n",
    "dataset_path = DATASET_PATH\n",
    "if os.path.exists(dataset_path):\n",
    "    try:\n",
    "        print(\"Rozpoczęcie ładowania datasetu z dysku...\")\n",
    "        dataset = load_from_disk(dataset_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Wystąpił błąd podczas ładowania datasetu: {e}\")\n",
    "        print(\"Inicjowanie ponownego pobierania datasetu...\")\n",
    "        dataset = download_and_save_dataset()\n",
    "else:\n",
    "    print(\"Folder 'data' nie został znaleziony. Inicjowanie pobierania datasetu...\")\n",
    "    dataset = download_and_save_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(\n",
    "    audio_array,\n",
    "    sr,\n",
    "    feature_type,\n",
    "    max_length=MAX_LENGTH,\n",
    "    n_mels=128,\n",
    "    n_mfcc=40,\n",
    "    n_chroma=12,\n",
    "    n_fft=2048,\n",
    "    hop_length=512,\n",
    "    normalize=True,\n",
    "):\n",
    "    \"\"\"Ekstrakcja różnych cech z sygnału audio.\n",
    "\n",
    "    Args:\n",
    "        audio_array: Sygnał audio w formie tablicy numpy\n",
    "        sr: Częstotliwość próbkowania\n",
    "        feature_type: Typ cechy do ekstrakcji\n",
    "        max_length: Maksymalna długość sygnału w sekundach\n",
    "        n_mels: Liczba pasm melowych dla melspektrogramu\n",
    "        n_mfcc: Liczba współczynników MFCC\n",
    "        n_chroma: Liczba pasm chromatycznych\n",
    "        n_fft: Długość okna dla krótkoterminowej transformaty Fouriera\n",
    "        hop_length: Przesunięcie okna między kolejnymi ramkami\n",
    "        normalize: Czy normalizować wynikowe cechy\n",
    "\n",
    "    Returns:\n",
    "        Wyekstrahowane cechy w formie tablicy numpy\n",
    "    \"\"\"\n",
    "    # Ustalenie docelowej długości sygnału\n",
    "    target_length = int(max_length * sr)\n",
    "    if len(audio_array) > target_length:\n",
    "        audio_array = audio_array[:target_length]\n",
    "    else:\n",
    "        padding = np.zeros(target_length - len(audio_array))\n",
    "        audio_array = np.concatenate([audio_array, padding])\n",
    "\n",
    "    feature = None\n",
    "\n",
    "    if feature_type == \"melspectrogram\":\n",
    "        # Ekstrakcja melspektrogramu\n",
    "        S = librosa.feature.melspectrogram(\n",
    "            y=audio_array, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "        feature = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    elif feature_type == \"spectrogram\":\n",
    "        # Obliczanie standardowego spektrogramu\n",
    "        D = np.abs(librosa.stft(audio_array, n_fft=n_fft, hop_length=hop_length))\n",
    "        feature = librosa.amplitude_to_db(D, ref=np.max)\n",
    "\n",
    "    elif feature_type == \"mfcc\":\n",
    "        # Obliczanie MFCC (Mel-frequency cepstral coefficients)\n",
    "        feature = librosa.feature.mfcc(\n",
    "            y=audio_array, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "\n",
    "    elif feature_type == \"chroma\":\n",
    "        # Obliczanie chromagramu\n",
    "        feature = librosa.feature.chroma_stft(\n",
    "            y=audio_array, sr=sr, n_chroma=n_chroma, n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "\n",
    "    elif feature_type == \"spectral_contrast\":\n",
    "        # Obliczanie spektralnego kontrastu\n",
    "        feature = librosa.feature.spectral_contrast(\n",
    "            y=audio_array, sr=sr, n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "\n",
    "    elif feature_type == \"zcr\":\n",
    "        # Obliczanie Zero Crossing Rate\n",
    "        feature = librosa.feature.zero_crossing_rate(audio_array, hop_length=hop_length)\n",
    "        # Rozszerzanie wymiaru dla ZCR\n",
    "        expanded = np.zeros((n_mels, feature.shape[1]))\n",
    "        normalized_feature = (feature - np.min(feature)) / (\n",
    "            np.max(feature) - np.min(feature) + 1e-8\n",
    "        )\n",
    "        for i in range(n_mels):\n",
    "            scale_factor = 1.0 - (i / float(n_mels))\n",
    "            expanded[i, :] = normalized_feature * scale_factor\n",
    "        feature = expanded\n",
    "\n",
    "    elif feature_type == \"rms\":\n",
    "        # Obliczanie RMS Energy\n",
    "        feature = librosa.feature.rms(y=audio_array, hop_length=hop_length)\n",
    "        # Rozszerzanie wymiaru dla RMS\n",
    "        expanded = np.zeros((n_mels, feature.shape[1]))\n",
    "        normalized_feature = (feature - np.min(feature)) / (\n",
    "            np.max(feature) - np.min(feature) + 1e-8\n",
    "        )\n",
    "        for i in range(n_mels):\n",
    "            scale_factor = np.exp(-3.0 * (i / float(n_mels)))\n",
    "            expanded[i, :] = normalized_feature * scale_factor\n",
    "        feature = expanded\n",
    "\n",
    "    elif feature_type == \"tempogram\":\n",
    "        # Obliczanie tempogramu\n",
    "        feature = librosa.feature.tempogram(y=audio_array, sr=sr, hop_length=hop_length)\n",
    "\n",
    "    elif feature_type == \"tonnetz\":\n",
    "        # Obliczanie Tonnetz - harmonicznych relacji\n",
    "        y_harm = librosa.effects.harmonic(audio_array, margin=4.0)\n",
    "        chroma = librosa.feature.chroma_cqt(y=y_harm, sr=sr, hop_length=hop_length)\n",
    "        feature = librosa.feature.tonnetz(chroma=chroma, sr=sr)\n",
    "\n",
    "    elif feature_type == \"delta_mfcc\":\n",
    "        # Obliczanie Delta MFCC - zmian w MFCC\n",
    "        mfccs = librosa.feature.mfcc(\n",
    "            y=audio_array, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "        feature = librosa.feature.delta(mfccs)\n",
    "\n",
    "    elif feature_type == \"delta_tempogram\":\n",
    "        # Obliczanie Delta Tempogram - zmian w tempie\n",
    "        tempogram = librosa.feature.tempogram(\n",
    "            y=audio_array, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "        feature = librosa.feature.delta(tempogram)\n",
    "\n",
    "    elif feature_type == \"hpss\":\n",
    "        # Rozdzielenie sygnału na komponenty harmoniczne i perkusyjne\n",
    "        y_harmonic, y_percussive = librosa.effects.hpss(audio_array)\n",
    "\n",
    "        # Generowanie spektrogramów dla obu komponentów\n",
    "        S_harmonic = librosa.feature.melspectrogram(\n",
    "            y=y_harmonic, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "        S_percussive = librosa.feature.melspectrogram(\n",
    "            y=y_percussive, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "\n",
    "        # Konwersja do skali dB\n",
    "        S_harmonic_db = librosa.power_to_db(S_harmonic, ref=np.max)\n",
    "        S_percussive_db = librosa.power_to_db(S_percussive, ref=np.max)\n",
    "\n",
    "        # Zamiast tworzyć 3-kanałową reprezentację, łączymy komponenty w jeden melspektrogram\n",
    "        # Używamy średniej ważonej - komponent harmoniczny ma większą wagę\n",
    "        feature = 0.7 * S_harmonic_db + 0.3 * S_percussive_db\n",
    "\n",
    "    elif feature_type == \"cqt\":\n",
    "        # Obliczanie Constant-Q Transform\n",
    "        C = librosa.cqt(\n",
    "            y=audio_array, sr=sr, hop_length=hop_length, n_bins=84, bins_per_octave=12\n",
    "        )\n",
    "        feature = librosa.amplitude_to_db(np.abs(C), ref=np.max)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Nieznany typ cechy: {feature_type}\")\n",
    "\n",
    "    # Normalizacja cech (opcjonalna)\n",
    "    if normalize and feature is not None:\n",
    "        if feature_type in [\"mfcc\", \"delta_mfcc\"]:\n",
    "            # JEDYNE MIEJSCE Z NORMALIZACJĄ MFCC - Cepstral Mean and Variance Normalization (CMVN)\n",
    "            # Normalizacja po osi czasowej (axis=1) - każdy współczynnik MFCC osobno\n",
    "            mean = np.mean(feature, axis=1, keepdims=True)\n",
    "            std = np.std(feature, axis=1, keepdims=True)\n",
    "            # Dodanie małej wartości epsilon aby uniknąć dzielenia przez zero\n",
    "            feature = (feature - mean) / (std + 1e-8)\n",
    "        elif feature_type in [\"melspectrogram\", \"spectrogram\", \"hpss\", \"cqt\"]:\n",
    "            # Spektrogramy - już przekształcone do dB, nie wymagają dodatkowej normalizacji\n",
    "            pass\n",
    "        else:\n",
    "            # Standardowa normalizacja min-max dla pozostałych cech\n",
    "            feature_min = np.min(feature)\n",
    "            feature_max = np.max(feature)\n",
    "            if feature_max > feature_min:\n",
    "                feature = (feature - feature_min) / (feature_max - feature_min)\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Równoległe Przetwarzanie Zbioru Danych Audio\n",
    "\n",
    "Funkcję `process_dataset` przetwarza zbiór danych audio na wybrany typ cechy (np. melspectrogram, mfcc, chroma) w sposób równoległy, wykorzystując wiele rdzeni procesora. Funkcja ekstraktuje cechy za pomocą `extract_features`, normalizuje dane, koduje etykiety, tworzy podziały do walidacji krzyżowej i zapisuje wyniki do pamięci podręcznej, aby uniknąć ponownego przetwarzania. Wyświetla również statystyki, takie jak liczba przetworzonych próbek i czas wykonania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(\n",
    "    dataset,\n",
    "    feature_type,\n",
    "    max_length=3.0,\n",
    "    n_mels=128,\n",
    "    n_mfcc=40,\n",
    "    n_chroma=12,\n",
    "    n_fft=2048,\n",
    "    hop_length=512,\n",
    "    normalize_features=True,\n",
    "    normalize_dataset=True,\n",
    "    n_jobs=-1,\n",
    "    cache_dir=\"src/ResNet_for_all_repr/processed_features\",\n",
    "    force_recompute=False,\n",
    "    cv_folds=5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Równoległe przetwarzanie całego zbioru danych audio na wybrany typ cechy z obsługą cache i walidacją krzyżową.\n",
    "\n",
    "    Argumenty:\n",
    "        dataset: Zbiór danych zawierający próbki audio.\n",
    "        feature_type: Typ cechy do ekstrakcji.\n",
    "        max_length: Maksymalna długość próbki audio w sekundach.\n",
    "        n_mels: Liczba pasm melowych dla melspektrogramu.\n",
    "        n_mfcc: Liczba współczynników MFCC.\n",
    "        n_chroma: Liczba pasm chromatycznych.\n",
    "        n_fft: Długość okna FFT.\n",
    "        hop_length: Długość przeskoku między kolejnymi ramkami.\n",
    "        normalize_features: Flaga określająca, czy normalizować pojedyncze cechy.\n",
    "        normalize_dataset: Flaga określająca, czy normalizować cały zbiór danych.\n",
    "        n_jobs: Liczba równoległych procesów (-1 oznacza wszystkie dostępne rdzenie).\n",
    "        cache_dir: Katalog do zapisywania przetworzonych cech.\n",
    "        force_recompute: Flaga wymuszająca ponowne obliczenie cech, nawet jeśli istnieją w pamięci podręcznej.\n",
    "        cv_folds: Liczba foldów do walidacji krzyżowej.\n",
    "\n",
    "    Zwraca:\n",
    "        dict: Słownik zawierający dane treningowe, walidacyjne i testowe oraz metadane.\n",
    "    \"\"\"\n",
    "\n",
    "    # Tworzenie katalogu pamięci podręcznej, jeśli nie istnieje\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    # Generowanie unikalnego identyfikatora dla zestawu parametrów\n",
    "    params_str = f\"{feature_type}_{max_length}_{n_mels}_{n_mfcc}_{n_chroma}_{n_fft}_{hop_length}_{normalize_features}_{normalize_dataset}_{cv_folds}\"\n",
    "    cache_id = hashlib.md5(params_str.encode()).hexdigest()\n",
    "    cache_file = os.path.join(cache_dir, f\"{feature_type}_{cache_id}.pkl\")\n",
    "\n",
    "    # Sprawdzanie istnienia pliku pamięci podręcznej\n",
    "    if os.path.exists(cache_file) and not force_recompute:\n",
    "        print(\n",
    "            f\"Wczytywanie przetworzonych cech z pliku pamięci podręcznej: {cache_file}\"\n",
    "        )\n",
    "        with open(cache_file, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    print(f\"Przetwarzanie próbek audio dla cechy: {feature_type}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Przygotowanie danych do przetwarzania\n",
    "    audio_samples = []\n",
    "    all_labels = []\n",
    "    sample_ids = []\n",
    "\n",
    "    for i, sample in enumerate(dataset[\"train\"]):\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Przygotowywanie {i}/{len(dataset['train'])} próbek\")\n",
    "        sample_ids.append(i)\n",
    "        audio_samples.append(\n",
    "            (sample[\"audio\"][\"array\"], sample[\"audio\"][\"sampling_rate\"])\n",
    "        )\n",
    "        all_labels.append(sample[\"emotion\"])\n",
    "\n",
    "    # Funkcja do przetwarzania pojedynczej próbki audio\n",
    "    def process_single_sample(i, audio_data):\n",
    "        audio_array, sr = audio_data\n",
    "        try:\n",
    "            feature = extract_features(\n",
    "                audio_array,\n",
    "                sr,\n",
    "                feature_type,\n",
    "                max_length,\n",
    "                n_mels=n_mels,\n",
    "                n_mfcc=n_mfcc,\n",
    "                n_chroma=n_chroma,\n",
    "                n_fft=n_fft,\n",
    "                hop_length=hop_length,\n",
    "                normalize=normalize_features,\n",
    "            )\n",
    "\n",
    "            if feature.size == 0 or (feature.ndim > 1 and feature.shape[1] == 0):\n",
    "                return i, None, \"Pusta cecha\"\n",
    "\n",
    "            return i, feature, None\n",
    "\n",
    "        except Exception as e:\n",
    "            return i, None, str(e)\n",
    "\n",
    "    # Równoległe przetwarzanie próbek audio\n",
    "    print(\n",
    "        f\"Rozpoczęcie równoległego przetwarzania na {n_jobs if n_jobs > 0 else 'wszystkich dostępnych'} rdzeniach...\"\n",
    "    )\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_single_sample)(i, audio_data)\n",
    "        for i, audio_data in enumerate(audio_samples)\n",
    "    )\n",
    "\n",
    "    # Zbieranie wyników przetwarzania\n",
    "    processed_features = []\n",
    "    valid_indices = []\n",
    "    error_count = 0\n",
    "\n",
    "    # Sprawdzenie czy results nie jest None i ma elementy\n",
    "    if results is None:\n",
    "        raise ValueError(\"Błąd przetwarzania równoległego - wyniki są None\")\n",
    "\n",
    "    for result in results:\n",
    "        if result is None or len(result) != 3:\n",
    "            error_count += 1\n",
    "            continue\n",
    "\n",
    "        i, feature, error = result\n",
    "        if feature is not None:\n",
    "            processed_features.append(feature)\n",
    "            valid_indices.append(i)\n",
    "        else:\n",
    "            error_count += 1\n",
    "            # Logowanie błędów dla odrzuconych próbek\n",
    "            if i % 100 == 0 or (\n",
    "                error and \"Pusta cecha\" not in error\n",
    "            ):  # Logowanie co 100 błędów lub niestandardowe błędy\n",
    "                print(f\"Błąd przy próbce {i}: {error}\")\n",
    "\n",
    "    # Konwersja listy cech na tablicę numpy\n",
    "    if len(processed_features) == 0:\n",
    "        raise ValueError(\n",
    "            f\"Nie udało się przetworzyć żadnych próbek dla cechy {feature_type}\"\n",
    "        )\n",
    "\n",
    "    features = np.array(processed_features)\n",
    "    valid_labels = [all_labels[i] for i in valid_indices]\n",
    "\n",
    "    # Przekształcenie do formatu 4D: [próbki, kanały, wysokość, szerokość]\n",
    "    features = features.reshape(\n",
    "        features.shape[0], 1, features.shape[1], features.shape[2]\n",
    "    )\n",
    "\n",
    "    # Kodowanie etykiet\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(valid_labels)\n",
    "    num_classes = len(np.unique(encoded_labels))\n",
    "\n",
    "    # UJEDNOLICONA STRATEGIA NORMALIZACJI:\n",
    "    # MFCC i delta_mfcc mają już zastosowaną normalizację CMVN w extract_features\n",
    "    # Dla innych cech stosujemy normalizację całego datasetu\n",
    "    if normalize_dataset and feature_type not in [\"mfcc\", \"delta_mfcc\"]:\n",
    "        print(f\"Zastosowanie normalizacji datasetu dla cechy: {feature_type}\")\n",
    "        mean = np.mean(features)\n",
    "        std = np.std(features)\n",
    "        if std > 0:\n",
    "            features = (features - mean) / std\n",
    "    elif feature_type in [\"mfcc\", \"delta_mfcc\"]:\n",
    "        print(\n",
    "            \"MFCC/delta_MFCC już znormalizowane metodą CMVN - pomijam normalizację datasetu\"\n",
    "        )\n",
    "\n",
    "    # Tworzenie foldów dla walidacji krzyżowej\n",
    "    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cv_splits = list(skf.split(features, encoded_labels))\n",
    "\n",
    "    # Przygotowanie słownika wynikowego\n",
    "    result = {\n",
    "        \"feature_type\": feature_type,\n",
    "        \"features\": features,\n",
    "        \"labels\": encoded_labels,\n",
    "        \"label_encoder\": label_encoder,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"cv_splits\": cv_splits,\n",
    "        \"params\": {\n",
    "            \"max_length\": max_length,\n",
    "            \"n_mels\": n_mels,\n",
    "            \"n_mfcc\": n_mfcc,\n",
    "            \"n_chroma\": n_chroma,\n",
    "            \"n_fft\": n_fft,\n",
    "            \"hop_length\": hop_length,\n",
    "            \"normalize_features\": normalize_features,\n",
    "            \"normalize_dataset\": normalize_dataset,\n",
    "        },\n",
    "        \"processing_time\": time.time() - start_time,\n",
    "    }\n",
    "\n",
    "    # Wyświetlanie statystyk przetwarzania\n",
    "    print(f\"Całkowita liczba próbek: {len(audio_samples)}\")\n",
    "    print(f\"Liczba ważnych próbek: {len(valid_indices)}\")\n",
    "    print(f\"Liczba pustych/błędnych cech: {error_count}\")\n",
    "    print(f\"Liczba klas emocji: {num_classes}\")\n",
    "    print(\n",
    "        f\"Mapowanie klas: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\"\n",
    "    )\n",
    "    print(f\"Czas przetwarzania: {result['processing_time']:.2f} sekund\")\n",
    "\n",
    "    # Zapis wyników do pamięci podręcznej\n",
    "    print(f\"Zapisywanie przetworzonych cech do pliku pamięci podręcznej: {cache_file}\")\n",
    "    with open(cache_file, \"wb\") as f:\n",
    "        pickle.dump(result, f)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Trening Modelu z Walidacją Krzyżową\n",
    "\n",
    " Funkcja `train_with_cross_validation` realizuje trening modelu z wykorzystaniem walidacji krzyżowej. Funkcja przetwarza zbiór danych na wybrane cechy audio za pomocą process_dataset, a następnie trenuje model (domyślnie `AudioResNet` z resnet_model_definition.py) na każdym foldzie walidacji krzyżowej, monitorując stratę i dokładność. Wykorzystuje mechanizm wczesnego zatrzymania (early stopping) i harmonogram uczenia, zapisuje najlepsze modele dla każdego foldu i oblicza średnie wyniki, takie jak dokładność i czas treningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_cross_validation(\n",
    "    dataset,\n",
    "    feature_type,\n",
    "    model_class=AudioResNet,\n",
    "    batch_size=32,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=1e-5,\n",
    "    epochs=50,\n",
    "    patience=10,\n",
    "    n_jobs=-1,\n",
    "    cache_dir=\"src/ResNet_for_all_repr/processed_features\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Funkcja realizuje trening modelu z wykorzystaniem walidacji krzyżowej.\n",
    "\n",
    "    Argumenty:\n",
    "        dataset: Zbiór danych, który będzie przetwarzany.\n",
    "        feature_type: Typ cechy, która ma być wyodrębniona.\n",
    "        model_class: Klasa modelu, która ma być użyta do treningu.\n",
    "        batch_size: Rozmiar partii danych do przetwarzania.\n",
    "        learning_rate: Wartość współczynnika uczenia.\n",
    "        weight_decay: Wartość współczynnika regularyzacji.\n",
    "        epochs: Maksymalna liczba epok treningowych.\n",
    "        patience: Liczba epok bez poprawy, po której następuje zatrzymanie treningu.\n",
    "        n_jobs: Liczba procesów równoległych do użycia.\n",
    "        cache_dir: Katalog, w którym będą przechowywane przetworzone cechy.\n",
    "\n",
    "    Zwraca:\n",
    "        dict: Wyniki walidacji krzyżowej.\n",
    "    \"\"\"\n",
    "\n",
    "    # Przetwarzanie danych z walidacją krzyżową\n",
    "    data = process_dataset(\n",
    "        dataset, feature_type, n_jobs=n_jobs, cache_dir=cache_dir, cv_folds=5\n",
    "    )\n",
    "\n",
    "    features = data[\"features\"]\n",
    "    labels = data[\"labels\"]\n",
    "    cv_splits = data[\"cv_splits\"]\n",
    "    num_classes = data[\"num_classes\"]\n",
    "\n",
    "    # Inicjalizacja listy wyników dla każdego foldu\n",
    "    cv_results = []\n",
    "\n",
    "    # Ustalenie urządzenia do obliczeń\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Używane urządzenie: {device}\")\n",
    "\n",
    "    # Pętla treningowa dla każdego foldu\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv_splits):\n",
    "        print(f\"\\n{'=' * 30} Fold {fold + 1}/{len(cv_splits)} {'=' * 30}\")\n",
    "\n",
    "        # Przygotowanie danych dla bieżącego foldu\n",
    "        X_train, X_val = features[train_idx], features[val_idx]\n",
    "        y_train, y_val = labels[train_idx], labels[val_idx]\n",
    "\n",
    "        # Konwersja danych do tensorów PyTorch\n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        y_train_tensor = torch.LongTensor(y_train)\n",
    "        X_val_tensor = torch.FloatTensor(X_val)\n",
    "        y_val_tensor = torch.LongTensor(y_val)\n",
    "\n",
    "        # Tworzenie zbiorów danych dla DataLoader\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "        # Inicjalizacja modelu\n",
    "        input_shape = features[0].shape\n",
    "        model = model_class(input_shape, num_classes).to(device)\n",
    "\n",
    "        # Ustalenie funkcji straty oraz optymalizatora\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    "        )\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.5, patience=5\n",
    "        )\n",
    "\n",
    "        # Inicjalizacja zmiennych do śledzenia najlepszego modelu\n",
    "        best_val_loss = float(\"inf\")\n",
    "        epochs_no_improve = 0\n",
    "        best_epoch = 0\n",
    "        best_model_state = None\n",
    "\n",
    "        # Historia statystyk treningu\n",
    "        history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Pętla treningowa\n",
    "        for epoch in range(epochs):\n",
    "            # Ustawienie modelu w tryb treningowy\n",
    "            model.train()\n",
    "            total_train_loss = 0\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                # Zerowanie gradientów\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Przechodzenie przez model\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                # Wsteczna propagacja i aktualizacja wag\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Obliczanie średniej straty treningowej\n",
    "            avg_train_loss = total_train_loss / len(train_dataset)\n",
    "\n",
    "            # Ustawienie modelu w tryb ewaluacji\n",
    "            model.eval()\n",
    "            total_val_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "\n",
    "                    total_val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    correct += (predictions == targets).sum().item()\n",
    "                    total += targets.size(0)\n",
    "\n",
    "            # Obliczanie średniej straty walidacyjnej oraz dokładności\n",
    "            avg_val_loss = total_val_loss / len(val_dataset)\n",
    "            val_accuracy = 100.0 * correct / total\n",
    "\n",
    "            # Aktualizacja harmonogramu uczenia\n",
    "            scheduler.step(avg_val_loss)\n",
    "\n",
    "            # Zapis statystyk do historii\n",
    "            history[\"train_loss\"].append(avg_train_loss)\n",
    "            history[\"val_loss\"].append(avg_val_loss)\n",
    "            history[\"val_acc\"].append(val_accuracy)\n",
    "\n",
    "            print(\n",
    "                f\"Epoka {epoch + 1}/{epochs}, Strata treningu: {avg_train_loss:.4f}, \"\n",
    "                f\"Strata walidacji: {avg_val_loss:.4f}, Dokładność walidacji: {val_accuracy:.2f}%\"\n",
    "            )\n",
    "\n",
    "            # Sprawdzanie warunków do zatrzymania treningu\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_epoch = epoch\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= patience:\n",
    "                    print(f\"Zatrzymanie treningu! Brak poprawy przez {patience} epok.\")\n",
    "                    break\n",
    "\n",
    "        # Obliczanie czasu treningu\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        # Przywracanie najlepszego modelu\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "        # Ewaluacja najlepszego modelu\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                correct += (predictions == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "\n",
    "        final_accuracy = 100.0 * correct / total\n",
    "\n",
    "        # Zapis wyników dla bieżącego foldu\n",
    "        fold_result = {\n",
    "            \"fold\": fold + 1,\n",
    "            \"best_epoch\": best_epoch + 1,\n",
    "            \"best_val_loss\": best_val_loss,\n",
    "            \"final_accuracy\": final_accuracy,\n",
    "            \"training_time\": training_time,\n",
    "            \"history\": history,\n",
    "            \"model_state\": best_model_state,\n",
    "        }\n",
    "\n",
    "        cv_results.append(fold_result)\n",
    "\n",
    "        print(f\"\\nWyniki dla foldu {fold + 1}:\")\n",
    "        print(f\"Najlepsza epoka: {best_epoch + 1}\")\n",
    "        print(f\"Najlepsza strata walidacji: {best_val_loss:.4f}\")\n",
    "        print(f\"Końcowa dokładność: {final_accuracy:.2f}%\")\n",
    "        print(f\"Czas treningu: {training_time:.2f} sekund\")\n",
    "\n",
    "    # Obliczanie średnich wyników\n",
    "    avg_accuracy = np.mean([res[\"final_accuracy\"] for res in cv_results])\n",
    "    avg_val_loss = np.mean([res[\"best_val_loss\"] for res in cv_results])\n",
    "    avg_training_time = np.mean([res[\"training_time\"] for res in cv_results])\n",
    "\n",
    "    print(f\"\\n{'=' * 30} Wyniki walidacji krzyżowej {'=' * 30}\")\n",
    "    print(\n",
    "        f\"Średnia dokładność: {avg_accuracy:.2f}% ± {np.std([res['final_accuracy'] for res in cv_results]):.2f}%\"\n",
    "    )\n",
    "    print(f\"Średnia strata walidacji: {avg_val_loss:.4f}\")\n",
    "    print(f\"Średni czas treningu: {avg_training_time:.2f} sekund\")\n",
    "\n",
    "    # Tworzenie słownika z wynikami\n",
    "    final_results = {\n",
    "        \"feature_type\": feature_type,\n",
    "        \"cv_results\": cv_results,\n",
    "        \"avg_accuracy\": avg_accuracy,\n",
    "        \"avg_val_loss\": avg_val_loss,\n",
    "        \"avg_training_time\": avg_training_time,\n",
    "        \"params\": data[\"params\"],\n",
    "        \"label_encoder\": data[\"label_encoder\"],\n",
    "        \"num_classes\": num_classes,\n",
    "    }\n",
    "\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja Collate dla DataLoader Audio\n",
    "\n",
    "Funkcja `audio_collate_fn` jest używana jako `collate_fn` w DataLoader do obsługi danych audio, w szczególności cech takich jak ZCR (Zero Crossing Rate) i RMS (RMS Energy). Funkcja przetwarza batch danych, pomijając puste tensory, dostosowuje wymiary tensorów (rozszerzając je do formatu 4D: [batch, kanały, wysokość, szerokość]), dopełnia je zerami do wspólnego rozmiaru i łączy w jeden batch tensorów cech oraz etykiet. W przypadku błędów zwraca dummy tensor, aby zapobiec przerwaniu procesu treningu.\n",
    "Uzasadnienie użytych featurów:\n",
    "Cechy audio, takie jak ZCR i RMS, są istotne w analizie sygnału, ponieważ dostarczają informacji o dynamice i energii dźwięku, co może być kluczowe w rozpoznawaniu emocji. Funkcja audio_collate_fn została zaprojektowana, aby obsługiwać te cechy, które często mają nietypowe wymiary (np. rozszerzone do 2D w procesie ekstrakcji), zapewniając ich poprawną integrację w batchach danych. Dopełnianie tensorów zerami pozwala na ujednolicenie rozmiarów danych wejściowych do modelu, co jest niezbędne dla architektur głębokich, takich jak ResNet, oczekujących spójnych wymiarów inputu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Funkcja collate_fn dla DataLoader, która obsługuje ZCR i RMS.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for feature, label in batch:\n",
    "        # Pomija elementy None oraz tensory bez wymiarów\n",
    "        if feature is None or feature.numel() == 0:\n",
    "            continue\n",
    "\n",
    "        # Sprawdza, czy tensor ma prawidłowy format\n",
    "        if feature.dim() == 2:  # Jeden wymiar + kanał\n",
    "            # Rozszerza tensor do formatu 4D\n",
    "            feature = feature.unsqueeze(0).unsqueeze(0)  # [H,W] -> [1,1,H,W]\n",
    "        elif feature.dim() == 3:  # Cechy 2D bez kanału lub 1D z batch\n",
    "            if feature.shape[0] == 1:  # Format [1, H, W]\n",
    "                feature = feature.unsqueeze(0)  # [1,H,W] -> [1,1,H,W]\n",
    "            else:  # Format [B, H, W]\n",
    "                feature = feature.unsqueeze(1)  # [B,H,W] -> [B,1,H,W]\n",
    "\n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Dopełnia tensory do wspólnego rozmiaru\n",
    "    try:\n",
    "        max_height = max([f.shape[2] for f in features])\n",
    "        max_width = max([f.shape[3] for f in features])\n",
    "\n",
    "        for i in range(len(features)):\n",
    "            if features[i].shape[2] < max_height or features[i].shape[3] < max_width:\n",
    "                # Dopełnia zerami do pełnego rozmiaru\n",
    "                padded = torch.zeros(\n",
    "                    features[i].shape[0],\n",
    "                    features[i].shape[1],\n",
    "                    max_height,\n",
    "                    max_width,\n",
    "                    device=features[i].device,\n",
    "                    dtype=features[i].dtype,\n",
    "                )\n",
    "                padded[:, :, : features[i].shape[2], : features[i].shape[3]] = features[\n",
    "                    i\n",
    "                ]\n",
    "                features[i] = padded\n",
    "\n",
    "        features_batch = torch.cat(features, dim=0)\n",
    "        labels_batch = torch.tensor(labels)\n",
    "\n",
    "        return features_batch, labels_batch\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd podczas tworzenia batch: {e}\")\n",
    "        print(f\"Kształty tensorów: {[f.shape for f in features]}\")\n",
    "        # Zwraca dummy tensor w przypadku błędu\n",
    "        return torch.zeros((1, 1, 4, 4)), torch.zeros(1, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie Danych i Trening Modelu dla Wybranej Cechy\n",
    "\n",
    "Funkcja `prepare_dataset`s tworzy zestawy danych treningowe, walidacyjne i testowe z zastosowaniem augmentacji dla danych treningowych, korzystając z klasy     `AugmentedAudioDataset`. Funkcja `train_model_for_feature` przetwarza zbiór danych na wybraną cechę audio (np. melspectrogram), dzieli dane na podzbiory, inicjalizuje model AudioResNet, trenuje go z użyciem optymalizatora Adam, harmonogramu uczenia i mechanizmu wczesnego zatrzymania (`EarlyStopping`), a także zapisuje najlepszy model i historię treningu.\n",
    "\n",
    "W poniższym bloku wykorzystujemy klasę `AugmentedAudioDataset` zdefiniowaną w pliku `augment_for_all_types.py`. Ten plik definiuje framework do augmentacji danych audio, oferując różne strategie augmentacji (np. `SpectrogramAugmentation`, `MFCCAugmentation`) dla różnych typów cech (melspectrogram, mfcc, zcr, itp.). Wykorzystuje wzorzec projektowy strategii, umożliwiając dodawanie szumu, maskowanie częstotliwości czy przesunięcia czasowe, co zwiększa różnorodność danych treningowych i pomaga w zapobieganiu przeuczeniu. Klasa `AugmentedAudioDataset` integruje augmentację z procesem ładowania danych do modelu.\n",
    "Wykorzystana również klasa `EarlyStopping` monitoruje stratę walidacyjną podczas treningu. Jeśli strata nie poprawia się przez określoną liczbę epok (parametr patience), trening zostaje zatrzymany, a najlepszy model zapisany. Mechanizm ten zapobiega przeuczeniu i oszczędza czas obliczeń, zatrzymując trening, gdy dalsza poprawa jest mało prawdopodobna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotowanie zestawów danych z odpowiednią augmentacją\n",
    "def prepare_datasets(\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test, feature_type, batch_size\n",
    "):\n",
    "    \"\"\"\n",
    "    Przygotowuje zestawy danych z zastosowaniem strategii augmentacji.\n",
    "    \"\"\"\n",
    "\n",
    "    # Tworzenie zbiorów danych z informacją o typie cechy\n",
    "    train_dataset = AugmentedAudioDataset(\n",
    "        X_train, y_train, feature_type=feature_type, augment=True\n",
    "    )\n",
    "\n",
    "    val_dataset = AugmentedAudioDataset(\n",
    "        X_val, y_val, feature_type=feature_type, augment=False\n",
    "    )\n",
    "\n",
    "    test_dataset = AugmentedAudioDataset(\n",
    "        X_test, y_test, feature_type=feature_type, augment=False\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, collate_fn=audio_collate_fn\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, collate_fn=audio_collate_fn\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, collate_fn=audio_collate_fn\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# Funkcja do trenowania modelu dla wybranej cechy\n",
    "def train_model_for_feature(dataset, feature_type, max_length=3.0):\n",
    "    \"\"\"\n",
    "    Trenuje model ResNet dla wybranej reprezentacji dźwięku.\n",
    "\n",
    "    Args:\n",
    "        dataset: Zbiór danych zawierający próbki audio i etykiety\n",
    "        feature_type: Typ cechy do ekstrakcji (np. 'melspectrogram', 'mfcc')\n",
    "        max_length: Maksymalna długość próbki audio w sekundach\n",
    "\n",
    "    Returns:\n",
    "        tuple: (model, test_loader, label_encoder, history, feature_dir, timestamp, feature_type, training_time)\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    feature_dir = os.path.join(results_dir, feature_type)\n",
    "    os.makedirs(feature_dir, exist_ok=True)\n",
    "\n",
    "    # Przetwarzanie danych\n",
    "    processed_data = process_dataset(dataset, feature_type, max_length)\n",
    "\n",
    "    # Wyodrębnienie istotnych wartości ze słownika\n",
    "    features = processed_data[\"features\"]\n",
    "    labels = processed_data[\"labels\"]\n",
    "    label_encoder = processed_data[\"label_encoder\"]\n",
    "    num_classes = processed_data[\"num_classes\"]\n",
    "    # Podział na zbiory\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, labels, test_size=0.2, random_state=SEED, stratify=labels\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=SEED, stratify=y_train\n",
    "    )\n",
    "\n",
    "    # Inicjalizacja modelu, funkcji straty i optymalizatora\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Używane urządzenie: {device}\")\n",
    "\n",
    "    model = AudioResNet(num_classes=num_classes, dropout_rate=DROPOUT_RATE)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.5, patience=3\n",
    "    )\n",
    "\n",
    "    # Przygotowanie danych za pomocą funkcji prepare_datasets\n",
    "    train_loader, val_loader, test_loader = prepare_datasets(\n",
    "        X_train,\n",
    "        X_val,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_val,\n",
    "        y_test,\n",
    "        feature_type=feature_type,\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "\n",
    "    # Ścieżka do zapisywania modelu\n",
    "    model_path = os.path.join(feature_dir, f\"best_model_{feature_type}_{timestamp}.pt\")\n",
    "    early_stopping = EarlyStopping(patience=EARLY_STOPPING_PATIENCE, path=model_path)\n",
    "\n",
    "    # Historia treningu\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_accuracy\": []}\n",
    "\n",
    "    # Proces treningu modelu\n",
    "    print(f\"Rozpoczynanie treningu dla cechy: {feature_type}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Faza treningu\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "\n",
    "        # Faza walidacji\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Obliczanie straty walidacyjnej\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Obliczanie dokładności\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_accuracy\"].append(val_accuracy)\n",
    "\n",
    "        print(\n",
    "            f\"Epoka {epoch + 1}/{NUM_EPOCHS}, Strata treningu: {train_loss:.4f}, \"\n",
    "            f\"Strata walidacji: {val_loss:.4f}, Dokładność walidacji: {val_accuracy:.2f}%\"\n",
    "        )\n",
    "\n",
    "        # Aktualizacja schedulera\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Sprawdzenie warunku early stopping\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Aktywacja early stopping!\")\n",
    "            break\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "    print(\n",
    "        f\"Zakończenie treningu po {epoch + 1} epokach. Czas: {training_time:.2f} sekund\"\n",
    "    )\n",
    "\n",
    "    # Wczytanie najlepszego modelu\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    return (\n",
    "        model,\n",
    "        test_loader,\n",
    "        label_encoder,\n",
    "        history,\n",
    "        feature_dir,\n",
    "        timestamp,\n",
    "        feature_type,\n",
    "        training_time,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja Modelu i Wizualizacja Wyników\n",
    "\n",
    "Funkcja `evaluate_model` przeprowadza ewaluację wytrenowanego modelu na danych testowych. Funkcja oblicza stratę i dokładność testową, generuje macierz konfuzji, raport klasyfikacji oraz wizualizacje historii treningu (strata i dokładność w czasie). Wyniki, w tym hiperparametry i metryki wydajności, są zapisywane do plików w celu dalszej analizy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    label_encoder,\n",
    "    history,\n",
    "    feature_dir,\n",
    "    timestamp,\n",
    "    feature_type,\n",
    "    training_time,\n",
    "    device=None,\n",
    "    save_results=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Ewaluacja modelu oraz generowanie wizualizacji wyników.\n",
    "\n",
    "    Args:\n",
    "        model: Wytrenowany model do ewaluacji.\n",
    "        test_loader: DataLoader zawierający dane testowe.\n",
    "        label_encoder: Enkoder etykiet do konwersji etykiet.\n",
    "        history: Historia treningu modelu.\n",
    "        feature_dir: Katalog przeznaczony do zapisywania wyników.\n",
    "        timestamp: Znacznik czasowy dla unikalności plików.\n",
    "        feature_type: Typ cechy, która jest analizowana.\n",
    "        training_time: Czas trwania treningu modelu.\n",
    "        device: Urządzenie, na którym przeprowadzana jest ewaluacja (CPU/GPU).\n",
    "        save_results: Flaga określająca, czy wyniki mają być zapisywane do plików.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Zawiera dokładność testu oraz historię treningu.\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                # Sprawdzenie, czy batch zawiera dane\n",
    "                if inputs.numel() == 0 or labels.numel() == 0:\n",
    "                    continue\n",
    "\n",
    "                # Weryfikacja wymiarów danych wejściowych\n",
    "                if inputs.dim() != 4:\n",
    "                    continue\n",
    "\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Obliczanie straty testowej\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # Obliczanie dokładności\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "                # Zbieranie predykcji oraz rzeczywistych etykiet\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        if len(test_loader) > 0:\n",
    "            test_loss = test_loss / len(test_loader)\n",
    "        else:\n",
    "            return 0.0, history\n",
    "\n",
    "        test_accuracy = 100 * test_correct / test_total if test_total > 0 else 0.0\n",
    "\n",
    "        if save_results and all_preds and all_labels:\n",
    "            # Obliczanie macierzy konfuzji\n",
    "            cm = confusion_matrix(all_labels, all_preds)\n",
    "            class_names = label_encoder.classes_\n",
    "\n",
    "            # Wizualizacja macierzy konfuzji\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "            sns.heatmap(\n",
    "                cm_normalized,\n",
    "                annot=True,\n",
    "                fmt=\".2f\",\n",
    "                cmap=\"Blues\",\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names,\n",
    "            )\n",
    "            plt.title(f\"Znormalizowana macierz konfuzji - {feature_type}\")\n",
    "            plt.ylabel(\"Rzeczywista etykieta\")\n",
    "            plt.xlabel(\"Przewidziana etykieta\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\n",
    "                os.path.join(\n",
    "                    feature_dir, f\"confusion_matrix_{feature_type}_{timestamp}.png\"\n",
    "                )\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "            # Generowanie raportu klasyfikacji\n",
    "            report = classification_report(\n",
    "                all_labels, all_preds, target_names=class_names, output_dict=True\n",
    "            )\n",
    "            report_df = pd.DataFrame(report).transpose()\n",
    "            report_df.to_csv(\n",
    "                os.path.join(\n",
    "                    feature_dir, f\"classification_report_{feature_type}_{timestamp}.csv\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Wizualizacja historii treningu\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(history[\"train_loss\"], label=\"Trening\")\n",
    "            plt.plot(history[\"val_loss\"], label=\"Walidacja\")\n",
    "            plt.title(f\"Strata podczas treningu - {feature_type}\")\n",
    "            plt.xlabel(\"Epoka\")\n",
    "            plt.ylabel(\"Strata\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(history[\"val_accuracy\"], label=\"Walidacja\")\n",
    "            plt.title(f\"Dokładność podczas treningu - {feature_type}\")\n",
    "            plt.xlabel(\"Epoka\")\n",
    "            plt.ylabel(\"Dokładność (%)\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\n",
    "                os.path.join(\n",
    "                    feature_dir, f\"training_history_{feature_type}_{timestamp}.png\"\n",
    "                )\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "            # Zapisanie hiperparametrów oraz wyników\n",
    "            results = {\n",
    "                \"feature_type\": feature_type,\n",
    "                \"hyperparameters\": {\n",
    "                    \"batch_size\": BATCH_SIZE,\n",
    "                    \"initial_lr\": LEARNING_RATE,\n",
    "                    \"weight_decay\": WEIGHT_DECAY,\n",
    "                    \"dropout_rate\": DROPOUT_RATE,\n",
    "                    \"early_stopping_patience\": EARLY_STOPPING_PATIENCE,\n",
    "                    \"max_epochs\": NUM_EPOCHS,\n",
    "                    \"actual_epochs\": len(history[\"train_loss\"]),\n",
    "                },\n",
    "                \"performance\": {\n",
    "                    \"test_accuracy\": test_accuracy,\n",
    "                    \"test_loss\": test_loss,\n",
    "                    \"val_accuracy\": history[\"val_accuracy\"][-1]\n",
    "                    if history[\"val_accuracy\"]\n",
    "                    else None,\n",
    "                    \"val_loss\": history[\"val_loss\"][-1]\n",
    "                    if history[\"val_loss\"]\n",
    "                    else None,\n",
    "                    \"training_time\": training_time,\n",
    "                },\n",
    "            }\n",
    "\n",
    "            # Zapisanie wyników do pliku\n",
    "            with open(\n",
    "                os.path.join(feature_dir, f\"results_{feature_type}_{timestamp}.txt\"),\n",
    "                \"w\",\n",
    "            ) as f:\n",
    "                for section, values in results.items():\n",
    "                    if isinstance(values, dict):\n",
    "                        f.write(f\"{section.upper()}:\\n\")\n",
    "                        for key, value in values.items():\n",
    "                            f.write(f\"  {key}: {value}\\n\")\n",
    "                        f.write(\"\\n\")\n",
    "                    else:\n",
    "                        f.write(f\"{section}: {values}\\n\\n\")\n",
    "\n",
    "        return test_accuracy, history\n",
    "\n",
    "    except Exception:\n",
    "        return 0.0, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksperyment Porównawczy Różnych Reprezentacji Audio\n",
    "\n",
    "Funkcja `run_feature_comparison_experiment` przeprowadza eksperymenty porównawcze dla różnych reprezentacji dźwięku. Funkcja trenuje modele dla każdego typu cechy (np. melspectrogram, mfcc), ewaluuje ich dokładność na danych testowych, zapisuje wyniki częściowe i końcowe do plików CSV oraz generuje wizualizacje porównujące dokładność i czas treningu dla różnych cech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista typów cech do przetestowania\n",
    "feature_types = [\n",
    "    \"spectrogram\",\n",
    "    \"melspectrogram\",\n",
    "    \"mfcc\",\n",
    "    \"chroma\",\n",
    "    \"spectral_contrast\",\n",
    "    \"zcr\",\n",
    "    \"rms\",\n",
    "    \"tempogram\",\n",
    "    \"tonnetz\",\n",
    "    \"delta_mfcc\",\n",
    "    \"delta_tempogram\",\n",
    "    \"hpss\",\n",
    "    \"cqt\",\n",
    "]\n",
    "\n",
    "\n",
    "def run_feature_comparison_experiment(\n",
    "    dataset,\n",
    "    feature_types_to_run=None,\n",
    "    skip_trained=True,\n",
    "    save_interim=True,\n",
    "    n_mels=128,\n",
    "    n_mfcc=40,\n",
    "    n_chroma=12,\n",
    "    n_fft=2048,\n",
    "    hop_length=512,\n",
    "    normalize_features=True,\n",
    "    normalize_dataset=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Uruchamia eksperymenty dla różnych reprezentacji dźwięku oraz porównuje wyniki.\n",
    "\n",
    "    Args:\n",
    "        dataset: Zbiór danych do przetwarzania.\n",
    "        feature_types_to_run: Lista typów cech do uruchomienia (domyślnie wszystkie).\n",
    "        skip_trained: Flaga określająca, czy pomijać cechy, dla których istnieją już wyniki.\n",
    "        save_interim: Flaga określająca, czy zapisywać wyniki częściowe po każdym typie cechy.\n",
    "        n_mels: Liczba pasm melowych dla melspektrogramu.\n",
    "        n_mfcc: Liczba współczynników MFCC.\n",
    "        n_chroma: Liczba pasm chromatycznych.\n",
    "        n_fft: Długość okna FFT.\n",
    "        hop_length: Długość przeskoku między kolejnymi ramkami.\n",
    "        normalize_features: Flaga określająca, czy normalizować pojedyncze cechy.\n",
    "        normalize_dataset: Flaga określająca, czy normalizować cały zbiór danych.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame z podsumowaniem wyników.\n",
    "    \"\"\"\n",
    "\n",
    "    # Katalog do przechowywania wyników\n",
    "    results_dir = \"src/ResNet_for_all_repr/feature_comparison_results\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    # Inicjalizacja słownika do przechowywania wyników\n",
    "    results = {}\n",
    "\n",
    "    # Użycie przekazanej listy cech lub domyślnie wszystkich\n",
    "    if feature_types_to_run is None:\n",
    "        feature_types_to_run = feature_types\n",
    "\n",
    "    # Sprawdzenie istnienia wcześniejszych wyników\n",
    "    summary_path = os.path.join(results_dir, \"feature_comparison_summary.csv\")\n",
    "    if os.path.exists(summary_path) and skip_trained:\n",
    "        try:\n",
    "            existing_results = pd.read_csv(summary_path)\n",
    "            trained_features = existing_results[\"Feature Type\"].tolist()\n",
    "\n",
    "            # Wczytanie istniejących wyników\n",
    "            for ft in trained_features:\n",
    "                if ft in feature_types_to_run:\n",
    "                    accuracy = existing_results[existing_results[\"Feature Type\"] == ft][\n",
    "                        \"Test Accuracy (%)\"\n",
    "                    ].values[0]\n",
    "                    results[ft] = {\"accuracy\": accuracy, \"history\": None}\n",
    "\n",
    "            # Usunięcie przetrenowanych cech z listy do uruchomienia\n",
    "            feature_types_to_run = [\n",
    "                ft for ft in feature_types_to_run if ft not in trained_features\n",
    "            ]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Nie udało się wczytać istniejących wyników: {e}\")\n",
    "\n",
    "    # Uruchamianie eksperymentów dla każdego typu cechy\n",
    "    start_time_all = time.time()\n",
    "\n",
    "    for i, feature_type in enumerate(feature_types_to_run):\n",
    "        try:\n",
    "            # Trenowanie modelu z przekazaniem wszystkich parametrów\n",
    "            (\n",
    "                model,\n",
    "                test_loader,\n",
    "                label_encoder,\n",
    "                history,\n",
    "                feature_dir,\n",
    "                timestamp,\n",
    "                feature_type,\n",
    "                training_time,\n",
    "            ) = train_model_for_feature(\n",
    "                dataset,\n",
    "                feature_type,\n",
    "                max_length=MAX_LENGTH,\n",
    "                n_mels=n_mels,\n",
    "                n_mfcc=n_mfcc,\n",
    "                n_chroma=n_chroma,\n",
    "                n_fft=n_fft,\n",
    "                hop_length=hop_length,\n",
    "                normalize_features=normalize_features,\n",
    "                normalize_dataset=normalize_dataset,\n",
    "            )\n",
    "\n",
    "            # Ewaluacja modelu\n",
    "            device = next(model.parameters()).device\n",
    "            accuracy, history = evaluate_model(\n",
    "                model,\n",
    "                test_loader,\n",
    "                label_encoder,\n",
    "                history,\n",
    "                feature_dir,\n",
    "                timestamp,\n",
    "                feature_type,\n",
    "                training_time,\n",
    "                device,\n",
    "            )\n",
    "\n",
    "            # Zapis wyników\n",
    "            results[feature_type] = {\"accuracy\": accuracy, \"history\": history}\n",
    "\n",
    "            # Zapis częściowych wyników, jeśli włączono tę opcję\n",
    "            if save_interim:\n",
    "                interim_results = {k: results[k][\"accuracy\"] for k in results}\n",
    "                interim_df = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Feature Type\": list(interim_results.keys()),\n",
    "                        \"Test Accuracy (%)\": list(interim_results.values()),\n",
    "                    }\n",
    "                ).sort_values(\"Test Accuracy (%)\", ascending=False)\n",
    "\n",
    "                interim_df.to_csv(\n",
    "                    os.path.join(results_dir, \"interim_results.csv\"), index=False\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            # Zapis informacji o błędzie\n",
    "            results[feature_type] = {\"accuracy\": 0.0, \"history\": None, \"error\": str(e)}\n",
    "\n",
    "    total_time = time.time() - start_time_all\n",
    "\n",
    "    # Dodanie wcześniej przetrenowanych cech\n",
    "    all_results = {}\n",
    "    all_results.update(results)\n",
    "\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Feature Type\": list(all_results.keys()),\n",
    "            \"Test Accuracy (%)\": [\n",
    "                all_results[ft][\"accuracy\"] for ft in all_results.keys()\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    results_df = results_df.sort_values(\"Test Accuracy (%)\", ascending=False)\n",
    "\n",
    "    # Zapis podsumowania do pliku CSV\n",
    "    results_df.to_csv(\n",
    "        os.path.join(results_dir, \"feature_comparison_summary.csv\"), index=False\n",
    "    )\n",
    "\n",
    "    # Wizualizacja porównania dokładności\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(results_df[\"Feature Type\"], results_df[\"Test Accuracy (%)\"])\n",
    "    plt.title(\"Porównanie dokładności dla różnych reprezentacji audio\")\n",
    "    plt.xlabel(\"Typ cechy\")\n",
    "    plt.ylabel(\"Dokładność testu (%)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, \"accuracy_comparison.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Dodanie wizualizacji czasu treningu, jeśli dostępne\n",
    "    if any(\"training_time\" in all_results.get(ft, {}) for ft in all_results):\n",
    "        times_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Feature Type\": [\n",
    "                    ft for ft in all_results if \"training_time\" in all_results[ft]\n",
    "                ],\n",
    "                \"Training Time (s)\": [\n",
    "                    all_results[ft].get(\"training_time\", 0)\n",
    "                    for ft in all_results\n",
    "                    if \"training_time\" in all_results[ft]\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(times_df[\"Feature Type\"], times_df[\"Training Time (s)\"])\n",
    "        plt.title(\"Porównanie czasu treningu dla różnych reprezentacji audio\")\n",
    "        plt.xlabel(\"Typ cechy\")\n",
    "        plt.ylabel(\"Czas treningu (s)\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, \"training_time_comparison.png\"))\n",
    "        plt.close()\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odczyt Dokładności z Zapisanych Wyników\n",
    "\n",
    " Funkcja `read_accuracy_from_results` odczytuje dokładność testową dla określonego typu cechy audio z zapisanych wyników w katalogu **feature_comparison_results**. Funkcja przeszukuje podfoldery w poszukiwaniu pliku **results.json** i próbuje wyciągnąć wartość dokładności z różnych możliwych kluczy (accuracy, test_accuracy, val_accuracy), zwracając ją jako liczbę zmiennoprzecinkową lub None, jeśli wynik nie zostanie znaleziony.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_accuracy_from_results(\n",
    "    feature_type: str,\n",
    "    results_base_dir: str = \"src/ResNet_for_all_repr/feature_comparison_results\",\n",
    ") -> float | None:\n",
    "    \"\"\"\n",
    "    Odczytuje dokładność z zapisanych wyników dla określonego typu cechy.\n",
    "\n",
    "    Args:\n",
    "        feature_type: Typ cechy (np. 'mfcc', 'spectrogram').\n",
    "        results_base_dir: Katalog bazowy zawierający wyniki.\n",
    "\n",
    "    Returns:\n",
    "        Dokładność jako liczba zmiennoprzecinkowa lub None, jeśli nie znaleziono.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    feature_dir = os.path.join(results_base_dir, feature_type)\n",
    "\n",
    "    if not os.path.exists(feature_dir):\n",
    "        return None\n",
    "\n",
    "    # Wyszukiwanie pliku results.json w podfolderach\n",
    "    for root, dirs, files in os.walk(feature_dir):\n",
    "        for file in files:\n",
    "            if file == \"results.json\":\n",
    "                try:\n",
    "                    with open(os.path.join(root, file), \"r\") as f:\n",
    "                        results = json.load(f)\n",
    "                        # Sprawdzanie różnych możliwych kluczy dla dokładności\n",
    "                        for key in [\"accuracy\", \"test_accuracy\", \"val_accuracy\"]:\n",
    "                            if key in results:\n",
    "                                return float(results[key])\n",
    "                except Exception as e:\n",
    "                    print(\n",
    "                        f\"Wystąpił błąd podczas odczytu pliku {os.path.join(root, file)}: {str(e)}\"\n",
    "                    )\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening i Porównanie Modeli dla Różnych Cech Audio\n",
    "\n",
    "Funkcja `run_training_experiment` przeprowadza trening modeli dla wybranej cechy audio lub wszystkich dostępnych reprezentacji (np. melspectrogram, mfcc). Funkcja pomija cechy z istniejącymi wynikami (jeśli ustawiono skip_trained), trenuje modele, ewaluuje ich dokładność, mierzy czas treningu i generuje szczegółowe raporty oraz interaktywne wizualizacje (wykresy dokładności i czasu treningu) przy użyciu bibliotek Plotly i Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_experiment(\n",
    "    dataset,\n",
    "    feature_type=None,\n",
    "    skip_trained=False,\n",
    "    results_base_dir=\"src/ResNet_for_all_repr/feature_comparison_results\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Uruchamia trening dla wybranej cechy lub wszystkich cech.\n",
    "\n",
    "    Args:\n",
    "        dataset: Zbiór danych do treningu.\n",
    "        feature_type: Konkretna cecha do treningu (None oznacza wszystkie cechy).\n",
    "        skip_trained: Flaga wskazująca, czy pomijać cechy, dla których istnieją już wyniki.\n",
    "        results_base_dir: Katalog bazowy do zapisywania wyników.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame z podsumowaniem wyników.\n",
    "    \"\"\"\n",
    "\n",
    "    # Lista wszystkich dostępnych typów cech\n",
    "    all_feature_types = [\n",
    "        \"spectrogram\",\n",
    "        \"melspectrogram\",\n",
    "        \"mfcc\",\n",
    "        \"chroma\",\n",
    "        \"spectral_contrast\",\n",
    "        \"zcr\",\n",
    "        \"rms\",\n",
    "        \"tempogram\",\n",
    "        \"tonnetz\",\n",
    "        \"delta_mfcc\",\n",
    "        \"delta_tempogram\",\n",
    "        \"hpss\",\n",
    "        \"cqt\",\n",
    "    ]\n",
    "\n",
    "    # Ustalenie, które cechy będą trenowane\n",
    "    feature_types_to_train = [feature_type] if feature_type else all_feature_types\n",
    "\n",
    "    # Tworzenie katalogów dla wyników\n",
    "    os.makedirs(results_base_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Słowniki do przechowywania wyników i czasów treningu\n",
    "    results = {}\n",
    "    training_times = {}\n",
    "\n",
    "    # Trening dla każdej cechy\n",
    "    for feat_type in feature_types_to_train:\n",
    "        # Sprawdzenie, czy istnieją wyniki dla danej cechy\n",
    "        feature_dir = os.path.join(results_base_dir, feat_type)\n",
    "\n",
    "        if (\n",
    "            skip_trained\n",
    "            and os.path.exists(feature_dir)\n",
    "            and len(os.listdir(feature_dir)) > 0\n",
    "        ):\n",
    "            print(\n",
    "                f\"\\nPomijanie cechy {feat_type.upper()} - znaleziono istniejące wyniki.\"\n",
    "            )\n",
    "\n",
    "            # Odczyt dokładności z istniejących wyników\n",
    "            accuracy = read_accuracy_from_results(feat_type, results_base_dir)\n",
    "            if accuracy:\n",
    "                results[feat_type] = accuracy\n",
    "                print(f\"Odczytana dokładność: {accuracy:.2f}%\")\n",
    "            continue\n",
    "\n",
    "        # Rozpoczęcie treningu dla danej cechy\n",
    "        print(f\"\\n{'=' * 50}\")\n",
    "        print(f\"Trening modelu na reprezentacji: {feat_type.upper()}\")\n",
    "        print(f\"{'=' * 50}\\n\")\n",
    "\n",
    "        # Pomiar czasu treningu\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Trening modelu\n",
    "        try:\n",
    "            (\n",
    "                model,\n",
    "                test_loader,\n",
    "                label_encoder,\n",
    "                history,\n",
    "                feature_dir,\n",
    "                feat_timestamp,\n",
    "                _,\n",
    "                training_time,\n",
    "            ) = train_model_for_feature(dataset, feat_type)\n",
    "\n",
    "            # Ewaluacja modelu\n",
    "            device = next(model.parameters()).device\n",
    "            accuracy, _ = evaluate_model(\n",
    "                model,\n",
    "                test_loader,\n",
    "                label_encoder,\n",
    "                history,\n",
    "                feature_dir,\n",
    "                feat_timestamp,\n",
    "                feat_type,\n",
    "                time.time() - start_time,\n",
    "                device,\n",
    "            )\n",
    "\n",
    "            results[feat_type] = accuracy\n",
    "            training_times[feat_type] = time.time() - start_time\n",
    "\n",
    "            print(\n",
    "                f\"\\nTrening dla {feat_type} zakończony sukcesem. Dokładność: {accuracy:.2f}%\"\n",
    "            )\n",
    "            print(f\"Czas treningu: {training_times[feat_type]:.2f} sekund\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nBłąd podczas treningu dla cechy {feat_type}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Generowanie raportu podsumowującego (tylko jeśli trenowano więcej niż jedną cechę)\n",
    "    if len(results) > 1:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"Wszystkie treningi zakończone. Generowanie raportu zbiorczego...\")\n",
    "        print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "        # Tworzenie DataFrame z wynikami\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"Feature Type\": list(results.keys()),\n",
    "                \"Test Accuracy (%)\": [results[ft] for ft in results.keys()],\n",
    "                \"Training Time (s)\": [\n",
    "                    training_times.get(ft, 0) for ft in results.keys()\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Sortowanie według dokładności\n",
    "        df = df.sort_values(\"Test Accuracy (%)\", ascending=False)\n",
    "\n",
    "        # Zapis do CSV\n",
    "        csv_path = os.path.join(results_base_dir, f\"accuracy_summary_{timestamp}.csv\")\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Zapisano podsumowanie do: {csv_path}\")\n",
    "\n",
    "        # Tworzenie wykresu dokładności przy użyciu Plotly\n",
    "        fig_accuracy = px.bar(\n",
    "            df,\n",
    "            x=\"Feature Type\",\n",
    "            y=\"Test Accuracy (%)\",\n",
    "            title=\"Porównanie dokładności dla różnych reprezentacji audio\",\n",
    "            color_discrete_sequence=[\"purple\"],\n",
    "        )\n",
    "\n",
    "        fig_accuracy.update_layout(\n",
    "            xaxis_title=\"Typ cechy\",\n",
    "            yaxis_title=\"Dokładność testu (%)\",\n",
    "            xaxis_tickangle=-45,\n",
    "            yaxis_range=[0, max(df[\"Test Accuracy (%)\"]) * 1.1],\n",
    "            template=\"plotly_white\",\n",
    "        )\n",
    "\n",
    "        # Dodanie wartości nad słupkami\n",
    "        fig_accuracy.update_traces(texttemplate=\"%{y:.1f}%\", textposition=\"outside\")\n",
    "\n",
    "        # Zapisanie wykresu dokładności\n",
    "        accuracy_plot_path = os.path.join(\n",
    "            results_base_dir, f\"accuracy_comparison_{timestamp}.html\"\n",
    "        )\n",
    "        fig_accuracy.write_html(accuracy_plot_path)\n",
    "\n",
    "        # Tworzenie wykresu czasu treningu przy użyciu Plotly\n",
    "        fig_time = px.bar(\n",
    "            df,\n",
    "            x=\"Feature Type\",\n",
    "            y=\"Training Time (s)\",\n",
    "            title=\"Porównanie czasu treningu dla różnych reprezentacji audio\",\n",
    "            color_discrete_sequence=[\"purple\"],  # Kolor fioletowy\n",
    "        )\n",
    "\n",
    "        fig_time.update_layout(\n",
    "            xaxis_title=\"Typ cechy\",\n",
    "            yaxis_title=\"Czas treningu (s)\",\n",
    "            xaxis_tickangle=-45,\n",
    "            yaxis_range=[0, max(df[\"Training Time (s)\"]) * 1.1],\n",
    "            template=\"plotly_white\",\n",
    "        )\n",
    "\n",
    "        # Dodanie wartości nad słupkami\n",
    "        fig_time.update_traces(texttemplate=\"%{y:.0f}s\", textposition=\"outside\")\n",
    "\n",
    "        # Zapisanie wykresu czasu treningu\n",
    "        time_plot_path = os.path.join(\n",
    "            results_base_dir, f\"training_time_comparison_{timestamp}.html\"\n",
    "        )\n",
    "        fig_time.write_html(time_plot_path)\n",
    "\n",
    "        fig_combined = make_subplots(\n",
    "            rows=1,\n",
    "            cols=2,\n",
    "            subplot_titles=(\n",
    "                \"Porównanie dokładności dla różnych reprezentacji audio\",\n",
    "                \"Porównanie czasu treningu dla różnych reprezentacji audio\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Dodanie słupków dokładności\n",
    "        fig_combined.add_trace(\n",
    "            go.Bar(\n",
    "                x=df[\"Feature Type\"],\n",
    "                y=df[\"Test Accuracy (%)\"],\n",
    "                text=df[\"Test Accuracy (%)\"].apply(lambda x: f\"{x:.1f}%\"),\n",
    "                textposition=\"outside\",\n",
    "                marker_color=\"purple\",\n",
    "                name=\"Dokładność\",\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Dodanie słupków czasu treningu\n",
    "        fig_combined.add_trace(\n",
    "            go.Bar(\n",
    "                x=df[\"Feature Type\"],\n",
    "                y=df[\"Training Time (s)\"],\n",
    "                text=df[\"Training Time (s)\"].apply(lambda x: f\"{int(x)}s\"),\n",
    "                textposition=\"outside\",\n",
    "                marker_color=\"purple\",\n",
    "                name=\"Czas treningu\",\n",
    "            ),\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "        # Aktualizacja układu\n",
    "        fig_combined.update_layout(\n",
    "            height=600, width=1200, showlegend=False, template=\"plotly_white\"\n",
    "        )\n",
    "\n",
    "        # Aktualizacja osi X i Y dla obu wykresów\n",
    "        fig_combined.update_xaxes(title_text=\"Typ cechy\", tickangle=-45, row=1, col=1)\n",
    "        fig_combined.update_xaxes(title_text=\"Typ cechy\", tickangle=-45, row=1, col=2)\n",
    "        fig_combined.update_yaxes(\n",
    "            title_text=\"Dokładność testu (%)\",\n",
    "            range=[0, max(df[\"Test Accuracy (%)\"]) * 1.1],\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "        fig_combined.update_yaxes(\n",
    "            title_text=\"Czas treningu (s)\",\n",
    "            range=[0, max(df[\"Training Time (s)\"]) * 1.1],\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "        # Zapisanie połączonego wykresu\n",
    "        combined_plot_path = os.path.join(\n",
    "            results_base_dir, f\"feature_comparison_{timestamp}.html\"\n",
    "        )\n",
    "        fig_combined.write_html(combined_plot_path)\n",
    "\n",
    "        print(\n",
    "            f\"Zapisano interaktywne wizualizacje do: {accuracy_plot_path}, {time_plot_path}, {combined_plot_path}\"\n",
    "        )\n",
    "        print(\"\\nPodsumowanie wyników:\")\n",
    "        print(df)\n",
    "\n",
    "        return df\n",
    "\n",
    "    # Zwrócenie wyniku dla pojedynczej cechy\n",
    "    elif len(results) == 1:\n",
    "        feature = list(results.keys())[0]\n",
    "        print(f\"\\nWynik dla cechy {feature}: {results[feature]:.2f}%\")\n",
    "        return results[feature]\n",
    "\n",
    "    # Informacja o braku przeprowadzonego treningu\n",
    "    else:\n",
    "        print(\"\\nNie przeprowadzono żadnego treningu.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchom trening dla wszystkich typów cech\n",
    "# results_df = run_training_experiment(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trening przeprowadzany wyłącznie dla melspektrogramu\n",
    "# accuracy = run_training_experiment(dataset, feature_type=\"chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = run_training_experiment(dataset, feature_type=\"melspectrogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = run_training_experiment(dataset, feature_type=\"mfcc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pomijanie cechy SPECTROGRAM - znaleziono istniejące wyniki.\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: MELSPECTROGRAM\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: melspectrogram...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Zastosowanie normalizacji datasetu dla cechy: melspectrogram\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 43.00 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\melspectrogram_53ee30be77b7cdc4bd886fd7c06dddfc.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: melspectrogram...\n",
      "Epoka 1/50, Strata treningu: 1.8975, Strata walidacji: 8.2423, Dokładność walidacji: 17.02%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250523_120505.pt\n",
      "Epoka 2/50, Strata treningu: 1.2981, Strata walidacji: 2.7703, Dokładność walidacji: 32.22%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250523_120505.pt\n",
      "Epoka 3/50, Strata treningu: 0.9970, Strata walidacji: 0.9707, Dokładność walidacji: 63.60%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250523_120505.pt\n",
      "Epoka 4/50, Strata treningu: 0.8474, Strata walidacji: 1.6916, Dokładność walidacji: 53.42%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 5/50, Strata treningu: 0.6562, Strata walidacji: 0.6531, Dokładność walidacji: 74.06%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250523_120505.pt\n",
      "Epoka 6/50, Strata treningu: 0.5141, Strata walidacji: 0.6144, Dokładność walidacji: 78.10%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250523_120505.pt\n",
      "Epoka 7/50, Strata treningu: 0.3933, Strata walidacji: 1.5857, Dokładność walidacji: 56.49%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 8/50, Strata treningu: 0.3197, Strata walidacji: 0.8120, Dokładność walidacji: 73.78%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 9/50, Strata treningu: 0.3099, Strata walidacji: 0.6848, Dokładność walidacji: 76.29%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 10/50, Strata treningu: 0.2138, Strata walidacji: 0.9631, Dokładność walidacji: 71.13%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 11/50, Strata treningu: 0.0986, Strata walidacji: 0.3416, Dokładność walidacji: 87.31%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250523_120505.pt\n",
      "Epoka 12/50, Strata treningu: 0.0331, Strata walidacji: 0.2985, Dokładność walidacji: 89.54%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250523_120505.pt\n",
      "Epoka 13/50, Strata treningu: 0.0256, Strata walidacji: 0.4438, Dokładność walidacji: 85.91%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 14/50, Strata treningu: 0.0277, Strata walidacji: 0.3801, Dokładność walidacji: 87.17%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 15/50, Strata treningu: 0.0261, Strata walidacji: 0.6391, Dokładność walidacji: 82.43%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 16/50, Strata treningu: 0.0404, Strata walidacji: 0.4509, Dokładność walidacji: 88.01%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 17/50, Strata treningu: 0.0178, Strata walidacji: 0.3013, Dokładność walidacji: 90.79%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 18/50, Strata treningu: 0.0102, Strata walidacji: 0.3210, Dokładność walidacji: 90.10%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 19/50, Strata treningu: 0.0076, Strata walidacji: 0.3399, Dokładność walidacji: 89.82%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 19 epokach. Czas: 887.34 sekund\n",
      "\n",
      "Trening dla melspectrogram zakończony sukcesem. Dokładność: 88.85%\n",
      "Czas treningu: 937.49 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: MFCC\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: mfcc...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "MFCC/delta_MFCC już znormalizowane metodą CMVN - pomijam normalizację datasetu\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 17.70 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\mfcc_de6bae255cca45e44a8891b16617e85d.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: mfcc...\n",
      "Epoka 1/50, Strata treningu: 1.9998, Strata walidacji: 2.6073, Dokładność walidacji: 34.17%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250523_122042.pt\n",
      "Epoka 2/50, Strata treningu: 1.2725, Strata walidacji: 1.8209, Dokładność walidacji: 39.33%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250523_122042.pt\n",
      "Epoka 3/50, Strata treningu: 0.9349, Strata walidacji: 3.6715, Dokładność walidacji: 31.80%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 4/50, Strata treningu: 0.7153, Strata walidacji: 1.6998, Dokładność walidacji: 52.30%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250523_122042.pt\n",
      "Epoka 5/50, Strata treningu: 0.4760, Strata walidacji: 1.7097, Dokładność walidacji: 52.02%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 6/50, Strata treningu: 0.3410, Strata walidacji: 3.4291, Dokładność walidacji: 46.58%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 7/50, Strata treningu: 0.3739, Strata walidacji: 1.5535, Dokładność walidacji: 56.90%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250523_122042.pt\n",
      "Epoka 8/50, Strata treningu: 0.2488, Strata walidacji: 1.4773, Dokładność walidacji: 57.32%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250523_122042.pt\n",
      "Epoka 9/50, Strata treningu: 0.1627, Strata walidacji: 2.6610, Dokładność walidacji: 49.09%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 10/50, Strata treningu: 0.1298, Strata walidacji: 2.9007, Dokładność walidacji: 44.91%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 11/50, Strata treningu: 0.1316, Strata walidacji: 1.6555, Dokładność walidacji: 63.04%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 12/50, Strata treningu: 0.0960, Strata walidacji: 2.5738, Dokładność walidacji: 55.65%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 13/50, Strata treningu: 0.0497, Strata walidacji: 1.3232, Dokładność walidacji: 68.34%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250523_122042.pt\n",
      "Epoka 14/50, Strata treningu: 0.0209, Strata walidacji: 1.1343, Dokładność walidacji: 70.99%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250523_122042.pt\n",
      "Epoka 15/50, Strata treningu: 0.0149, Strata walidacji: 1.1346, Dokładność walidacji: 72.11%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 16/50, Strata treningu: 0.0091, Strata walidacji: 1.2006, Dokładność walidacji: 70.01%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 17/50, Strata treningu: 0.0073, Strata walidacji: 1.3868, Dokładność walidacji: 69.04%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 18/50, Strata treningu: 0.0158, Strata walidacji: 1.2667, Dokładność walidacji: 70.85%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 19/50, Strata treningu: 0.0089, Strata walidacji: 1.1630, Dokładność walidacji: 70.71%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 20/50, Strata treningu: 0.0038, Strata walidacji: 1.2505, Dokładność walidacji: 70.99%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 21/50, Strata treningu: 0.0048, Strata walidacji: 1.2741, Dokładność walidacji: 71.97%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 21 epokach. Czas: 359.07 sekund\n",
      "\n",
      "Trening dla mfcc zakończony sukcesem. Dokładność: 71.24%\n",
      "Czas treningu: 379.69 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: CHROMA\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: chroma...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Zastosowanie normalizacji datasetu dla cechy: chroma\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 22.22 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\chroma_f7c54044e13af32ceb625a21ae0ad422.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: chroma...\n",
      "Epoka 1/50, Strata treningu: 2.1484, Strata walidacji: 1.4891, Dokładność walidacji: 42.82%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\chroma\\best_model_chroma_20250523_122702.pt\n",
      "Epoka 2/50, Strata treningu: 1.5667, Strata walidacji: 1.8296, Dokładność walidacji: 34.31%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 3/50, Strata treningu: 1.2902, Strata walidacji: 1.5741, Dokładność walidacji: 46.72%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 4/50, Strata treningu: 1.1129, Strata walidacji: 1.3135, Dokładność walidacji: 50.49%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\chroma\\best_model_chroma_20250523_122702.pt\n",
      "Epoka 5/50, Strata treningu: 0.9752, Strata walidacji: 1.7714, Dokładność walidacji: 45.33%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 6/50, Strata treningu: 0.8122, Strata walidacji: 1.5574, Dokładność walidacji: 49.93%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 7/50, Strata treningu: 0.6940, Strata walidacji: 1.8348, Dokładność walidacji: 48.68%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 8/50, Strata treningu: 0.5686, Strata walidacji: 1.5518, Dokładność walidacji: 52.58%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 9/50, Strata treningu: 0.3136, Strata walidacji: 1.5363, Dokładność walidacji: 58.58%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 10/50, Strata treningu: 0.1197, Strata walidacji: 1.8327, Dokładność walidacji: 58.86%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 11/50, Strata treningu: 0.1203, Strata walidacji: 1.8215, Dokładność walidacji: 55.37%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 11 epokach. Czas: 90.96 sekund\n",
      "\n",
      "Trening dla chroma zakończony sukcesem. Dokładność: 49.50%\n",
      "Czas treningu: 114.98 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: SPECTRAL_CONTRAST\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: spectral_contrast...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Zastosowanie normalizacji datasetu dla cechy: spectral_contrast\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 12.18 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\spectral_contrast_c67aaf46a546d07787a9bc50c190a605.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: spectral_contrast...\n",
      "Epoka 1/50, Strata treningu: 2.3511, Strata walidacji: 1.6758, Dokładność walidacji: 32.36%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectral_contrast\\best_model_spectral_contrast_20250523_122857.pt\n",
      "Epoka 2/50, Strata treningu: 1.8196, Strata walidacji: 1.7041, Dokładność walidacji: 36.68%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 3/50, Strata treningu: 1.5815, Strata walidacji: 1.5059, Dokładność walidacji: 36.40%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectral_contrast\\best_model_spectral_contrast_20250523_122857.pt\n",
      "Epoka 4/50, Strata treningu: 1.3625, Strata walidacji: 1.4794, Dokładność walidacji: 40.86%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectral_contrast\\best_model_spectral_contrast_20250523_122857.pt\n",
      "Epoka 5/50, Strata treningu: 1.2321, Strata walidacji: 1.7731, Dokładność walidacji: 38.08%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 6/50, Strata treningu: 1.1152, Strata walidacji: 1.6137, Dokładność walidacji: 40.31%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 7/50, Strata treningu: 0.9598, Strata walidacji: 1.5741, Dokładność walidacji: 41.14%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 8/50, Strata treningu: 0.7823, Strata walidacji: 1.6828, Dokładność walidacji: 42.12%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 9/50, Strata treningu: 0.4365, Strata walidacji: 2.0136, Dokładność walidacji: 45.47%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 10/50, Strata treningu: 0.2706, Strata walidacji: 2.1957, Dokładność walidacji: 44.91%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 11/50, Strata treningu: 0.2577, Strata walidacji: 2.2790, Dokładność walidacji: 42.68%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 11 epokach. Czas: 86.84 sekund\n",
      "\n",
      "Trening dla spectral_contrast zakończony sukcesem. Dokładność: 43.03%\n",
      "Czas treningu: 100.64 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: ZCR\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: zcr...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Zastosowanie normalizacji datasetu dla cechy: zcr\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 12.44 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\zcr_1bb58748091eb5860417275cc92ce18f.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: zcr...\n",
      "Epoka 1/50, Strata treningu: 2.3081, Strata walidacji: 1.8515, Dokładność walidacji: 18.69%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\zcr\\best_model_zcr_20250523_123037.pt\n",
      "Epoka 2/50, Strata treningu: 1.9659, Strata walidacji: 1.7927, Dokładność walidacji: 19.25%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\zcr\\best_model_zcr_20250523_123037.pt\n",
      "Epoka 3/50, Strata treningu: 1.8419, Strata walidacji: 1.7853, Dokładność walidacji: 23.15%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\zcr\\best_model_zcr_20250523_123037.pt\n",
      "Epoka 4/50, Strata treningu: 1.8052, Strata walidacji: 1.7296, Dokładność walidacji: 22.18%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\zcr\\best_model_zcr_20250523_123037.pt\n",
      "Epoka 5/50, Strata treningu: 1.7567, Strata walidacji: 1.7238, Dokładność walidacji: 27.06%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\zcr\\best_model_zcr_20250523_123037.pt\n",
      "Epoka 6/50, Strata treningu: 1.7467, Strata walidacji: 1.7470, Dokładność walidacji: 27.48%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 7/50, Strata treningu: 1.7281, Strata walidacji: 1.7118, Dokładność walidacji: 25.24%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\zcr\\best_model_zcr_20250523_123037.pt\n",
      "Epoka 8/50, Strata treningu: 1.6948, Strata walidacji: 1.8681, Dokładność walidacji: 24.97%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 9/50, Strata treningu: 1.6728, Strata walidacji: 2.0435, Dokładność walidacji: 22.73%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 10/50, Strata treningu: 1.6597, Strata walidacji: 1.8916, Dokładność walidacji: 21.90%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 11/50, Strata treningu: 1.6414, Strata walidacji: 1.7166, Dokładność walidacji: 24.27%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 12/50, Strata treningu: 1.5702, Strata walidacji: 1.7040, Dokładność walidacji: 28.73%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\zcr\\best_model_zcr_20250523_123037.pt\n",
      "Epoka 13/50, Strata treningu: 1.5077, Strata walidacji: 1.7732, Dokładność walidacji: 27.06%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 14/50, Strata treningu: 1.4852, Strata walidacji: 1.7632, Dokładność walidacji: 26.36%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 15/50, Strata treningu: 1.4259, Strata walidacji: 1.8281, Dokładność walidacji: 26.36%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 16/50, Strata treningu: 1.3643, Strata walidacji: 1.9721, Dokładność walidacji: 25.24%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 17/50, Strata treningu: 1.1339, Strata walidacji: 2.0475, Dokładność walidacji: 29.57%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 18/50, Strata treningu: 0.9739, Strata walidacji: 2.2918, Dokładność walidacji: 26.78%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 19/50, Strata treningu: 0.8514, Strata walidacji: 2.3780, Dokładność walidacji: 24.83%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 19 epokach. Czas: 851.62 sekund\n",
      "\n",
      "Trening dla zcr zakończony sukcesem. Dokładność: 27.87%\n",
      "Czas treningu: 870.74 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: RMS\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: rms...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Zastosowanie normalizacji datasetu dla cechy: rms\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 16.86 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\rms_0f95119d57261dd135d27ffb480e633b.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: rms...\n",
      "Epoka 1/50, Strata treningu: 2.1566, Strata walidacji: 1.8769, Dokładność walidacji: 24.13%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\rms\\best_model_rms_20250523_124508.pt\n",
      "Epoka 2/50, Strata treningu: 1.8607, Strata walidacji: 1.8283, Dokładność walidacji: 23.29%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\rms\\best_model_rms_20250523_124508.pt\n",
      "Epoka 3/50, Strata treningu: 1.7746, Strata walidacji: 1.7779, Dokładność walidacji: 24.69%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\rms\\best_model_rms_20250523_124508.pt\n",
      "Epoka 4/50, Strata treningu: 1.7259, Strata walidacji: 1.6963, Dokładność walidacji: 28.31%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\rms\\best_model_rms_20250523_124508.pt\n",
      "Epoka 5/50, Strata treningu: 1.6935, Strata walidacji: 1.7334, Dokładność walidacji: 26.36%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 6/50, Strata treningu: 1.6635, Strata walidacji: 1.7296, Dokładność walidacji: 28.17%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 7/50, Strata treningu: 1.6310, Strata walidacji: 1.8241, Dokładność walidacji: 26.08%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 8/50, Strata treningu: 1.5914, Strata walidacji: 1.7996, Dokładność walidacji: 28.45%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 9/50, Strata treningu: 1.5227, Strata walidacji: 1.6629, Dokładność walidacji: 30.82%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\rms\\best_model_rms_20250523_124508.pt\n",
      "Epoka 10/50, Strata treningu: 1.4814, Strata walidacji: 1.7440, Dokładność walidacji: 30.26%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 11/50, Strata treningu: 1.4219, Strata walidacji: 1.6677, Dokładność walidacji: 32.91%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 12/50, Strata treningu: 1.3802, Strata walidacji: 1.7156, Dokładność walidacji: 31.94%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 13/50, Strata treningu: 1.3533, Strata walidacji: 1.7492, Dokładność walidacji: 30.96%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 14/50, Strata treningu: 1.1287, Strata walidacji: 2.1024, Dokładność walidacji: 30.26%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 15/50, Strata treningu: 1.0046, Strata walidacji: 2.0303, Dokładność walidacji: 29.15%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 16/50, Strata treningu: 0.8470, Strata walidacji: 2.2727, Dokładność walidacji: 31.10%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 16 epokach. Czas: 737.33 sekund\n",
      "\n",
      "Trening dla rms zakończony sukcesem. Dokładność: 34.34%\n",
      "Czas treningu: 760.48 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: TEMPOGRAM\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: tempogram...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Zastosowanie normalizacji datasetu dla cechy: tempogram\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 36.30 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\tempogram_0fa2708c9788e12fe31c7b96ae59978d.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: tempogram...\n",
      "Epoka 1/50, Strata treningu: 2.1025, Strata walidacji: 2.8752, Dokładność walidacji: 16.60%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250523_125749.pt\n",
      "Epoka 2/50, Strata treningu: 1.8806, Strata walidacji: 1.8330, Dokładność walidacji: 19.25%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250523_125749.pt\n",
      "Epoka 3/50, Strata treningu: 1.8433, Strata walidacji: 1.8442, Dokładność walidacji: 22.45%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 4/50, Strata treningu: 1.8023, Strata walidacji: 2.0478, Dokładność walidacji: 21.48%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 5/50, Strata treningu: 1.7971, Strata walidacji: 1.7764, Dokładność walidacji: 22.59%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250523_125749.pt\n",
      "Epoka 6/50, Strata treningu: 1.7810, Strata walidacji: 1.8407, Dokładność walidacji: 21.62%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 7/50, Strata treningu: 1.7792, Strata walidacji: 1.8242, Dokładność walidacji: 25.94%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 8/50, Strata treningu: 1.7791, Strata walidacji: 1.7669, Dokładność walidacji: 22.32%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250523_125749.pt\n",
      "Epoka 9/50, Strata treningu: 1.7709, Strata walidacji: 1.8942, Dokładność walidacji: 21.34%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 10/50, Strata treningu: 1.7669, Strata walidacji: 1.7941, Dokładność walidacji: 18.41%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 11/50, Strata treningu: 1.7590, Strata walidacji: 1.8892, Dokładność walidacji: 20.92%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 12/50, Strata treningu: 1.7652, Strata walidacji: 1.7697, Dokładność walidacji: 24.13%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 13/50, Strata treningu: 1.7484, Strata walidacji: 1.7535, Dokładność walidacji: 22.59%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250523_125749.pt\n",
      "Epoka 14/50, Strata treningu: 1.7509, Strata walidacji: 1.7689, Dokładność walidacji: 22.59%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 15/50, Strata treningu: 1.7392, Strata walidacji: 1.7570, Dokładność walidacji: 24.55%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 16/50, Strata treningu: 1.7386, Strata walidacji: 1.7536, Dokładność walidacji: 26.08%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 17/50, Strata treningu: 1.7377, Strata walidacji: 1.7543, Dokładność walidacji: 24.69%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 18/50, Strata treningu: 1.7216, Strata walidacji: 1.7548, Dokładność walidacji: 24.27%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 19/50, Strata treningu: 1.7021, Strata walidacji: 1.7491, Dokładność walidacji: 25.24%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250523_125749.pt\n",
      "Epoka 20/50, Strata treningu: 1.7031, Strata walidacji: 1.7356, Dokładność walidacji: 26.22%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250523_125749.pt\n",
      "Epoka 21/50, Strata treningu: 1.6955, Strata walidacji: 1.7824, Dokładność walidacji: 23.99%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 22/50, Strata treningu: 1.6960, Strata walidacji: 1.8242, Dokładność walidacji: 18.55%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 23/50, Strata treningu: 1.6837, Strata walidacji: 1.7846, Dokładność walidacji: 24.41%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 24/50, Strata treningu: 1.6776, Strata walidacji: 1.7345, Dokładność walidacji: 25.10%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250523_125749.pt\n",
      "Epoka 25/50, Strata treningu: 1.6818, Strata walidacji: 1.7331, Dokładność walidacji: 25.66%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250523_125749.pt\n",
      "Epoka 26/50, Strata treningu: 1.6638, Strata walidacji: 1.7481, Dokładność walidacji: 28.03%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 27/50, Strata treningu: 1.6452, Strata walidacji: 1.7364, Dokładność walidacji: 26.08%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 28/50, Strata treningu: 1.6349, Strata walidacji: 1.7994, Dokładność walidacji: 25.52%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 29/50, Strata treningu: 1.6318, Strata walidacji: 1.7345, Dokładność walidacji: 26.64%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 30/50, Strata treningu: 1.5750, Strata walidacji: 1.8791, Dokładność walidacji: 27.48%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 31/50, Strata treningu: 1.5563, Strata walidacji: 1.7592, Dokładność walidacji: 28.17%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 32/50, Strata treningu: 1.5129, Strata walidacji: 1.7804, Dokładność walidacji: 25.66%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 32 epokach. Czas: 4147.19 sekund\n",
      "\n",
      "Trening dla tempogram zakończony sukcesem. Dokładność: 22.74%\n",
      "Czas treningu: 4210.68 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: TONNETZ\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: tonnetz...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Zastosowanie normalizacji datasetu dla cechy: tonnetz\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 248.68 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\tonnetz_7167c47d6c727ab781906e64fa4abba3.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: tonnetz...\n",
      "Epoka 1/50, Strata treningu: 2.4087, Strata walidacji: 1.7532, Dokładność walidacji: 26.92%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tonnetz\\best_model_tonnetz_20250523_140759.pt\n",
      "Epoka 2/50, Strata treningu: 1.8333, Strata walidacji: 1.8799, Dokładność walidacji: 28.59%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 3/50, Strata treningu: 1.7356, Strata walidacji: 1.6753, Dokładność walidacji: 35.15%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tonnetz\\best_model_tonnetz_20250523_140759.pt\n",
      "Epoka 4/50, Strata treningu: 1.5098, Strata walidacji: 1.5672, Dokładność walidacji: 36.40%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tonnetz\\best_model_tonnetz_20250523_140759.pt\n",
      "Epoka 5/50, Strata treningu: 1.4058, Strata walidacji: 1.5805, Dokładność walidacji: 36.26%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 6/50, Strata treningu: 1.3118, Strata walidacji: 1.8813, Dokładność walidacji: 35.70%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 7/50, Strata treningu: 1.1987, Strata walidacji: 1.6860, Dokładność walidacji: 37.80%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 8/50, Strata treningu: 1.0814, Strata walidacji: 1.9847, Dokładność walidacji: 35.84%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 9/50, Strata treningu: 0.5730, Strata walidacji: 2.3634, Dokładność walidacji: 39.05%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 10/50, Strata treningu: 0.3904, Strata walidacji: 2.3449, Dokładność walidacji: 35.43%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 11/50, Strata treningu: 0.3499, Strata walidacji: 2.6082, Dokładność walidacji: 36.40%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 11 epokach. Czas: 152.04 sekund\n",
      "\n",
      "Trening dla tonnetz zakończony sukcesem. Dokładność: 36.57%\n",
      "Czas treningu: 403.50 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: DELTA_MFCC\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: delta_mfcc...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "MFCC/delta_MFCC już znormalizowane metodą CMVN - pomijam normalizację datasetu\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 21.69 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\delta_mfcc_d569b0771144337dc2547e81c8ebe308.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: delta_mfcc...\n",
      "Epoka 1/50, Strata treningu: 2.0545, Strata walidacji: 1.5543, Dokładność walidacji: 36.82%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_mfcc\\best_model_delta_mfcc_20250523_141443.pt\n",
      "Epoka 2/50, Strata treningu: 1.4206, Strata walidacji: 1.7823, Dokładność walidacji: 38.63%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 3/50, Strata treningu: 1.0957, Strata walidacji: 2.8097, Dokładność walidacji: 30.82%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 4/50, Strata treningu: 0.7720, Strata walidacji: 1.7495, Dokładność walidacji: 48.95%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 5/50, Strata treningu: 0.5347, Strata walidacji: 2.7046, Dokładność walidacji: 39.61%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 6/50, Strata treningu: 0.2523, Strata walidacji: 2.0366, Dokładność walidacji: 52.86%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 7/50, Strata treningu: 0.0708, Strata walidacji: 1.7567, Dokładność walidacji: 59.14%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 8/50, Strata treningu: 0.0386, Strata walidacji: 2.0456, Dokładność walidacji: 58.30%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 8 epokach. Czas: 229.30 sekund\n",
      "\n",
      "Trening dla delta_mfcc zakończony sukcesem. Dokładność: 37.79%\n",
      "Czas treningu: 255.28 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: DELTA_TEMPOGRAM\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: delta_tempogram...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Zastosowanie normalizacji datasetu dla cechy: delta_tempogram\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 44.23 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\delta_tempogram_27ff0d1000b7677f7601949700eb5524.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: delta_tempogram...\n",
      "Epoka 1/50, Strata treningu: 2.1277, Strata walidacji: 1.8365, Dokładność walidacji: 19.39%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_tempogram\\best_model_delta_tempogram_20250523_141858.pt\n",
      "Epoka 2/50, Strata treningu: 1.8959, Strata walidacji: 1.7931, Dokładność walidacji: 17.85%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_tempogram\\best_model_delta_tempogram_20250523_141858.pt\n",
      "Epoka 3/50, Strata treningu: 1.8455, Strata walidacji: 1.8148, Dokładność walidacji: 18.83%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 4/50, Strata treningu: 1.8319, Strata walidacji: 1.7814, Dokładność walidacji: 19.39%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_tempogram\\best_model_delta_tempogram_20250523_141858.pt\n",
      "Epoka 5/50, Strata treningu: 1.8125, Strata walidacji: 1.7830, Dokładność walidacji: 20.08%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 6/50, Strata treningu: 1.8086, Strata walidacji: 1.7816, Dokładność walidacji: 22.04%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 7/50, Strata treningu: 1.8018, Strata walidacji: 1.7834, Dokładność walidacji: 20.50%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 8/50, Strata treningu: 1.7868, Strata walidacji: 1.7797, Dokładność walidacji: 19.67%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_tempogram\\best_model_delta_tempogram_20250523_141858.pt\n",
      "Epoka 9/50, Strata treningu: 1.7892, Strata walidacji: 1.7636, Dokładność walidacji: 21.90%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_tempogram\\best_model_delta_tempogram_20250523_141858.pt\n",
      "Epoka 10/50, Strata treningu: 1.7822, Strata walidacji: 1.7687, Dokładność walidacji: 22.73%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 11/50, Strata treningu: 1.7806, Strata walidacji: 1.7695, Dokładność walidacji: 22.87%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 12/50, Strata treningu: 1.7742, Strata walidacji: 1.7723, Dokładność walidacji: 20.92%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 13/50, Strata treningu: 1.7590, Strata walidacji: 1.7736, Dokładność walidacji: 21.06%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 14/50, Strata treningu: 1.7485, Strata walidacji: 1.7643, Dokładność walidacji: 22.32%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 15/50, Strata treningu: 1.7458, Strata walidacji: 1.7940, Dokładność walidacji: 21.62%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 16/50, Strata treningu: 1.7399, Strata walidacji: 1.7795, Dokładność walidacji: 20.78%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 16 epokach. Czas: 2597.35 sekund\n",
      "\n",
      "Trening dla delta_tempogram zakończony sukcesem. Dokładność: 22.07%\n",
      "Czas treningu: 2664.88 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: HPSS\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: hpss...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Zastosowanie normalizacji datasetu dla cechy: hpss\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 134.35 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\hpss_9a2142f8b9d0ffa7f227272f64dcdd92.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: hpss...\n",
      "Epoka 1/50, Strata treningu: 1.8415, Strata walidacji: 2.2964, Dokładność walidacji: 41.84%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\hpss\\best_model_hpss_20250523_150323.pt\n",
      "Epoka 2/50, Strata treningu: 1.2334, Strata walidacji: 1.5542, Dokładność walidacji: 45.19%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\hpss\\best_model_hpss_20250523_150323.pt\n",
      "Epoka 3/50, Strata treningu: 0.9477, Strata walidacji: 0.9479, Dokładność walidacji: 67.92%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\hpss\\best_model_hpss_20250523_150323.pt\n",
      "Epoka 4/50, Strata treningu: 0.7157, Strata walidacji: 1.0515, Dokładność walidacji: 64.30%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 5/50, Strata treningu: 0.5758, Strata walidacji: 1.0270, Dokładność walidacji: 64.30%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 6/50, Strata treningu: 0.4863, Strata walidacji: 0.6486, Dokładność walidacji: 76.57%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\hpss\\best_model_hpss_20250523_150323.pt\n",
      "Epoka 7/50, Strata treningu: 0.3895, Strata walidacji: 1.3197, Dokładność walidacji: 63.04%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 8/50, Strata treningu: 0.2971, Strata walidacji: 0.8837, Dokładność walidacji: 74.76%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 9/50, Strata treningu: 0.3235, Strata walidacji: 1.5476, Dokładność walidacji: 63.18%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 10/50, Strata treningu: 0.2724, Strata walidacji: 0.9127, Dokładność walidacji: 74.76%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 11/50, Strata treningu: 0.1343, Strata walidacji: 0.3592, Dokładność walidacji: 87.87%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\hpss\\best_model_hpss_20250523_150323.pt\n",
      "Epoka 12/50, Strata treningu: 0.0500, Strata walidacji: 0.3346, Dokładność walidacji: 87.45%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\hpss\\best_model_hpss_20250523_150323.pt\n",
      "Epoka 13/50, Strata treningu: 0.0428, Strata walidacji: 0.4482, Dokładność walidacji: 86.89%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 14/50, Strata treningu: 0.0559, Strata walidacji: 0.4309, Dokładność walidacji: 88.01%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 15/50, Strata treningu: 0.0468, Strata walidacji: 0.5968, Dokładność walidacji: 84.38%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 16/50, Strata treningu: 0.0664, Strata walidacji: 0.3826, Dokładność walidacji: 88.70%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 17/50, Strata treningu: 0.0192, Strata walidacji: 0.3102, Dokładność walidacji: 91.77%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\hpss\\best_model_hpss_20250523_150323.pt\n",
      "Epoka 18/50, Strata treningu: 0.0100, Strata walidacji: 0.2753, Dokładność walidacji: 91.77%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\hpss\\best_model_hpss_20250523_150323.pt\n",
      "Epoka 19/50, Strata treningu: 0.0167, Strata walidacji: 0.3735, Dokładność walidacji: 88.28%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 20/50, Strata treningu: 0.0126, Strata walidacji: 0.3133, Dokładność walidacji: 89.96%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 21/50, Strata treningu: 0.0254, Strata walidacji: 0.3822, Dokładność walidacji: 87.73%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 22/50, Strata treningu: 0.0092, Strata walidacji: 0.3502, Dokładność walidacji: 89.54%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 23/50, Strata treningu: 0.0065, Strata walidacji: 0.2736, Dokładność walidacji: 92.47%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\hpss\\best_model_hpss_20250523_150323.pt\n",
      "Epoka 24/50, Strata treningu: 0.0050, Strata walidacji: 0.2833, Dokładność walidacji: 92.19%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 25/50, Strata treningu: 0.0041, Strata walidacji: 0.2591, Dokładność walidacji: 92.19%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\hpss\\best_model_hpss_20250523_150323.pt\n",
      "Epoka 26/50, Strata treningu: 0.0022, Strata walidacji: 0.2633, Dokładność walidacji: 92.61%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 27/50, Strata treningu: 0.0027, Strata walidacji: 0.2788, Dokładność walidacji: 92.05%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 28/50, Strata treningu: 0.0020, Strata walidacji: 0.2665, Dokładność walidacji: 91.63%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 29/50, Strata treningu: 0.0014, Strata walidacji: 0.2561, Dokładność walidacji: 92.05%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\hpss\\best_model_hpss_20250523_150323.pt\n",
      "Epoka 30/50, Strata treningu: 0.0028, Strata walidacji: 0.2948, Dokładność walidacji: 91.49%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 31/50, Strata treningu: 0.0021, Strata walidacji: 0.2769, Dokładność walidacji: 91.49%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 32/50, Strata treningu: 0.0019, Strata walidacji: 0.2757, Dokładność walidacji: 91.21%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 33/50, Strata treningu: 0.0015, Strata walidacji: 0.2872, Dokładność walidacji: 91.77%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 34/50, Strata treningu: 0.0016, Strata walidacji: 0.2875, Dokładność walidacji: 91.91%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 35/50, Strata treningu: 0.0009, Strata walidacji: 0.2719, Dokładność walidacji: 92.05%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 36/50, Strata treningu: 0.0013, Strata walidacji: 0.2700, Dokładność walidacji: 92.19%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 36 epokach. Czas: 2061.86 sekund\n",
      "\n",
      "Trening dla hpss zakończony sukcesem. Dokładność: 93.20%\n",
      "Czas treningu: 2205.50 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: CQT\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: cqt...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Zastosowanie normalizacji datasetu dla cechy: cqt\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 46.44 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\cqt_6f9ae6afaf9dc5f29cdf3cc598b84fa5.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: cqt...\n",
      "Epoka 1/50, Strata treningu: 1.8026, Strata walidacji: 1.6993, Dokładność walidacji: 41.00%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\cqt\\best_model_cqt_20250523_154008.pt\n",
      "Epoka 2/50, Strata treningu: 1.1280, Strata walidacji: 1.3371, Dokładność walidacji: 54.81%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\cqt\\best_model_cqt_20250523_154008.pt\n",
      "Epoka 3/50, Strata treningu: 0.9020, Strata walidacji: 1.4189, Dokładność walidacji: 53.97%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 4/50, Strata treningu: 0.7029, Strata walidacji: 1.2419, Dokładność walidacji: 57.18%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\cqt\\best_model_cqt_20250523_154008.pt\n",
      "Epoka 5/50, Strata treningu: 0.6574, Strata walidacji: 0.7022, Dokładność walidacji: 75.45%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\cqt\\best_model_cqt_20250523_154008.pt\n",
      "Epoka 6/50, Strata treningu: 0.5251, Strata walidacji: 1.8266, Dokładność walidacji: 56.76%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 7/50, Strata treningu: 0.4565, Strata walidacji: 0.7008, Dokładność walidacji: 74.76%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\cqt\\best_model_cqt_20250523_154008.pt\n",
      "Epoka 8/50, Strata treningu: 0.3526, Strata walidacji: 1.3062, Dokładność walidacji: 64.99%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 9/50, Strata treningu: 0.3079, Strata walidacji: 1.5280, Dokładność walidacji: 61.51%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 10/50, Strata treningu: 0.2578, Strata walidacji: 0.9538, Dokładność walidacji: 75.45%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 11/50, Strata treningu: 0.2019, Strata walidacji: 1.2347, Dokładność walidacji: 68.34%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 12/50, Strata treningu: 0.0766, Strata walidacji: 0.5306, Dokładność walidacji: 85.08%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\cqt\\best_model_cqt_20250523_154008.pt\n",
      "Epoka 13/50, Strata treningu: 0.0278, Strata walidacji: 0.5518, Dokładność walidacji: 85.77%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 14/50, Strata treningu: 0.0214, Strata walidacji: 0.5370, Dokładność walidacji: 83.96%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 15/50, Strata treningu: 0.0174, Strata walidacji: 0.6627, Dokładność walidacji: 83.82%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 16/50, Strata treningu: 0.0151, Strata walidacji: 0.5981, Dokładność walidacji: 83.96%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 17/50, Strata treningu: 0.0114, Strata walidacji: 0.5015, Dokładność walidacji: 85.08%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\cqt\\best_model_cqt_20250523_154008.pt\n",
      "Epoka 18/50, Strata treningu: 0.0156, Strata walidacji: 0.5578, Dokładność walidacji: 86.61%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 19/50, Strata treningu: 0.0046, Strata walidacji: 0.5442, Dokładność walidacji: 86.19%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 20/50, Strata treningu: 0.0022, Strata walidacji: 0.5126, Dokładność walidacji: 86.75%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 21/50, Strata treningu: 0.0020, Strata walidacji: 0.5224, Dokładność walidacji: 86.19%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 22/50, Strata treningu: 0.0019, Strata walidacji: 0.5221, Dokładność walidacji: 86.05%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 23/50, Strata treningu: 0.0018, Strata walidacji: 0.5484, Dokładność walidacji: 86.75%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 24/50, Strata treningu: 0.0023, Strata walidacji: 0.5001, Dokładność walidacji: 86.89%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\cqt\\best_model_cqt_20250523_154008.pt\n",
      "Epoka 25/50, Strata treningu: 0.0017, Strata walidacji: 0.4907, Dokładność walidacji: 87.31%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\cqt\\best_model_cqt_20250523_154008.pt\n",
      "Epoka 26/50, Strata treningu: 0.0015, Strata walidacji: 0.4974, Dokładność walidacji: 87.31%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 27/50, Strata treningu: 0.0012, Strata walidacji: 0.5321, Dokładność walidacji: 85.50%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 28/50, Strata treningu: 0.0012, Strata walidacji: 0.5026, Dokładność walidacji: 86.75%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 29/50, Strata treningu: 0.0009, Strata walidacji: 0.5222, Dokładność walidacji: 87.59%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 30/50, Strata treningu: 0.0012, Strata walidacji: 0.5149, Dokładność walidacji: 86.47%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 31/50, Strata treningu: 0.0008, Strata walidacji: 0.5218, Dokładność walidacji: 86.75%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 32/50, Strata treningu: 0.0009, Strata walidacji: 0.5251, Dokładność walidacji: 85.91%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 32 epokach. Czas: 1192.24 sekund\n",
      "\n",
      "Trening dla cqt zakończony sukcesem. Dokładność: 86.40%\n",
      "Czas treningu: 1244.00 sekund\n",
      "\n",
      "==================================================\n",
      "Wszystkie treningi zakończone. Generowanie raportu zbiorczego...\n",
      "==================================================\n",
      "\n",
      "Zapisano podsumowanie do: feature_comparison_results\\accuracy_summary_20250523_120505.csv\n",
      "Zapisano interaktywne wizualizacje do: feature_comparison_results\\accuracy_comparison_20250523_120505.html, feature_comparison_results\\training_time_comparison_20250523_120505.html, feature_comparison_results\\feature_comparison_20250523_120505.html\n",
      "\n",
      "Podsumowanie wyników:\n",
      "         Feature Type  Test Accuracy (%)  Training Time (s)\n",
      "10               hpss          93.199554        2205.504406\n",
      "0      melspectrogram          88.851728         937.489439\n",
      "11                cqt          86.399108        1243.996090\n",
      "1                mfcc          71.237458         379.690132\n",
      "2              chroma          49.498328         114.978851\n",
      "3   spectral_contrast          43.032330         100.636407\n",
      "8          delta_mfcc          37.792642         255.281821\n",
      "7             tonnetz          36.566332         403.499856\n",
      "5                 rms          34.336678         760.479113\n",
      "4                 zcr          27.870680         870.742069\n",
      "6           tempogram          22.742475        4210.679155\n",
      "9     delta_tempogram          22.073579        2664.882107\n"
     ]
    }
   ],
   "source": [
    "# Rozpoczyna trening, pomijając cechy, dla których wyniki są już dostępne\n",
    "results_df = run_training_experiment(dataset, skip_trained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generowanie Wizualizacji Wyników Analizy\n",
    "\n",
    " Funkcja `generate_all_visualizations` automatycznie generuje i zapisuje wizualizacje wyników analizy różnych cech audio. Funkcja wyszukuje katalog z wynikami, odczytuje dane dotyczące dokładności i emocji, sortuje wyniki według dokładności, zapisuje je do plików CSV oraz tworzy wykresy porównawcze i wizualizacje emocji, zapisując je w odpowiednich lokalizacjach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Znalezione wyniki dokładności:\n",
      "         Feature Type  Test Accuracy (%)  Training Time (s)\n",
      "4                hpss          93.199554        2199.296314\n",
      "5      melspectrogram          88.851728         932.379515\n",
      "9         spectrogram          86.510591       14884.568313\n",
      "1                 cqt          86.399108        1240.278840\n",
      "6                mfcc          71.237458         377.691140\n",
      "0              chroma          49.498328         113.689844\n",
      "8   spectral_contrast          43.032330          99.525570\n",
      "2          delta_mfcc          37.792642         252.201571\n",
      "11            tonnetz          36.566332         401.704787\n",
      "7                 rms          34.336678         755.930766\n",
      "12                zcr          27.870680         866.040243\n",
      "10          tempogram          22.742475        4189.227754\n",
      "3     delta_tempogram          22.073579        2649.031884\n",
      "Zapisano wyniki dokładności do: feature_comparison_results\\feature_comparison_summary_auto.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "purple"
         },
         "name": "Dokładność",
         "text": [
          "93.2%",
          "88.9%",
          "86.5%",
          "86.4%",
          "71.2%",
          "49.5%",
          "43.0%",
          "37.8%",
          "36.6%",
          "34.3%",
          "27.9%",
          "22.7%",
          "22.1%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "hpss",
          "melspectrogram",
          "spectrogram",
          "cqt",
          "mfcc",
          "chroma",
          "spectral_contrast",
          "delta_mfcc",
          "tonnetz",
          "rms",
          "zcr",
          "tempogram",
          "delta_tempogram"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "qylufsVMV0CKHhW2gjZWQGSiR4WtoFVAVlPc/IqZVUDoU9qDMs9RQII4OjTJv0hALGaaYyOERUAJXzNMdeVCQNaT+pJ9SEJApjk2QhgrQUCgzizj5N47QJP8C9YSvjZARJP8C9YSNkA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "purple"
         },
         "name": "Czas treningu",
         "text": [
          "2199s",
          "932s",
          "14884s",
          "1240s",
          "377s",
          "113s",
          "99s",
          "252s",
          "401s",
          "755s",
          "866s",
          "4189s",
          "2649s"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "hpss",
          "melspectrogram",
          "spectrogram",
          "cqt",
          "mfcc",
          "chroma",
          "spectral_contrast",
          "delta_mfcc",
          "tonnetz",
          "rms",
          "zcr",
          "tempogram",
          "delta_tempogram"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "AABotpcuoUAAACA/CSONQAAAfL5IEs1AAAAwiB1hk0AAAMDoDpt3QAAAAGcmbFxAAAAA8aLhWEAAAABEc4ZvQAAAgM5GG3lAAACANXKfh0AAAABrUhCLQAAAFE46XbBAAAAQUxCypEA=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Porównanie dokładności dla różnych reprezentacji audio",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Porównanie czasu treningu dla różnych reprezentacji audio",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 600,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "tickangle": -45,
         "title": {
          "text": "Typ cechy"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "tickangle": -45,
         "title": {
          "text": "Typ cechy"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Dokładność testu (%)"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Czas treningu (s)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zapisano wykres porównania dokładności do: feature_comparison_results\\combined_comparison_auto.html\n",
      "\n",
      "Zapisano wyniki emocji do: feature_comparison_results\\emotions_comparison_auto.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Emotion: %{x}<br>Feature Type: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z:.1f}",
         "type": "heatmap",
         "x": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "xaxis": "x",
         "y": [
          "hpss",
          "melspectrogram",
          "spectrogram",
          "cqt",
          "mfcc",
          "chroma",
          "spectral_contrast",
          "tonnetz",
          "rms",
          "delta_mfcc",
          "zcr",
          "tempogram",
          "delta_tempogram"
         ],
         "yaxis": "y",
         "z": {
          "bdata": "8xrKayivV0DTpEmTJs1XQBtgKyHdbFZAAAAAAADoV0CZGtg7pgZYQHQeYEdJv1VAfmisD431VkCQDcgGZANXQDtjU/S5W1RA8pEJ9E5dV0Bw7NIoEMFXQEdJv1NIhFNAWK9evXp1V0Do1o8I4uhWQBxMkc+6QVNApAcqZ7fwVUBQXkN5DYVXQLRb+NWYSFJA72C/1cbQVkBeTsHLKXhXQJAGaZAG6VJA1fm1h1zWVUCHh4eHh4dXQJH4dpD4dlJAamlpaWnpUEAr1x0vtgRTQLETO7ETu09A74X3wnvhUUAUFBQUFBRVQMlCFrKQhU9AAv+qcS/wR0CAK9aAK9ZIQB3st9oYmkVAiob449blRUCcINyNfY9QQG0zag3kJEdAIrdjyO0YRkAc+1fQWa9LQIPmDYTmDTxAk7Nb+NWYPkCnW/PDImVMQJ936loObjZAaGlpaWlpPUD7dqkn47dDQEzHXCI8KThAZhAvklU4Q0CWqF2J2hVIQFP9nLCGd0JATHXl3PoRRUDDck8jLPc8QKbg5RS8nC5AOYge34WDQECbCOSaCORKQEloL6G9hDJAq3igy573Q0DVUF5DeQ01QJQ/6pQ/6gRAFgJNIdAUPkBs/ROlALtOQHsJ7SW0l0FAT+zETuzEPkDSmvzs+7VAQHYz4s2INz9AqaqqqqqqOkAEtRmYrnM8QMY555xzzhlAwXgr+xxSP0Bx7cBcOzAnQJb3KS4Zgi1AkRLgbslNOkCbtVmbtVk7QHHtwFw7MPc/1VBeQ3kNNUAAAAAAAAAAAOgpon69sDpA7Fk3mCKfFUDZsmXLli1DQAAAAAAAAAAA",
          "dtype": "f8",
          "shape": "13, 6"
         }
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "F1-score (%)"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(252,251,253)"
          ],
          [
           0.125,
           "rgb(239,237,245)"
          ],
          [
           0.25,
           "rgb(218,218,235)"
          ],
          [
           0.375,
           "rgb(188,189,220)"
          ],
          [
           0.5,
           "rgb(158,154,200)"
          ],
          [
           0.625,
           "rgb(128,125,186)"
          ],
          [
           0.75,
           "rgb(106,81,163)"
          ],
          [
           0.875,
           "rgb(84,39,143)"
          ],
          [
           1,
           "rgb(63,0,125)"
          ]
         ]
        },
        "height": 800,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "F1-score dla każdej emocji i typu cechy (%)"
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Emocja"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Typ cechy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Feature Type=hpss<br>Emotion=%{x}<br>F1-score=%{y}<extra></extra>",
         "legendgroup": "hpss",
         "marker": {
          "color": "rgb(218,218,235)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "hpss",
         "offsetgroup": "hpss",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "8xrKayivV0DTpEmTJs1XQBtgKyHdbFZAAAAAAADoV0CZGtg7pgZYQHQeYEdJv1VA",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Feature Type=melspectrogram<br>Emotion=%{x}<br>F1-score=%{y}<extra></extra>",
         "legendgroup": "melspectrogram",
         "marker": {
          "color": "rgb(188,189,220)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "melspectrogram",
         "offsetgroup": "melspectrogram",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "fmisD431VkCQDcgGZANXQDtjU/S5W1RA8pEJ9E5dV0Bw7NIoEMFXQEdJv1NIhFNA",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Feature Type=spectrogram<br>Emotion=%{x}<br>F1-score=%{y}<extra></extra>",
         "legendgroup": "spectrogram",
         "marker": {
          "color": "rgb(158,154,200)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "spectrogram",
         "offsetgroup": "spectrogram",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "WK9evXp1V0Do1o8I4uhWQBxMkc+6QVNApAcqZ7fwVUBQXkN5DYVXQLRb+NWYSFJA",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 600,
        "legend": {
         "title": {
          "text": "Typ cechy"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Porównanie F1-score dla 3 najlepszych reprezentacji"
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Emocja"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "F1-score (%)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "chroma",
         "r": {
          "bdata": "Av+qcS/wR0CAK9aAK9ZIQB3st9oYmkVAiob449blRUCcINyNfY9QQG0zag3kJEdA",
          "dtype": "f8"
         },
         "subplot": "polar",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "cqt",
         "r": {
          "bdata": "72C/1cbQVkBeTsHLKXhXQJAGaZAG6VJA1fm1h1zWVUCHh4eHh4dXQJH4dpD4dlJA",
          "dtype": "f8"
         },
         "subplot": "polar2",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "delta_mfcc",
         "r": {
          "bdata": "q3igy573Q0DVUF5DeQ01QJQ/6pQ/6gRAFgJNIdAUPkBs/ROlALtOQHsJ7SW0l0FA",
          "dtype": "f8"
         },
         "subplot": "polar3",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "delta_tempogram",
         "r": {
          "bdata": "1VBeQ3kNNUAAAAAAAAAAAOgpon69sDpA7Fk3mCKfFUDZsmXLli1DQAAAAAAAAAAA",
          "dtype": "f8"
         },
         "subplot": "polar4",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "hpss",
         "r": {
          "bdata": "8xrKayivV0DTpEmTJs1XQBtgKyHdbFZAAAAAAADoV0CZGtg7pgZYQHQeYEdJv1VA",
          "dtype": "f8"
         },
         "subplot": "polar5",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "melspectrogram",
         "r": {
          "bdata": "fmisD431VkCQDcgGZANXQDtjU/S5W1RA8pEJ9E5dV0Bw7NIoEMFXQEdJv1NIhFNA",
          "dtype": "f8"
         },
         "subplot": "polar6",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "mfcc",
         "r": {
          "bdata": "amlpaWnpUEAr1x0vtgRTQLETO7ETu09A74X3wnvhUUAUFBQUFBRVQMlCFrKQhU9A",
          "dtype": "f8"
         },
         "subplot": "polar7",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "rms",
         "r": {
          "bdata": "THXl3PoRRUDDck8jLPc8QKbg5RS8nC5AOYge34WDQECbCOSaCORKQEloL6G9hDJA",
          "dtype": "f8"
         },
         "subplot": "polar8",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "spectral_contrast",
         "r": {
          "bdata": "IrdjyO0YRkAc+1fQWa9LQIPmDYTmDTxAk7Nb+NWYPkCnW/PDImVMQJ936loObjZA",
          "dtype": "f8"
         },
         "subplot": "polar9",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "spectrogram",
         "r": {
          "bdata": "WK9evXp1V0Do1o8I4uhWQBxMkc+6QVNApAcqZ7fwVUBQXkN5DYVXQLRb+NWYSFJA",
          "dtype": "f8"
         },
         "subplot": "polar10",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "tempogram",
         "r": {
          "bdata": "wXgr+xxSP0Bx7cBcOzAnQJb3KS4Zgi1AkRLgbslNOkCbtVmbtVk7QHHtwFw7MPc/",
          "dtype": "f8"
         },
         "subplot": "polar11",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "tonnetz",
         "r": {
          "bdata": "aGlpaWlpPUD7dqkn47dDQEzHXCI8KThAZhAvklU4Q0CWqF2J2hVIQFP9nLCGd0JA",
          "dtype": "f8"
         },
         "subplot": "polar12",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "zcr",
         "r": {
          "bdata": "T+zETuzEPkDSmvzs+7VAQHYz4s2INz9AqaqqqqqqOkAEtRmYrnM8QMY555xzzhlA",
          "dtype": "f8"
         },
         "subplot": "polar13",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "chroma",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "cqt",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "delta_mfcc",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "delta_tempogram",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.78,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "hpss",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.78,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "melspectrogram",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.78,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "mfcc",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.56,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "rms",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.56,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "spectral_contrast",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.56,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "spectrogram",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.33999999999999997,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "tempogram",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.33999999999999997,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "tonnetz",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.33999999999999997,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "zcr",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.12,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 1900,
        "polar": {
         "domain": {
          "x": [
           0,
           0.2888888888888889
          ],
          "y": [
           0.88,
           1
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar10": {
         "domain": {
          "x": [
           0,
           0.2888888888888889
          ],
          "y": [
           0.22,
           0.33999999999999997
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar11": {
         "domain": {
          "x": [
           0.35555555555555557,
           0.6444444444444445
          ],
          "y": [
           0.22,
           0.33999999999999997
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar12": {
         "domain": {
          "x": [
           0.7111111111111111,
           1
          ],
          "y": [
           0.22,
           0.33999999999999997
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar13": {
         "domain": {
          "x": [
           0,
           0.2888888888888889
          ],
          "y": [
           0,
           0.12
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar14": {
         "domain": {
          "x": [
           0.35555555555555557,
           0.6444444444444445
          ],
          "y": [
           0,
           0.12
          ]
         }
        },
        "polar15": {
         "domain": {
          "x": [
           0.7111111111111111,
           1
          ],
          "y": [
           0,
           0.12
          ]
         }
        },
        "polar2": {
         "domain": {
          "x": [
           0.35555555555555557,
           0.6444444444444445
          ],
          "y": [
           0.88,
           1
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar3": {
         "domain": {
          "x": [
           0.7111111111111111,
           1
          ],
          "y": [
           0.88,
           1
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar4": {
         "domain": {
          "x": [
           0,
           0.2888888888888889
          ],
          "y": [
           0.66,
           0.78
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar5": {
         "domain": {
          "x": [
           0.35555555555555557,
           0.6444444444444445
          ],
          "y": [
           0.66,
           0.78
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar6": {
         "domain": {
          "x": [
           0.7111111111111111,
           1
          ],
          "y": [
           0.66,
           0.78
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar7": {
         "domain": {
          "x": [
           0,
           0.2888888888888889
          ],
          "y": [
           0.44,
           0.56
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar8": {
         "domain": {
          "x": [
           0.35555555555555557,
           0.6444444444444445
          ],
          "y": [
           0.44,
           0.56
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar9": {
         "domain": {
          "x": [
           0.7111111111111111,
           1
          ],
          "y": [
           0.44,
           0.56
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1200
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "red"
         },
         "text": [
          "94.7%",
          "93.8%",
          "91.8%",
          "91.3%",
          "67.6%",
          "47.9%",
          "44.2%",
          "42.1%",
          "39.9%",
          "31.3%",
          "30.8%",
          "29.4%",
          "21.1%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "hpss",
          "spectrogram",
          "melspectrogram",
          "cqt",
          "mfcc",
          "chroma",
          "spectral_contrast",
          "rms",
          "delta_mfcc",
          "tempogram",
          "zcr",
          "tonnetz",
          "delta_tempogram"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "8xrKayivV0BYr169enVXQH5orA+N9VZA72C/1cbQVkBqaWlpaelQQAL/qnEv8EdAIrdjyO0YRkBMdeXc+hFFQKt4oMue90NAwXgr+xxSP0BP7MRO7MQ+QGhpaWlpaT1A1VBeQ3kNNUA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "purple"
         },
         "text": [
          "95.2%",
          "93.9%",
          "92.1%",
          "91.6%",
          "76.1%",
          "55.4%",
          "49.7%",
          "39.4%",
          "33.4%",
          "29.0%",
          "21.1%",
          "11.6%",
          "0.0%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "hpss",
          "cqt",
          "melspectrogram",
          "spectrogram",
          "mfcc",
          "spectral_contrast",
          "chroma",
          "tonnetz",
          "zcr",
          "rms",
          "delta_mfcc",
          "tempogram",
          "delta_tempogram"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "06RJkybNV0BeTsHLKXhXQJANyAZkA1dA6NaPCOLoVkAr1x0vtgRTQBz7V9BZr0tAgCvWgCvWSED7dqkn47dDQNKa/Oz7tUBAw3JPIyz3PEDVUF5DeQ01QHHtwFw7MCdAAAAAAAAAAAA=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "yellow"
         },
         "text": [
          "89.7%",
          "81.4%",
          "77.0%",
          "75.6%",
          "63.5%",
          "43.2%",
          "31.2%",
          "28.1%",
          "26.7%",
          "24.2%",
          "15.3%",
          "14.8%",
          "2.6%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "hpss",
          "melspectrogram",
          "spectrogram",
          "cqt",
          "mfcc",
          "chroma",
          "zcr",
          "spectral_contrast",
          "delta_tempogram",
          "tonnetz",
          "rms",
          "tempogram",
          "delta_mfcc"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "G2ArId1sVkA7Y1P0uVtUQBxMkc+6QVNAkAZpkAbpUkCxEzuxE7tPQB3st9oYmkVAdjPizYg3P0CD5g2E5g08QOgpon69sDpATMdcIjwpOECm4OUUvJwuQJb3KS4Zgi1AlD/qlD/qBEA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "blue"
         },
         "text": [
          "95.6%",
          "93.5%",
          "87.8%",
          "87.3%",
          "71.5%",
          "43.8%",
          "38.4%",
          "33.0%",
          "30.6%",
          "30.1%",
          "26.7%",
          "26.3%",
          "5.4%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "hpss",
          "melspectrogram",
          "spectrogram",
          "cqt",
          "mfcc",
          "chroma",
          "tonnetz",
          "rms",
          "spectral_contrast",
          "delta_mfcc",
          "zcr",
          "tempogram",
          "delta_tempogram"
         ],
         "xaxis": "x4",
         "y": {
          "bdata": "AAAAAADoV0DykQn0Tl1XQKQHKme38FVA1fm1h1zWVUDvhffCe+FRQIqG+OPW5UVAZhAvklU4Q0A5iB7fhYNAQJOzW/jVmD5AFgJNIdAUPkCpqqqqqqo6QJES4G7JTTpA7Fk3mCKfFUA=",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "gray"
         },
         "text": [
          "96.1%",
          "95.0%",
          "94.1%",
          "94.1%",
          "84.3%",
          "66.2%",
          "61.5%",
          "56.8%",
          "53.8%",
          "48.2%",
          "38.4%",
          "28.5%",
          "27.4%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "hpss",
          "melspectrogram",
          "cqt",
          "spectrogram",
          "mfcc",
          "chroma",
          "delta_mfcc",
          "spectral_contrast",
          "rms",
          "tonnetz",
          "delta_tempogram",
          "zcr",
          "tempogram"
         ],
         "xaxis": "x5",
         "y": {
          "bdata": "mRrYO6YGWEBw7NIoEMFXQIeHh4eHh1dAUF5DeQ2FV0AUFBQUFBRVQJwg3I19j1BAbP0TpQC7TkCnW/PDImVMQJsI5JoI5EpAlqhdidoVSEDZsmXLli1DQAS1GZiuczxAm7VZm7VZO0A=",
          "dtype": "f8"
         },
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "green"
         },
         "text": [
          "87.0%",
          "78.1%",
          "73.9%",
          "73.1%",
          "63.0%",
          "46.3%",
          "36.9%",
          "35.2%",
          "22.4%",
          "18.5%",
          "6.5%",
          "1.4%",
          "0.0%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "hpss",
          "melspectrogram",
          "cqt",
          "spectrogram",
          "mfcc",
          "chroma",
          "tonnetz",
          "delta_mfcc",
          "spectral_contrast",
          "rms",
          "zcr",
          "tempogram",
          "delta_tempogram"
         ],
         "xaxis": "x6",
         "y": {
          "bdata": "dB5gR0m/VUBHSb9TSIRTQJH4dpD4dlJAtFv41ZhIUkDJQhaykIVPQG0zag3kJEdAU/2csIZ3QkB7Ce0ltJdBQJ936loObjZASWgvob2EMkDGOeecc84ZQHHtwFw7MPc/AAAAAAAAAAA=",
          "dtype": "f8"
         },
         "yaxis": "y6"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "anger",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "fear",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "happiness",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6333333333333333,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "neutral",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6333333333333333,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "sadness",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.26666666666666666,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "surprised",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.26666666666666666,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 1000,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Porównanie F1-score dla różnych emocji według typu reprezentacji"
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "tickangle": -45
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "tickangle": -45
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ],
         "tickangle": -45
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ],
         "tickangle": -45
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.45
         ],
         "tickangle": -45
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.55,
          1
         ],
         "tickangle": -45
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.7333333333333334,
          1
         ],
         "range": [
          0,
          110
         ],
         "title": {
          "text": "F1-score (%)"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.7333333333333334,
          1
         ],
         "range": [
          0,
          110
         ],
         "title": {
          "text": "F1-score (%)"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.3666666666666667,
          0.6333333333333333
         ],
         "range": [
          0,
          110
         ],
         "title": {
          "text": "F1-score (%)"
         }
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.3666666666666667,
          0.6333333333333333
         ],
         "range": [
          0,
          110
         ],
         "title": {
          "text": "F1-score (%)"
         }
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.26666666666666666
         ],
         "range": [
          0,
          110
         ],
         "title": {
          "text": "F1-score (%)"
         }
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.26666666666666666
         ],
         "range": [
          0,
          110
         ],
         "title": {
          "text": "F1-score (%)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wygenerowane wizualizacje emocji:\n",
      "- heatmap: feature_comparison_results\\emotions_heatmap_auto.html\n",
      "- top_features: feature_comparison_results\\top_features_emotions_auto.html\n",
      "- radar: feature_comparison_results\\emotions_radar_auto.html\n",
      "- dashboard: feature_comparison_results\\emotions_dashboard_auto.html\n",
      "\n",
      "Generowanie wszystkich wizualizacji zakończone pomyślnie.\n"
     ]
    }
   ],
   "source": [
    "def generate_all_visualizations():\n",
    "    \"\"\"Generuje i zapisuje wszystkie wizualizacje wyników analizy.\"\"\"\n",
    "    # Wyszukiwanie katalogu z wynikami\n",
    "    base_dir = find_results_directory()\n",
    "    if base_dir is None:\n",
    "        return\n",
    "\n",
    "    # Odczyt wyników z plików\n",
    "    results_df = read_results_from_files(base_dir)\n",
    "    emotions_df = read_emotion_results(base_dir)\n",
    "\n",
    "    # Ustalenie katalogu do zapisu\n",
    "    save_dir = base_dir\n",
    "\n",
    "    # Przetwarzanie wyników dokładności\n",
    "    if results_df is not None and not results_df.empty:\n",
    "        # Sortowanie wyników według dokładności w porządku malejącym\n",
    "        results_df = results_df.sort_values(\"Test Accuracy (%)\", ascending=False)\n",
    "\n",
    "        # Wyświetlenie DataFrame dla przeglądu wyników\n",
    "        print(f\"\\nZnalezione wyniki dokładności:\\n{results_df}\")\n",
    "\n",
    "        # Zapis wyników do pliku CSV\n",
    "        csv_path = os.path.join(save_dir, \"feature_comparison_summary_auto.csv\")\n",
    "        results_df.to_csv(csv_path, index=False)\n",
    "        print(f\"Zapisano wyniki dokładności do: {csv_path}\")\n",
    "\n",
    "        # Generowanie wykresu porównania dokładności\n",
    "        combined_path = generate_accuracy_comparison_plot(results_df, save_dir)\n",
    "        print(f\"Zapisano wykres porównania dokładności do: {combined_path}\")\n",
    "    else:\n",
    "        print(\"Brak danych dokładności do wygenerowania wykresów.\")\n",
    "\n",
    "    # Przetwarzanie wyników emocji\n",
    "    if emotions_df is not None and not emotions_df.empty:\n",
    "        # Zapis wyników emocji do pliku CSV\n",
    "        emotions_csv_path = os.path.join(save_dir, \"emotions_comparison_auto.csv\")\n",
    "        emotions_df.to_csv(emotions_csv_path, index=False)\n",
    "        print(f\"\\nZapisano wyniki emocji do: {emotions_csv_path}\")\n",
    "\n",
    "        # Generowanie wizualizacji emocji\n",
    "        emotion_paths = generate_emotion_visualizations(\n",
    "            emotions_df, results_df, save_dir\n",
    "        )\n",
    "        print(\"\\nWygenerowane wizualizacje emocji:\")\n",
    "        for name, path in emotion_paths.items():\n",
    "            if path:\n",
    "                print(f\"- {name}: {path}\")\n",
    "\n",
    "        print(\"\\nGenerowanie wszystkich wizualizacji zakończone pomyślnie.\")\n",
    "    else:\n",
    "        print(\"Brak danych emocji do wygenerowania wykresów.\")\n",
    "\n",
    "\n",
    "# Uruchomienie generowania wszystkich wizualizacji\n",
    "generate_all_visualizations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Audio Emotion Recognition)",
   "language": "python",
   "name": "audio-emotion-recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
