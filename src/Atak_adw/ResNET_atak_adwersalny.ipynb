{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook zawiera kod z atakiem adwersalnym na sieć ResNET-18 wytrenowaną na datasecie nEMO. \n",
    "### Atak adwersalny (ang. adversarial attack) na sieć neuronową to technika, która polega na celowym modyfikowaniu danych wejściowych w taki sposób, aby wprowadzić w błąd model uczenia maszynowego. Przekształcenia danych wejściowych są często niemal niewidoczne dla człowieka.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katalog główny projektu: c:\\Users\\kubas\\Desktop\\Projekt dyplomowy\\Audio-Emotion-Recognition\n",
      "Czy katalog src istnieje: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Dodaj katalog główny projektu do sys.path\n",
    "current_dir = (\n",
    "    os.path.dirname(os.path.abspath(__file__))\n",
    "    if \"__file__\" in globals()\n",
    "    else os.getcwd()\n",
    ")\n",
    "project_root = os.path.abspath(os.path.join(current_dir, \"..\", \"..\"))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Katalog główny projektu: {project_root}\")\n",
    "print(f\"Czy katalog src istnieje: {os.path.exists(os.path.join(project_root, 'src'))}\")\n",
    "\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import soundfile as sf\n",
    "from datasets import load_from_disk\n",
    "\n",
    "\n",
    "from src.helpers.early_stopping import EarlyStopping\n",
    "from src.helpers.augmentation import AugmentedAudioDataset\n",
    "from src.helpers.resnet_model_definition import AudioResNet\n",
    "from src.config import (\n",
    "    BATCH_SIZE,\n",
    "    EARLY_STOPPING_PATIENCE,\n",
    "    MODEL_PATH,\n",
    "    MAX_LENGTH,\n",
    "    SEED,\n",
    "    DATASET_PATH,\n",
    ")\n",
    "from src.create_data import download_and_save_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ładowanie datasetu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczęcie ładowania datasetu z dysku...\n"
     ]
    }
   ],
   "source": [
    "# Weryfikacja istnienia folderu z danymi oraz załadowanie zbioru danych\n",
    "dataset_path = DATASET_PATH\n",
    "if os.path.exists(dataset_path):\n",
    "    try:\n",
    "        print(\"Rozpoczęcie ładowania datasetu z dysku...\")\n",
    "        dataset = load_from_disk(dataset_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Wystąpił błąd podczas ładowania datasetu: {e}\")\n",
    "        print(\"Inicjowanie ponownego pobierania datasetu...\")\n",
    "        dataset = download_and_save_dataset()\n",
    "else:\n",
    "    print(\"Folder 'data' nie został znaleziony. Inicjowanie pobierania datasetu...\")\n",
    "    dataset = download_and_save_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Przetwarzanie próbek audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przetwarzanie próbek audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Przetwarzanie próbek audio: 100%|██████████| 4481/4481 [00:38<00:00, 115.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ustawienie seed dla powtarzalności wyników\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Przetwarzanie danych audio\n",
    "print(\"Przetwarzanie próbek audio...\")\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for sample in tqdm(dataset[\"train\"], desc=\"Przetwarzanie próbek audio\"):\n",
    "    audio_array = sample[\"audio\"][\"array\"]\n",
    "    sr = sample[\"audio\"][\"sampling_rate\"]\n",
    "\n",
    "    # Ujednolicenie długości\n",
    "    target_length = int(MAX_LENGTH * sr)\n",
    "    if len(audio_array) > target_length:\n",
    "        audio_array = audio_array[:target_length]\n",
    "    else:\n",
    "        padding = np.zeros(target_length - len(audio_array))\n",
    "        audio_array = np.concatenate([audio_array, padding])\n",
    "\n",
    "    # Ekstrakcja melspektrogramu\n",
    "    S = librosa.feature.melspectrogram(y=audio_array, sr=sr, n_mels=128)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "    features.append(S_db)\n",
    "\n",
    "    # Dodanie etykiety\n",
    "    labels.append(sample[\"emotion\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Konwersja i normalizacja danych audio oraz etykiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n"
     ]
    }
   ],
   "source": [
    "# Konwersja list na tablice numpy\n",
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], 1, features.shape[1], features.shape[2])\n",
    "\n",
    "# Normalizacja danych (standardyzacja)\n",
    "mean = np.mean(features)\n",
    "std = np.std(features)\n",
    "features = (features - mean) / std\n",
    "\n",
    "# Konwersja etykiet na liczby\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "num_classes = len(np.unique(labels))\n",
    "print(f\"Liczba klas emocji: {num_classes}\")\n",
    "print(\n",
    "    f\"Mapowanie klas: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Podział danych na zbiory treningowe, walidacyjne i testowe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział na zbiory\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=SEED, stratify=labels\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=SEED, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Inicjalizacja modelu i optymalizatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Używane urządzenie: cpu\n"
     ]
    }
   ],
   "source": [
    "# Inicjalizacja modelu, funkcji straty i optymalizatora\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Używane urządzenie: {device}\")\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = AudioResNet(num_classes=num_classes, dropout_rate=0.5)\n",
    "model = model.to(device)\n",
    "\n",
    "# Inicjalizacja funkcji straty i optymalizatora\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=0.001, weight_decay=1e-5\n",
    ")  # Dodanie regularyzacji L2\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Przygotowanie zestawów danych z augmentacją i ładowanie ich do DataLoaderów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotowanie zestawów danych z augmentacją\n",
    "train_dataset = AugmentedAudioDataset(X_train, y_train, augment=True)\n",
    "val_dataset = AugmentedAudioDataset(X_val, y_val, augment=False)\n",
    "test_dataset = AugmentedAudioDataset(X_test, y_test, augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Ścieżka do zapisywania modelu\n",
    "early_stopping = EarlyStopping(patience=EARLY_STOPPING_PATIENCE, path=MODEL_PATH)\n",
    "\n",
    "# Śledzenie historii treningu\n",
    "history = {\"train_loss\": [], \"val_loss\": [], \"val_accuracy\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Ładowanie wytrenowanego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resnet18_model(model_path, num_classes, device, dropout_rate=0.5):\n",
    "    \"\"\"\n",
    "    Ładuje istniejący model ResNet-18 z podanej ścieżki\n",
    "\n",
    "    Parametry:\n",
    "    - model_path: ścieżka do katalogu lub pliku z modelem\n",
    "    - num_classes: liczba klas wyjściowych (emocji)\n",
    "    - device: urządzenie (CPU/GPU)\n",
    "    - dropout_rate: współczynnik dropout (domyślnie 0.5)\n",
    "\n",
    "    Zwraca:\n",
    "    - załadowany model ResNet-18\n",
    "    \"\"\"\n",
    "    print(f\"Ładowanie modelu ResNet-18 z: {model_path}\")\n",
    "\n",
    "    # Sprawdzenie, czy podana ścieżka jest katalogiem czy plikiem\n",
    "    if os.path.isdir(model_path):\n",
    "        # Jeśli katalog, znajdź plik z modelem\n",
    "        model_files = [f for f in os.listdir(model_path) if f.endswith((\".pt\", \".pth\"))]\n",
    "        if not model_files:\n",
    "            raise FileNotFoundError(\n",
    "                f\"Nie znaleziono plików modelu w katalogu {model_path}\"\n",
    "            )\n",
    "\n",
    "        # Wybierz najnowszy plik\n",
    "        model_files.sort(\n",
    "            key=lambda x: os.path.getmtime(os.path.join(model_path, x)), reverse=True\n",
    "        )\n",
    "        model_file = os.path.join(model_path, model_files[0])\n",
    "        print(f\"Wybrany plik modelu: {model_files[0]}\")\n",
    "    else:\n",
    "        # Jeśli bezpośrednia ścieżka do pliku\n",
    "        model_file = model_path\n",
    "\n",
    "    # WAŻNE: Inicjalizacja modelu z tymi samymi parametrami co podczas treningu\n",
    "    model = AudioResNet(num_classes=num_classes, dropout_rate=dropout_rate)\n",
    "\n",
    "    try:\n",
    "        # Ładowanie wag modelu\n",
    "        checkpoint = torch.load(model_file, map_location=device)\n",
    "\n",
    "        # Sprawdzenie typu zapisanego modelu\n",
    "        if isinstance(checkpoint, dict):\n",
    "            if \"model_state_dict\" in checkpoint:\n",
    "                model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "                print(\"Załadowano model_state_dict z checkpointu\")\n",
    "            elif \"state_dict\" in checkpoint:\n",
    "                model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "                print(\"Załadowano state_dict z checkpointu\")\n",
    "            else:\n",
    "                # Próba załadowania bezpośrednio\n",
    "                model.load_state_dict(checkpoint)\n",
    "                print(\"Załadowano checkpoint jako state_dict\")\n",
    "        else:\n",
    "            # Bezpośredni state_dict\n",
    "            model.load_state_dict(checkpoint)\n",
    "            print(\"Załadowano bezpośredni state_dict\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd podczas ładowania modelu: {e}\")\n",
    "        print(\"Sprawdzam strukturę checkpointu...\")\n",
    "\n",
    "        # Diagnostyka - sprawdź co jest w checkpoincie\n",
    "        if isinstance(checkpoint, dict):\n",
    "            print(f\"Klucze w checkpoincie: {list(checkpoint.keys())}\")\n",
    "\n",
    "        # Próba załadowania z ignorowaniem niekompatybilnych warstw\n",
    "        try:\n",
    "            model.load_state_dict(checkpoint, strict=False)\n",
    "            print(\"Załadowano model z strict=False\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Nie udało się załadować modelu nawet z strict=False: {e2}\")\n",
    "            raise e2\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()  # Ustawienie modelu w trybie ewaluacji dla ataku\n",
    "\n",
    "    print(f\"Model ResNet-18 załadowany pomyślnie na urządzenie: {device}\")\n",
    "\n",
    "    # Sprawdzenie architektury modelu\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Całkowita liczba parametrów: {total_params:,}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Funkcja sprawdzająca gotowość modelu do ataku adwersalnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_model_compatibility(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Sprawdza kompatybilność załadowanego modelu z danymi testowymi\n",
    "    \"\"\"\n",
    "    print(\"Sprawdzanie kompatybilności modelu...\")\n",
    "\n",
    "    try:\n",
    "        # Pobierz jedną próbkę\n",
    "        for batch_features, batch_labels in test_loader:\n",
    "            batch_features = batch_features.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # Test forward pass\n",
    "            with torch.no_grad():\n",
    "                outputs = model(batch_features)\n",
    "                print(f\"Wejście: {batch_features.shape}\")\n",
    "                print(f\"Wyjście: {outputs.shape}\")\n",
    "                print(f\"Oczekiwana liczba klas: {outputs.shape[1]}\")\n",
    "\n",
    "            break\n",
    "\n",
    "        print(\"✓ Model jest kompatybilny z danymi\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Błąd kompatybilności: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ładowanie modelu ResNet-18 z: c:\\Users\\kubas\\Desktop\\Projekt dyplomowy\\Audio-Emotion-Recognition\\src\\ResNet_mel\\model_outputs\n",
      "Wybrany plik modelu: best_model_20250515_090117.pt\n",
      "Załadowano checkpoint jako state_dict\n",
      "Model ResNet-18 załadowany pomyślnie na urządzenie: cpu\n",
      "Całkowita liczba parametrów: 11,173,318\n",
      "Sprawdzanie kompatybilności modelu...\n",
      "Wejście: torch.Size([32, 1, 128, 141])\n",
      "Wyjście: torch.Size([32, 6])\n",
      "Oczekiwana liczba klas: 6\n",
      "✓ Model jest kompatybilny z danymi\n",
      "Model gotowy do ataku adwersalnego!\n"
     ]
    }
   ],
   "source": [
    "# Poprawiona ścieżka do katalogu z modelem ResNet wytrenowanym na mel-spectrogramach\n",
    "MODEL_PATH = os.path.join(project_root, \"src\", \"ResNet_mel\", \"model_outputs\")\n",
    "NUM_CLASSES = 6\n",
    "DROPOUT_RATE = 0.5  # Upewnij się, że to jest ta sama wartość co podczas treningu\n",
    "\n",
    "# Załaduj model\n",
    "model = load_resnet18_model(MODEL_PATH, NUM_CLASSES, device, DROPOUT_RATE)\n",
    "\n",
    "# Sprawdź kompatybilność\n",
    "if verify_model_compatibility(model, test_loader, device):\n",
    "    print(\"Model gotowy do ataku adwersalnego!\")\n",
    "else:\n",
    "    print(\"Sprawdź konfigurację modelu i danych!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATAK ADWERSALNY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wykorzystaną metodą ataku adwersalnego jest Fast Gradient Sign Method (FGSM).\n",
    "Jest to jedna z najprostszych i najszybszych metod. FGSM modyfikuje wejście tak, aby maksymalizować stratę, czyli wprowadza model w błąd.  \n",
    "Etapy ataku:\n",
    "1. Obliczamy gradient funkcji straty względem danych wejściowych.\n",
    "2. Tworzymy perturbację (zakłócenie) poprzez pomnożenie znaku gradientu przez niski parametr ε.\n",
    "3. Dodajemy perturbację do oryginalnego obrazu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, data, target, epsilon, criterion):\n",
    "    \"\"\"\n",
    "    Implementacja ataku Fast Gradient Sign Method (FGSM)\n",
    "\n",
    "    Parametry:\n",
    "    - model: model neural network\n",
    "    - data: tensor wejściowy (batch of mel-spectrograms)\n",
    "    - target: prawdziwe etykiety\n",
    "    - epsilon: siła ataku\n",
    "    - criterion: funkcja straty\n",
    "\n",
    "    Zwraca:\n",
    "    - perturbed_data: dane po ataku\n",
    "    - perturbation: dodana perturbacja\n",
    "    \"\"\"\n",
    "    # Upewnij się, że dane wymagają gradientów\n",
    "    data.requires_grad = True\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(data)\n",
    "\n",
    "    # Oblicz stratę\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    # Backward pass - oblicz gradienty\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Zbierz gradienty z danych wejściowych\n",
    "    data_grad = data.grad.data\n",
    "\n",
    "    # Stwórz zakłócenie używając znaku gradientu\n",
    "    sign_data_grad = data_grad.sign()\n",
    "\n",
    "    # Stwórz zakłócone dane przez dodanie epsilon * sign(gradient)\n",
    "    perturbed_data = data + epsilon * sign_data_grad\n",
    "\n",
    "    # Opcjonalnie: ogranic wartości do odpowiedniego zakresu (dla normalized mel-spectrograms)\n",
    "    # Zakładając, że dane wejściowe są znormalizowane (mean=0, std=1)\n",
    "    # perturbed_data = torch.clamp(perturbed_data, -3, 3)  # ±3 std deviations\n",
    "\n",
    "    # Oblicz rzeczywistą perturbację\n",
    "    perturbation = perturbed_data - data\n",
    "\n",
    "    return perturbed_data.detach(), perturbation.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Denormalizacja spektrogramów\n",
    "Aby odtworzyć dźwięk z melspektrogramu po ataku adwersalnym należy przywrócić do oryginalnego zakresu wartości, w jakim był przed normalizacją."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_melspectrogram(normalized_melspec, mean, std):\n",
    "    \"\"\"\n",
    "    Denormalizuje mel-spektrogram\n",
    "\n",
    "    Parametry:\n",
    "    - normalized_melspec: znormalizowany mel-spektrogram\n",
    "    - mean: średnia użyta do normalizacji\n",
    "    - std: odchylenie standardowe użyte do normalizacji\n",
    "\n",
    "    Zwraca:\n",
    "    - denormalized_melspec: denormalizowany mel-spektrogram\n",
    "    \"\"\"\n",
    "    return normalized_melspec * std + mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zamiana spetrogramów z powrotem na dźwięk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melspectrogram_to_audio_advanced(\n",
    "    melspec_db, sr=24000, n_fft=2048, hop_length=512, n_mels=128, n_iter=32, length=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Zaawansowana konwersja mel-spektrogramu na audio z lepszą jakością\n",
    "\n",
    "    Parametry:\n",
    "    - melspec_db: mel-spektrogram w dB\n",
    "    - sr: sampling rate\n",
    "    - n_fft: FFT window size\n",
    "    - hop_length: hop length\n",
    "    - n_mels: liczba mel bins\n",
    "    - n_iter: iteracje Griffin-Lim\n",
    "    - length: docelowa długość\n",
    "\n",
    "    Zwraca:\n",
    "    - audio: zrekonstruowany sygnał\n",
    "    \"\"\"\n",
    "    # Konwersja z dB na power\n",
    "    melspec_power = librosa.db_to_power(melspec_db)\n",
    "\n",
    "    # Tworzymy mel filter bank\n",
    "    mel_basis = librosa.filters.mel(sr=sr, n_fft=n_fft, n_mels=n_mels)\n",
    "\n",
    "    # Próba odwrócenia mel-skali (pseudo-inverse)\n",
    "    mel_basis_inv = np.linalg.pinv(mel_basis)\n",
    "\n",
    "    # Rekonstrukcja spektrogramu\n",
    "    spec_power = np.dot(mel_basis_inv, melspec_power)\n",
    "\n",
    "    # Upewnij się, że wartości nie są negatywne\n",
    "    spec_power = np.abs(spec_power)\n",
    "\n",
    "    # Griffin-Lim do rekonstrukcji fazy\n",
    "    audio = librosa.griffinlim(\n",
    "        spec_power, n_iter=n_iter, hop_length=hop_length, length=length\n",
    "    )\n",
    "\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja poniżej przeprowadza atak FGSM na całą partię danych z loadera, zapisuje audio przed i po ataku dla kilku przykładów i liczy statystyki:\n",
    "    - dokładność modelu przed i po ataku\n",
    "    - skuteczność ataku (ile predykcji się zmieniło)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_adversarial_batch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    epsilon,\n",
    "    criterion,\n",
    "    device,\n",
    "    output_dir=\"adversarial_audio\",\n",
    "    mean=0,\n",
    "    std=1,\n",
    "    sr=24000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Przetwarza całą partię danych przez atak FGSM i zapisuje audio\n",
    "\n",
    "    Parametry:\n",
    "    - model: trenowany model\n",
    "    - data_loader: DataLoader z danymi\n",
    "    - epsilon: siła ataku\n",
    "    - criterion: funkcja straty\n",
    "    - device: urządzenie obliczeniowe\n",
    "    - output_dir: katalog na pliki wyjściowe\n",
    "    - mean, std: parametry normalizacji\n",
    "    - sr: sampling rate\n",
    "\n",
    "    Zwraca:\n",
    "    - results: słownik z wynikami\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    results = {\n",
    "        \"original_predictions\": [],\n",
    "        \"adversarial_predictions\": [],\n",
    "        \"original_accuracy\": 0,\n",
    "        \"adversarial_accuracy\": 0,\n",
    "        \"attack_success_rate\": 0,\n",
    "    }\n",
    "\n",
    "    correct_original = 0\n",
    "    correct_adversarial = 0\n",
    "    attack_success = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(\n",
    "        tqdm(data_loader, desc=f\"FGSM ε={epsilon}\")\n",
    "    ):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Oryginalny forward pass\n",
    "        with torch.no_grad():\n",
    "            original_output = model(data)\n",
    "            original_pred = original_output.argmax(dim=1)\n",
    "\n",
    "        # Atak FGSM - tutaj tensor będzie wymagał gradientów\n",
    "        perturbed_data, perturbation = fgsm_attack(\n",
    "            model, data, target, epsilon, criterion\n",
    "        )\n",
    "\n",
    "        # Forward pass na danych po ataku (perturbed_data już jest detached w fgsm_attack)\n",
    "        with torch.no_grad():\n",
    "            adversarial_output = model(perturbed_data)\n",
    "            adversarial_pred = adversarial_output.argmax(dim=1)\n",
    "\n",
    "        # Statystyki\n",
    "        correct_original += (original_pred == target).sum().item()\n",
    "        correct_adversarial += (adversarial_pred == target).sum().item()\n",
    "        attack_success += (original_pred != adversarial_pred).sum().item()\n",
    "        total_samples += data.size(0)\n",
    "\n",
    "        # Zapisz przykłady audio (pierwszy przykład z każdej partii)\n",
    "        if batch_idx < 5:  # Zapisz tylko pierwsze 5 partii\n",
    "            for i in range(min(3, data.size(0))):  # Pierwsze 3 próbki z partii\n",
    "                try:\n",
    "                    # Denormalizuj spektrogramy - używaj .detach().cpu().numpy()\n",
    "                    orig_melspec = denormalize_melspectrogram(\n",
    "                        data[i].detach().cpu().numpy().squeeze(), mean, std\n",
    "                    )\n",
    "                    adv_melspec = denormalize_melspectrogram(\n",
    "                        perturbed_data[i].detach().cpu().numpy().squeeze(), mean, std\n",
    "                    )\n",
    "\n",
    "                    # Konwertuj na audio\n",
    "                    orig_audio = melspectrogram_to_audio_advanced(orig_melspec, sr=sr)\n",
    "                    adv_audio = melspectrogram_to_audio_advanced(adv_melspec, sr=sr)\n",
    "\n",
    "                    # Zapisz pliki audio\n",
    "                    orig_filename = (\n",
    "                        f\"{output_dir}/original_batch{batch_idx}_sample{i}.wav\"\n",
    "                    )\n",
    "                    adv_filename = f\"{output_dir}/adversarial_batch{batch_idx}_sample{i}_eps{epsilon}.wav\"\n",
    "\n",
    "                    sf.write(orig_filename, orig_audio, sr)\n",
    "                    sf.write(adv_filename, adv_audio, sr)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\n",
    "                        f\"Błąd podczas konwersji audio (batch {batch_idx}, sample {i}): {e}\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "        # Zapisz predykcje - upewnij się, że są detached\n",
    "        results[\"original_predictions\"].extend(original_pred.detach().cpu().tolist())\n",
    "        results[\"adversarial_predictions\"].extend(\n",
    "            adversarial_pred.detach().cpu().tolist()\n",
    "        )\n",
    "\n",
    "    # Oblicz końcowe statystyki\n",
    "    results[\"original_accuracy\"] = correct_original / total_samples\n",
    "    results[\"adversarial_accuracy\"] = correct_adversarial / total_samples\n",
    "    results[\"attack_success_rate\"] = attack_success / total_samples\n",
    "\n",
    "    print(f\"\\nWyniki dla ε = {epsilon}:\")\n",
    "    print(f\"Dokładność oryginalna: {results['original_accuracy']:.4f}\")\n",
    "    print(f\"Dokładność po ataku: {results['adversarial_accuracy']:.4f}\")\n",
    "    print(f\"Sukces ataku: {results['attack_success_rate']:.4f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testowanie różnych wartości epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multiple_epsilons(\n",
    "    model,\n",
    "    test_loader,\n",
    "    epsilons,\n",
    "    criterion,\n",
    "    device,\n",
    "    output_dir=\"fgsm_results\",\n",
    "    mean=0,\n",
    "    std=1,\n",
    "    sr=24000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Testuje atak FGSM dla różnych wartości epsilon\n",
    "\n",
    "    Parametry:\n",
    "    - model: model do testowania\n",
    "    - test_loader: DataLoader z danymi testowymi\n",
    "    - epsilons: lista wartości epsilon\n",
    "    - criterion: funkcja straty\n",
    "    - device: urządzenie obliczeniowe\n",
    "    - output_dir: katalog wyjściowy\n",
    "    - mean, std: parametry normalizacji\n",
    "    - sr: sampling rate\n",
    "\n",
    "    Zwraca:\n",
    "    - all_results: wyniki dla wszystkich epsilon\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    all_results = {}\n",
    "\n",
    "    for epsilon in epsilons:\n",
    "        epsilon_dir = os.path.join(output_dir, f\"epsilon_{epsilon}\")\n",
    "        results = process_adversarial_batch(\n",
    "            model, test_loader, epsilon, criterion, device, epsilon_dir, mean, std, sr\n",
    "        )\n",
    "        all_results[epsilon] = results\n",
    "\n",
    "    # Wygeneruj wykres podsumowujący\n",
    "    plot_adversarial_results(all_results, output_dir)\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wizualizacja wyników ataku adwersalnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adversarial_results(results_dict, output_dir):\n",
    "    \"\"\"\n",
    "    Tworzy wykres wyników ataku adwersalnego\n",
    "    \"\"\"\n",
    "    epsilons = list(results_dict.keys())\n",
    "    original_acc = [results_dict[eps][\"original_accuracy\"] for eps in epsilons]\n",
    "    adversarial_acc = [results_dict[eps][\"adversarial_accuracy\"] for eps in epsilons]\n",
    "    attack_success = [results_dict[eps][\"attack_success_rate\"] for eps in epsilons]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Wykres 1: Dokładność vs Epsilon\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epsilons, original_acc, \"b-o\", label=\"Oryginalna dokładność\")\n",
    "    plt.plot(epsilons, adversarial_acc, \"r-o\", label=\"Dokładność po ataku\")\n",
    "    plt.xlabel(\"Epsilon\")\n",
    "    plt.ylabel(\"Dokładność\")\n",
    "    plt.title(\"Dokładność vs Siła ataku\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Wykres 2: Sukces ataku vs Epsilon\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epsilons, attack_success, \"g-o\", label=\"Sukces ataku\")\n",
    "    plt.xlabel(\"Epsilon\")\n",
    "    plt.ylabel(\"Wskaźnik sukcesu ataku\")\n",
    "    plt.title(\"Skuteczność ataku vs Epsilon\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Wykres 3: Degradacja wydajności\n",
    "    plt.subplot(2, 2, 3)\n",
    "    performance_drop = [orig - adv for orig, adv in zip(original_acc, adversarial_acc)]\n",
    "    plt.plot(epsilons, performance_drop, \"m-o\", label=\"Spadek wydajności\")\n",
    "    plt.xlabel(\"Epsilon\")\n",
    "    plt.ylabel(\"Spadek dokładności\")\n",
    "    plt.title(\"Degradacja wydajności\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Tabela wyników\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.axis(\"tight\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    table_data = []\n",
    "    for eps in epsilons:\n",
    "        table_data.append(\n",
    "            [\n",
    "                f\"{eps:.3f}\",\n",
    "                f\"{results_dict[eps]['original_accuracy']:.3f}\",\n",
    "                f\"{results_dict[eps]['adversarial_accuracy']:.3f}\",\n",
    "                f\"{results_dict[eps]['attack_success_rate']:.3f}\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    table = plt.table(\n",
    "        cellText=table_data,\n",
    "        colLabels=[\"Epsilon\", \"Org. Acc\", \"Adv. Acc\", \"Attack Success\"],\n",
    "        cellLoc=\"center\",\n",
    "        loc=\"center\",\n",
    "    )\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    plt.title(\"Podsumowanie wyników\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(output_dir, \"adversarial_attack_results.png\"),\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Wykres został zapisany w: {output_dir}/adversarial_attack_results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_adversarial_examples(\n",
    "    all_results, epsilons, label_encoder, data_loader, model, device, output_dir\n",
    "):\n",
    "    \"\"\"\n",
    "    Wizualizuje przykłady adwersalne dla melspektrogramów\n",
    "\n",
    "    Parametry:\n",
    "    - all_results: słownik z wynikami ataku dla różnych wartości epsilon\n",
    "    - epsilons: lista wartości epsilon\n",
    "    - label_encoder: enkoder etykiet\n",
    "    - data_loader: DataLoader z danymi testowymi\n",
    "    - model: model do testowania\n",
    "    - device: urządzenie obliczeniowe\n",
    "    - output_dir: katalog do zapisywania wyników\n",
    "    \"\"\"\n",
    "\n",
    "    class_names = label_encoder.classes_\n",
    "\n",
    "    # Utworzenie katalogu dla wizualizacji\n",
    "    visualization_dir = os.path.join(output_dir, \"visualizations\")\n",
    "    os.makedirs(visualization_dir, exist_ok=True)\n",
    "    print(f\"Utworzono katalog: {visualization_dir}\")\n",
    "\n",
    "    # Znajdź przykłady, które zostały błędnie sklasyfikowane po ataku\n",
    "    model.eval()\n",
    "    cnt = 0\n",
    "\n",
    "    # Dla każdego epsilon (pomijając 0)\n",
    "    for eps in epsilons:\n",
    "        if eps == 0 or eps not in all_results:\n",
    "            continue\n",
    "\n",
    "        print(f\"Przetwarzam epsilon={eps}\")\n",
    "\n",
    "        # Utwórz katalog dla danego epsilon\n",
    "        eps_dir = os.path.join(visualization_dir, f\"epsilon_{eps}\")\n",
    "        os.makedirs(eps_dir, exist_ok=True)\n",
    "\n",
    "        # Poszukaj przykładów, dla których atak był skuteczny\n",
    "        example_count = 0\n",
    "        for batch_idx, (data, target) in enumerate(\n",
    "            tqdm(data_loader, desc=f\"Szukanie przykładów dla ε={eps}\")\n",
    "        ):\n",
    "            if example_count >= 5:  # Ograniczenie do 5 przykładów na każdy epsilon\n",
    "                break\n",
    "\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # Oryginalny forward pass\n",
    "            with torch.no_grad():\n",
    "                original_output = model(data)\n",
    "                original_pred = original_output.argmax(dim=1)\n",
    "\n",
    "            # Atak FGSM\n",
    "            perturbed_data, perturbation = fgsm_attack(\n",
    "                model, data, target, eps, criterion\n",
    "            )\n",
    "\n",
    "            # Forward pass na danych po ataku\n",
    "            with torch.no_grad():\n",
    "                adversarial_output = model(perturbed_data)\n",
    "                adversarial_pred = adversarial_output.argmax(dim=1)\n",
    "\n",
    "            # Znajdź przykłady, dla których predykcja się zmieniła\n",
    "            for i in range(data.size(0)):\n",
    "                if original_pred[i] != adversarial_pred[i]:\n",
    "                    # Znaleziono przykład, dla którego atak był skuteczny\n",
    "                    orig_img = data[i].detach().cpu().squeeze(0).numpy()\n",
    "                    adv_img = perturbed_data[i].detach().cpu().squeeze(0).numpy()\n",
    "                    diff_img = adv_img - orig_img\n",
    "\n",
    "                    # Wizualizacja\n",
    "                    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "                    # Oryginalny melspektrogram\n",
    "                    im0 = axes[0].imshow(\n",
    "                        orig_img, aspect=\"auto\", origin=\"lower\", cmap=\"viridis\"\n",
    "                    )\n",
    "                    axes[0].set_title(\n",
    "                        f\"Oryginalny\\nKlasa: {class_names[original_pred[i]]}\"\n",
    "                    )\n",
    "                    axes[0].set_ylabel(\"Mel Bins\")\n",
    "                    axes[0].set_xlabel(\"Frames\")\n",
    "\n",
    "                    # Perturbacja (różnica)\n",
    "                    im1 = axes[1].imshow(\n",
    "                        diff_img, aspect=\"auto\", origin=\"lower\", cmap=\"coolwarm\"\n",
    "                    )\n",
    "                    axes[1].set_title(f\"Perturbacja\\nEpsilon: {eps}\")\n",
    "                    axes[1].set_xlabel(\"Frames\")\n",
    "\n",
    "                    # Przykład adwersalny\n",
    "                    im2 = axes[2].imshow(\n",
    "                        adv_img, aspect=\"auto\", origin=\"lower\", cmap=\"viridis\"\n",
    "                    )\n",
    "                    axes[2].set_title(\n",
    "                        f\"Adwersalny\\nKlasa: {class_names[adversarial_pred[i]]}\"\n",
    "                    )\n",
    "                    axes[2].set_xlabel(\"Frames\")\n",
    "\n",
    "                    # Dodaj paski kolorów\n",
    "                    plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "                    plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "                    plt.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(\n",
    "                        os.path.join(\n",
    "                            eps_dir, f\"adversarial_example_{example_count}.png\"\n",
    "                        )\n",
    "                    )\n",
    "                    plt.close()\n",
    "\n",
    "                    example_count += 1\n",
    "                    cnt += 1\n",
    "\n",
    "                    if (\n",
    "                        example_count >= 5\n",
    "                    ):  # Ograniczenie do 5 przykładów na każdy epsilon\n",
    "                        break\n",
    "\n",
    "            if cnt >= 15:  # Ograniczenie do 15 przykładów łącznie\n",
    "                return\n",
    "\n",
    "    # Jeśli nie znaleziono żadnych przykładów\n",
    "    if cnt == 0:\n",
    "        print(\"Nie znaleziono żadnych przykładów, dla których atak byłby skuteczny.\")\n",
    "        print(\"Spróbuj zwiększyć wartości epsilon lub użyć innego modelu.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uruchomienie ataku dla różnych wartości epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM ε=0: 100%|██████████| 29/29 [00:33<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla ε = 0:\n",
      "Dokładność oryginalna: 0.9130\n",
      "Dokładność po ataku: 0.9130\n",
      "Sukces ataku: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM ε=0.001: 100%|██████████| 29/29 [00:33<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla ε = 0.001:\n",
      "Dokładność oryginalna: 0.9130\n",
      "Dokładność po ataku: 0.8986\n",
      "Sukces ataku: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM ε=0.005: 100%|██████████| 29/29 [00:33<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla ε = 0.005:\n",
      "Dokładność oryginalna: 0.9130\n",
      "Dokładność po ataku: 0.7982\n",
      "Sukces ataku: 0.1148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM ε=0.01: 100%|██████████| 29/29 [00:34<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla ε = 0.01:\n",
      "Dokładność oryginalna: 0.9130\n",
      "Dokładność po ataku: 0.6132\n",
      "Sukces ataku: 0.2999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM ε=0.02: 100%|██████████| 29/29 [00:34<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla ε = 0.02:\n",
      "Dokładność oryginalna: 0.9130\n",
      "Dokładność po ataku: 0.3133\n",
      "Sukces ataku: 0.6020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM ε=0.05: 100%|██████████| 29/29 [00:35<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla ε = 0.05:\n",
      "Dokładność oryginalna: 0.9130\n",
      "Dokładność po ataku: 0.0268\n",
      "Sukces ataku: 0.8896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM ε=0.1: 100%|██████████| 29/29 [00:35<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla ε = 0.1:\n",
      "Dokładność oryginalna: 0.9130\n",
      "Dokładność po ataku: 0.0011\n",
      "Sukces ataku: 0.9175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM ε=0.2: 100%|██████████| 29/29 [00:35<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla ε = 0.2:\n",
      "Dokładność oryginalna: 0.9130\n",
      "Dokładność po ataku: 0.0000\n",
      "Sukces ataku: 0.9186\n",
      "Wykres został zapisany w: fgsm_attack_results/adversarial_attack_results.png\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "epsilons = [0, 0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2]\n",
    "results = test_multiple_epsilons(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    epsilons=epsilons,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    output_dir=\"fgsm_attack_results\",\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    sr=24000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utworzono katalog: fgsm_attack_results\\visualizations\n",
      "Przetwarzam epsilon=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Szukanie przykładów dla ε=0.001:  38%|███▊      | 11/29 [00:14<00:23,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przetwarzam epsilon=0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Szukanie przykładów dla ε=0.005:   3%|▎         | 1/29 [00:03<01:41,  3.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przetwarzam epsilon=0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Szukanie przykładów dla ε=0.02:   0%|          | 0/29 [00:03<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "visualize_adversarial_examples(\n",
    "    all_results=results,\n",
    "    epsilons=[0.001, 0.005, 0.02],\n",
    "    label_encoder=label_encoder,\n",
    "    data_loader=test_loader,\n",
    "    model=model,\n",
    "    device=device,\n",
    "    output_dir=\"fgsm_attack_results\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja podgłaśniająca nagrania wyekstrahowane ze spektrogramów po ataku adwersalnym (pierwotne były bardzo ciche)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podgłośniono: adversarial_batch0_sample0_eps0.2.wav (gain: 9.33)\n",
      "Podgłośniono: adversarial_batch0_sample1_eps0.2.wav (gain: 8.59)\n",
      "Podgłośniono: adversarial_batch0_sample2_eps0.2.wav (gain: 8.07)\n",
      "Podgłośniono: adversarial_batch1_sample0_eps0.2.wav (gain: 9.83)\n",
      "Podgłośniono: adversarial_batch1_sample1_eps0.2.wav (gain: 6.03)\n",
      "Podgłośniono: adversarial_batch1_sample2_eps0.2.wav (gain: 16.56)\n",
      "Podgłośniono: adversarial_batch2_sample0_eps0.2.wav (gain: 9.72)\n",
      "Podgłośniono: adversarial_batch2_sample1_eps0.2.wav (gain: 22.24)\n",
      "Podgłośniono: adversarial_batch2_sample2_eps0.2.wav (gain: 4.88)\n",
      "Podgłośniono: adversarial_batch3_sample0_eps0.2.wav (gain: 5.90)\n",
      "Podgłośniono: adversarial_batch3_sample1_eps0.2.wav (gain: 8.49)\n",
      "Podgłośniono: adversarial_batch3_sample2_eps0.2.wav (gain: 10.43)\n",
      "Podgłośniono: adversarial_batch4_sample0_eps0.2.wav (gain: 5.72)\n",
      "Podgłośniono: adversarial_batch4_sample1_eps0.2.wav (gain: 7.26)\n",
      "Podgłośniono: adversarial_batch4_sample2_eps0.2.wav (gain: 6.65)\n",
      "Podgłośniono: original_batch0_sample0.wav (gain: 12.42)\n",
      "Podgłośniono: original_batch0_sample1.wav (gain: 18.87)\n",
      "Podgłośniono: original_batch0_sample2.wav (gain: 11.55)\n",
      "Podgłośniono: original_batch1_sample0.wav (gain: 17.43)\n",
      "Podgłośniono: original_batch1_sample1.wav (gain: 9.41)\n",
      "Podgłośniono: original_batch1_sample2.wav (gain: 17.45)\n",
      "Podgłośniono: original_batch2_sample0.wav (gain: 16.12)\n",
      "Podgłośniono: original_batch2_sample1.wav (gain: 18.95)\n",
      "Podgłośniono: original_batch2_sample2.wav (gain: 9.69)\n",
      "Podgłośniono: original_batch3_sample0.wav (gain: 10.85)\n",
      "Podgłośniono: original_batch3_sample1.wav (gain: 18.69)\n",
      "Podgłośniono: original_batch3_sample2.wav (gain: 12.03)\n",
      "Podgłośniono: original_batch4_sample0.wav (gain: 11.81)\n",
      "Podgłośniono: original_batch4_sample1.wav (gain: 15.45)\n",
      "Podgłośniono: original_batch4_sample2.wav (gain: 11.27)\n",
      "Podgłaśnianie zakończone.\n"
     ]
    }
   ],
   "source": [
    "def boost_audio_folder(input_folder, output_folder, target_amp=0.9):\n",
    "    \"\"\"\n",
    "    Podgłaśnia wszystkie pliki WAV w folderze input_folder\n",
    "    i zapisuje je w output_folder z maksymalną amplitudą target_amp.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(\".wav\"):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # Wczytanie audio\n",
    "            audio, sr = sf.read(input_path)\n",
    "\n",
    "            # Obliczenie obecnej max amplitudy\n",
    "            max_amp = np.max(np.abs(audio))\n",
    "            if max_amp == 0:\n",
    "                print(f\"Plik {filename} jest pusty lub ma zero amplitudy — pominięty.\")\n",
    "                continue\n",
    "\n",
    "            # Obliczenie wzmocnienia i podgłośnienie\n",
    "            gain = target_amp / max_amp\n",
    "            audio_boosted = audio * gain\n",
    "\n",
    "            # Zapisanie podgłośnionego nagrania\n",
    "            sf.write(output_path, audio_boosted, sr)\n",
    "            print(f\"Podgłośniono: {filename} (gain: {gain:.2f})\")\n",
    "\n",
    "    print(\"Podgłaśnianie zakończone.\")\n",
    "\n",
    "\n",
    "# Przykład użycia:\n",
    "boost_audio_folder(\n",
    "    \"fgsm_attack_results/epsilon_0.2\", \"fgsm_attack_results/epsilon_0.2/new\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analiza podatności poszczególnych klas na atak FGSM dla różnych wartości epsilon\n",
    "Wynikiem działania funkcji są raporty klasyfikacji oraz macierze pomyłek dla modeli \"zaatakowanych\" poszczególnymi wartościami epsilon i porównanie dokładności modelu bazowego do dokładności modeli po ataku. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analizuję podatność poszczególnych klas na atak FGSM dla różnych wartości epsilon...\n",
      "\n",
      "Analiza dla epsilon = 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atak FGSM (eps=0.005): 100%|██████████| 29/29 [00:20<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raport klasyfikacji po ataku FGSM (epsilon=0.005):\n",
      "              precision    recall  f1-score     support\n",
      "anger          0.917293  0.813333  0.862191  150.000000\n",
      "fear           0.885906  0.897959  0.891892  147.000000\n",
      "happiness      0.666667  0.680000  0.673267  150.000000\n",
      "neutral        0.797619  0.827160  0.812121  162.000000\n",
      "sadness        0.871166  0.922078  0.895899  154.000000\n",
      "surprised      0.641221  0.626866  0.633962  134.000000\n",
      "accuracy       0.798216  0.798216  0.798216    0.798216\n",
      "macro avg      0.796645  0.794566  0.794889  897.000000\n",
      "weighted avg   0.799464  0.798216  0.798116  897.000000\n",
      "\n",
      "Analiza dla epsilon = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atak FGSM (eps=0.01): 100%|██████████| 29/29 [00:20<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raport klasyfikacji po ataku FGSM (epsilon=0.01):\n",
      "              precision    recall  f1-score     support\n",
      "anger          0.745283  0.526667  0.617188  150.000000\n",
      "fear           0.754967  0.775510  0.765101  147.000000\n",
      "happiness      0.441176  0.500000  0.468750  150.000000\n",
      "neutral        0.619048  0.641975  0.630303  162.000000\n",
      "sadness        0.757576  0.811688  0.783699  154.000000\n",
      "surprised      0.386861  0.395522  0.391144  134.000000\n",
      "accuracy       0.613155  0.613155  0.613155    0.613155\n",
      "macro avg      0.617485  0.608560  0.609364  897.000000\n",
      "weighted avg   0.621785  0.613155  0.613793  897.000000\n",
      "\n",
      "Analiza dla epsilon = 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atak FGSM (eps=0.02): 100%|██████████| 29/29 [00:21<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raport klasyfikacji po ataku FGSM (epsilon=0.02):\n",
      "              precision    recall  f1-score     support\n",
      "anger          0.407407  0.220000  0.285714  150.000000\n",
      "fear           0.526316  0.544218  0.535117  147.000000\n",
      "happiness      0.192513  0.240000  0.213650  150.000000\n",
      "neutral        0.248521  0.259259  0.253776  162.000000\n",
      "sadness        0.506579  0.500000  0.503268  154.000000\n",
      "surprised      0.083333  0.097015  0.089655  134.000000\n",
      "accuracy       0.313266  0.313266  0.313266    0.313266\n",
      "macro avg      0.327445  0.310082  0.313530  897.000000\n",
      "weighted avg   0.330877  0.313266  0.316829  897.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ewaluacja na oryginalnych danych: 100%|██████████| 29/29 [00:05<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Porównanie dokładności klas przed i po ataku FGSM dla różnych wartości epsilon:\n",
      "           Dokładność bazowa  Dokładność (ε=0.005)  Spadek (ε=0.005)  \\\n",
      "surprised           0.813433              0.626866          0.186567   \n",
      "anger               0.906667              0.813333          0.093333   \n",
      "happiness           0.853333              0.680000          0.173333   \n",
      "neutral             0.950617              0.827160          0.123457   \n",
      "sadness             0.980519              0.922078          0.058442   \n",
      "fear                0.959184              0.897959          0.061224   \n",
      "\n",
      "           Dokładność (ε=0.01)  Spadek (ε=0.01)  Dokładność (ε=0.02)  \\\n",
      "surprised             0.395522         0.417910             0.097015   \n",
      "anger                 0.526667         0.380000             0.220000   \n",
      "happiness             0.500000         0.353333             0.240000   \n",
      "neutral               0.641975         0.308642             0.259259   \n",
      "sadness               0.811688         0.168831             0.500000   \n",
      "fear                  0.775510         0.183673             0.544218   \n",
      "\n",
      "           Spadek (ε=0.02)  Średni spadek  \n",
      "surprised         0.716418       0.440299  \n",
      "anger             0.686667       0.386667  \n",
      "happiness         0.613333       0.380000  \n",
      "neutral           0.691358       0.374486  \n",
      "sadness           0.480519       0.235931  \n",
      "fear              0.414966       0.219955  \n",
      "\n",
      "Analiza zakończona. Wszystkie wyniki zostały zapisane w katalogu: model_outputs\\fgsm_audio_results_20250529_174051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Utworzenie katalogu dla wyników ataku FGSM\n",
    "TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUTPUT_DIR = os.path.join(project_root, \"src\", \"Atak_adw\", \"model_outputs\")\n",
    "FGSM_DIR = os.path.join(OUTPUT_DIR, f\"fgsm_audio_results_{TIMESTAMP}\")\n",
    "os.makedirs(FGSM_DIR, exist_ok=True)  # Utworzenie katalogu dla wykresów i raportów\n",
    "AUDIO_FGSM_DIR = os.path.join(OUTPUT_DIR, f\"fgsm_audio_results_{TIMESTAMP}\")\n",
    "os.makedirs(AUDIO_FGSM_DIR, exist_ok=True)  # Utworzenie katalogu dla audio\n",
    "\n",
    "# Analiza najbardziej podatnych klas na atak dla wielu wartości epsilon\n",
    "print(\n",
    "    \"\\nAnalizuję podatność poszczególnych klas na atak FGSM dla różnych wartości epsilon...\"\n",
    ")\n",
    "\n",
    "# Lista wartości epsilon do analizy podatności klas\n",
    "target_epsilons = [0.005, 0.01, 0.02]\n",
    "\n",
    "# Słownik do przechowywania wyników dla każdej wartości epsilon\n",
    "class_accuracy_results = {}\n",
    "\n",
    "# Dla każdej wartości epsilon wykonaj analizę\n",
    "for target_epsilon in target_epsilons:\n",
    "    print(f\"\\nAnaliza dla epsilon = {target_epsilon}\")\n",
    "\n",
    "    # Przechowywanie macierzy konfuzji dla ataku\n",
    "    all_preds_adv = []\n",
    "    all_labels_adv = []\n",
    "\n",
    "    # Uruchomienie ataku z wybraną wartością epsilon\n",
    "    model.eval()\n",
    "    for data, target in tqdm(test_loader, desc=f\"Atak FGSM (eps={target_epsilon})\"):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Przeprowadzenie ataku FGSM\n",
    "        # Przeprowadzenie ataku FGSM\n",
    "        perturbed_data, _ = fgsm_attack(\n",
    "            model, data.clone(), target, target_epsilon, criterion\n",
    "        )  # Predykcja na przykładach adwersalnych\n",
    "        with torch.no_grad():\n",
    "            output = model(perturbed_data)\n",
    "\n",
    "        # Wyznaczenie predykcji\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        # Zapisanie predykcji i rzeczywistych etykiet\n",
    "        all_preds_adv.extend(predicted.cpu().numpy())\n",
    "        all_labels_adv.extend(target.cpu().numpy())\n",
    "\n",
    "    # Macierz konfuzji dla ataku\n",
    "    cm_adv = confusion_matrix(all_labels_adv, all_preds_adv)\n",
    "    class_names = label_encoder.classes_\n",
    "\n",
    "    # Wizualizacja macierzy konfuzji dla ataku\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm_normalized_adv = cm_adv.astype(\"float\") / cm_adv.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(\n",
    "        cm_normalized_adv,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap=\"Reds\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "    )\n",
    "    plt.title(f\"Znormalizowana macierz konfuzji po ataku FGSM (ε={target_epsilon})\")\n",
    "    plt.ylabel(\"Rzeczywista etykieta\")\n",
    "    plt.xlabel(\"Przewidziana etykieta\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FGSM_DIR, f\"confusion_matrix_fgsm_{target_epsilon}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Raport klasyfikacji dla ataku\n",
    "    report_adv = classification_report(\n",
    "        all_labels_adv, all_preds_adv, target_names=class_names, output_dict=True\n",
    "    )\n",
    "    report_df_adv = pd.DataFrame(report_adv).transpose()\n",
    "    print(f\"\\nRaport klasyfikacji po ataku FGSM (epsilon={target_epsilon}):\")\n",
    "    print(report_df_adv)\n",
    "    report_df_adv.to_csv(\n",
    "        os.path.join(FGSM_DIR, f\"classification_report_fgsm_{target_epsilon}.csv\")\n",
    "    )\n",
    "\n",
    "    # Zapisanie dokładności dla każdej klasy przy danej wartości epsilon\n",
    "    class_accuracies = {name: report_adv[name][\"recall\"] for name in class_names}\n",
    "    class_accuracy_results[target_epsilon] = class_accuracies\n",
    "\n",
    "# Utworzenie DataFrame z wynikami dla wszystkich wartości epsilon\n",
    "comparison_df = pd.DataFrame(index=class_names)\n",
    "\n",
    "all_preds_orig = []\n",
    "all_labels_orig = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(test_loader, desc=\"Ewaluacja na oryginalnych danych\"):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        all_preds_orig.extend(predicted.cpu().numpy())\n",
    "        all_labels_orig.extend(target.cpu().numpy())\n",
    "\n",
    "# Bazowa dokładność (bez ataku)\n",
    "report = classification_report(\n",
    "    all_labels_orig, all_preds_orig, target_names=class_names, output_dict=True\n",
    ")\n",
    "baseline_accuracies = {name: report[name][\"recall\"] for name in class_names}\n",
    "comparison_df[\"Dokładność bazowa\"] = pd.Series(baseline_accuracies)\n",
    "\n",
    "# Dodanie kolumn dla każdej wartości epsilon\n",
    "for eps in target_epsilons:\n",
    "    comparison_df[f\"Dokładność (ε={eps})\"] = pd.Series(class_accuracy_results[eps])\n",
    "    comparison_df[f\"Spadek (ε={eps})\"] = (\n",
    "        comparison_df[\"Dokładność bazowa\"] - comparison_df[f\"Dokładność (ε={eps})\"]\n",
    "    )\n",
    "\n",
    "# Sortowanie według średniego spadku dokładności\n",
    "comparison_df[\"Średni spadek\"] = comparison_df[\n",
    "    [f\"Spadek (ε={eps})\" for eps in target_epsilons]\n",
    "].mean(axis=1)\n",
    "comparison_df = comparison_df.sort_values(\"Średni spadek\", ascending=False)\n",
    "\n",
    "print(\n",
    "    \"\\nPorównanie dokładności klas przed i po ataku FGSM dla różnych wartości epsilon:\"\n",
    ")\n",
    "print(comparison_df)\n",
    "comparison_df.to_csv(os.path.join(FGSM_DIR, \"accuracy_comparison_all_epsilons.csv\"))\n",
    "\n",
    "# Wizualizacja spadku dokładności dla każdej klasy w funkcji epsilon\n",
    "plt.figure(figsize=(12, 8))\n",
    "for class_name in class_names:\n",
    "    accuracies = [baseline_accuracies[class_name]] + [\n",
    "        class_accuracy_results[eps][class_name] for eps in target_epsilons\n",
    "    ]\n",
    "    plt.plot(\n",
    "        [0] + target_epsilons, accuracies, marker=\"o\", linewidth=2, label=class_name\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Epsilon (siła ataku)\")\n",
    "plt.ylabel(\"Dokładność klasyfikacji\")\n",
    "plt.title(\"Spadek dokładności klasyfikacji emocji pod wpływem ataku FGSM\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.savefig(os.path.join(FGSM_DIR, \"accuracy_vs_epsilon_by_class.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nAnaliza zakończona. Wszystkie wyniki zostały zapisane w katalogu: {FGSM_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PODSUMOWANIE\n",
    "1.\tKrytyczny próg epsilon - wartość ε=0.02 wydaje się być punktem krytycznym, przy którym dokładność spada poniżej 50%.\n",
    "2.\tPodatność na klasy - model wykazuje znacząco różną odporność dla różnych emocji. Klasy \"zaskoczenie\", \"złość\" i \"szczęście\" są znacznie bardziej podatne na ataki niż \"strach\", \"smutek\" i \"neutralność\".\n",
    "3.\tPraktyczna interpretacja - nawet niewielkie perturbacje rzędu ε=0.01 (odpowiadające nieznacznym zmianom pikseli, często niewidocznym dla ludzkiego oka) powodują spadek dokładności o około 26%, co wskazuje na istotną podatność modelu ResNet-18 na ataki adwersalne.\n",
    "4.\tImplikacje dla zastosowań - model wymaga dodatkowych mechanizmów obrony przed atakami adwersalnymi, szczególnie w zastosowaniach krytycznych lub związanych z bezpieczeństwem, gdzie rozpoznawanie emocji może być kluczowym elementem systemu.\n",
    "Przedstawione wyniki potwierdzają znaną w dziedzinie uczenia maszynowego podatność sieci neuronowych na ataki adwersalne typu FGSM, nawet przy zastosowaniu zaawansowanej architektury takiej jak ResNet-18.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Audio Emotion Recognition)",
   "language": "python",
   "name": "audio-emotion-recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
