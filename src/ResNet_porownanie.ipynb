{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importowanie niezbędnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardowe biblioteki Pythona\n",
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Biblioteki naukowe i manipulacja danymi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Biblioteki ML i uczenia głębokiego\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Biblioteki do pracy z dźwiękiem i sygnałami\n",
    "import librosa\n",
    "\n",
    "# Biblioteki do wizualizacji\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Biblioteki do przygotowania danych i oceny modelu\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "        # Tworzenie połączonego wykresu przy użyciu subplots\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Biblioteki specyficzne dla projektu\n",
    "from create_data import download_and_save_dataset\n",
    "from datasets import load_from_disk\n",
    "from config import (\n",
    "    BATCH_SIZE, DATASET_PATH, DROPOUT_RATE, EARLY_STOPPING_PATIENCE, \n",
    "    LEARNING_RATE, MAX_LENGTH, NUM_EPOCHS, SEED, WEIGHT_DECAY, MODEL_DIR\n",
    ")\n",
    "from helpers.augment_for_all_types import AugmentedAudioDataset\n",
    "from helpers.early_stopping import EarlyStopping\n",
    "from helpers.resnet_model_definition import AudioResNet\n",
    "from helpers.utils import find_results_directory, read_results_from_files\n",
    "from helpers.data_proccesing import read_emotion_results\n",
    "from helpers.vizualization import generate_accuracy_comparison_plot, generate_emotion_visualizations\n",
    "\n",
    "# Ustawienie seed dla powtarzalności wyników\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Utworzenie katalogu dla wyników\n",
    "results_dir = 'feature_comparison_results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ładowanie datasetu z dysku...\n"
     ]
    }
   ],
   "source": [
    "# Sprawdź czy folder data istnieje i załaduj dataset\n",
    "dataset_path = DATASET_PATH\n",
    "if os.path.exists(dataset_path):\n",
    "    try:\n",
    "        print(\"Ładowanie datasetu z dysku...\")\n",
    "        dataset = load_from_disk(dataset_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd podczas ładowania datasetu: {e}\")\n",
    "        print(\"Pobieranie datasetu ponownie...\")\n",
    "        dataset = download_and_save_dataset()\n",
    "else:\n",
    "    print(\"Folder 'data' nie istnieje. Pobieranie datasetu...\")\n",
    "    dataset = download_and_save_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_array, sr, feature_type, max_length=3.0, \n",
    "                     n_mels=128, n_mfcc=40, n_chroma=12, \n",
    "                     n_fft=2048, hop_length=512, normalize=True):\n",
    "    \"\"\"Ekstrakcja różnych cech z sygnału audio.\n",
    "    \n",
    "    Args:\n",
    "        audio_array: Sygnał audio w formie tablicy numpy\n",
    "        sr: Częstotliwość próbkowania\n",
    "        feature_type: Typ cechy do ekstrakcji\n",
    "        max_length: Maksymalna długość sygnału w sekundach\n",
    "        n_mels: Liczba pasm melowych dla melspektrogramu\n",
    "        n_mfcc: Liczba współczynników MFCC\n",
    "        n_chroma: Liczba pasm chromatycznych\n",
    "        n_fft: Długość okna dla krótkoterminowej transformaty Fouriera\n",
    "        hop_length: Przesunięcie okna między kolejnymi ramkami\n",
    "        normalize: Czy normalizować wynikowe cechy\n",
    "        \n",
    "    Returns:\n",
    "        Wyekstrahowane cechy w formie tablicy numpy\n",
    "    \"\"\"\n",
    "    # Ujednolicenie długości\n",
    "    target_length = int(max_length * sr)\n",
    "    if len(audio_array) > target_length:\n",
    "        audio_array = audio_array[:target_length]\n",
    "    else:\n",
    "        padding = np.zeros(target_length - len(audio_array))\n",
    "        audio_array = np.concatenate([audio_array, padding])\n",
    "    \n",
    "    feature = None\n",
    "    \n",
    "    if feature_type == \"melspectrogram\":\n",
    "        # Ekstrakcja melspektrogramu\n",
    "        S = librosa.feature.melspectrogram(\n",
    "            y=audio_array, sr=sr, n_mels=n_mels,\n",
    "            n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "        feature = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    elif feature_type == \"spectrogram\":\n",
    "        # Standardowy spektrogram\n",
    "        D = np.abs(librosa.stft(audio_array, n_fft=n_fft, hop_length=hop_length))\n",
    "        feature = librosa.amplitude_to_db(D, ref=np.max)\n",
    "    \n",
    "    elif feature_type == \"mfcc\":\n",
    "        # MFCC (Mel-frequency cepstral coefficients)\n",
    "        feature = librosa.feature.mfcc(\n",
    "            y=audio_array, sr=sr, n_mfcc=n_mfcc,\n",
    "            n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "    \n",
    "    elif feature_type == \"chroma\":\n",
    "        # Chromagram\n",
    "        feature = librosa.feature.chroma_stft(\n",
    "            y=audio_array, sr=sr, n_chroma=n_chroma,\n",
    "            n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "    \n",
    "    elif feature_type == \"spectral_contrast\":\n",
    "        # Spektralny kontrast\n",
    "        feature = librosa.feature.spectral_contrast(\n",
    "            y=audio_array, sr=sr, n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "    \n",
    "    elif feature_type == \"zcr\":\n",
    "    # Zero Crossing Rate\n",
    "        feature = librosa.feature.zero_crossing_rate(\n",
    "            audio_array, hop_length=hop_length\n",
    "        )\n",
    "        # Zawsze rozszerzaj wymiar dla ZCR\n",
    "        expanded = np.zeros((n_mels, feature.shape[1]))\n",
    "        normalized_feature = (feature - np.min(feature)) / (np.max(feature) - np.min(feature) + 1e-8)\n",
    "        for i in range(n_mels):\n",
    "            scale_factor = 1.0 - (i / float(n_mels))\n",
    "            expanded[i, :] = normalized_feature * scale_factor\n",
    "        feature = expanded\n",
    "\n",
    "    elif feature_type == \"rms\":\n",
    "        # RMS Energy\n",
    "        feature = librosa.feature.rms(\n",
    "            y=audio_array, hop_length=hop_length\n",
    "        )\n",
    "        # Zawsze rozszerzaj wymiar dla RMS\n",
    "        expanded = np.zeros((n_mels, feature.shape[1]))\n",
    "        normalized_feature = (feature - np.min(feature)) / (np.max(feature) - np.min(feature) + 1e-8)\n",
    "        for i in range(n_mels):\n",
    "            scale_factor = np.exp(-3.0 * (i / float(n_mels)))\n",
    "            expanded[i, :] = normalized_feature * scale_factor\n",
    "        feature = expanded\n",
    "\n",
    "    elif feature_type == \"tempogram\":\n",
    "        # Tempogram\n",
    "        feature = librosa.feature.tempogram(\n",
    "            y=audio_array, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "    \n",
    "    elif feature_type == \"tonnetz\":\n",
    "        # Tonnetz - harmoniczne relacje\n",
    "        y_harm = librosa.effects.harmonic(audio_array, margin=4.0)\n",
    "        chroma = librosa.feature.chroma_cqt(\n",
    "            y=y_harm, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "        feature = librosa.feature.tonnetz(chroma=chroma, sr=sr)\n",
    "    \n",
    "    elif feature_type == \"delta_mfcc\":\n",
    "        # Delta MFCC - zmiany w MFCC\n",
    "        mfccs = librosa.feature.mfcc(\n",
    "            y=audio_array, sr=sr, n_mfcc=n_mfcc,\n",
    "            n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "        feature = librosa.feature.delta(mfccs)\n",
    "    \n",
    "    elif feature_type == \"delta_tempogram\":\n",
    "        # Delta Tempogram - zmiany w tempie\n",
    "        tempogram = librosa.feature.tempogram(\n",
    "            y=audio_array, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "        feature = librosa.feature.delta(tempogram)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Nieznany typ cechy: {feature_type}\")\n",
    "    \n",
    "    # Normalizacja cech (opcjonalna, ale zalecana)\n",
    "    if normalize and feature is not None:\n",
    "        if feature_type in [\"mfcc\", \"delta_mfcc\"]:\n",
    "            # Normalizacja MFCC - już zaimplementowana\n",
    "            feature = librosa.util.normalize(feature)\n",
    "        elif feature_type in [\"melspectrogram\", \"spectrogram\"]:\n",
    "            # Dla spektrogramów - już przekształcone do dB\n",
    "            pass\n",
    "        else:\n",
    "            # Standardowa normalizacja min-max dla pozostałych cech\n",
    "            feature_min = np.min(feature)\n",
    "            feature_max = np.max(feature)\n",
    "            if feature_max > feature_min:\n",
    "                feature = (feature - feature_min) / (feature_max - feature_min)\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset, feature_type, max_length=3.0,\n",
    "                    n_mels=128, n_mfcc=40, n_chroma=12,\n",
    "                    n_fft=2048, hop_length=512, \n",
    "                    normalize_features=True, normalize_dataset=True,\n",
    "                    n_jobs=-1, cache_dir=\"processed_features\",\n",
    "                    force_recompute=False, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Równoległe przetwarzanie całego zbioru danych audio na wybrany typ cechy z obsługą cache i walidacją krzyżową.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Zbiór danych zawierający próbki audio\n",
    "        feature_type: Typ cechy do ekstrakcji\n",
    "        max_length: Maksymalna długość próbki audio w sekundach\n",
    "        n_mels: Liczba pasm melowych dla melspektrogramu\n",
    "        n_mfcc: Liczba współczynników MFCC\n",
    "        n_chroma: Liczba pasm chromatycznych\n",
    "        n_fft: Długość okna FFT\n",
    "        hop_length: Długość przeskoku między kolejnymi ramkami\n",
    "        normalize_features: Czy normalizować pojedyncze cechy\n",
    "        normalize_dataset: Czy normalizować cały zbiór danych\n",
    "        n_jobs: Liczba równoległych procesów (-1 oznacza wszystkie dostępne rdzenie)\n",
    "        cache_dir: Katalog do zapisywania przetworzonych cech\n",
    "        force_recompute: Czy wymusić ponowne obliczenie cech, nawet jeśli istnieją w cache\n",
    "        cv_folds: Liczba foldów do walidacji krzyżowej\n",
    "        \n",
    "    Returns:\n",
    "        dict: Słownik zawierający dane treningowe, walidacyjne i testowe oraz metadane\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Tworzenie katalogu cache, jeśli nie istnieje\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    \n",
    "    # Generowanie unikalnego ID dla tego zestawu parametrów\n",
    "    params_str = f\"{feature_type}_{max_length}_{n_mels}_{n_mfcc}_{n_chroma}_{n_fft}_{hop_length}_{normalize_features}_{normalize_dataset}_{cv_folds}\"\n",
    "    cache_id = hashlib.md5(params_str.encode()).hexdigest()\n",
    "    cache_file = os.path.join(cache_dir, f\"{feature_type}_{cache_id}.pkl\")\n",
    "    \n",
    "    # Sprawdzenie, czy istnieje już plik cache\n",
    "    if os.path.exists(cache_file) and not force_recompute:\n",
    "        print(f\"Wczytywanie przetworzonych cech z pliku cache: {cache_file}\")\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    print(f\"Przetwarzanie próbek audio dla cechy: {feature_type}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Przygotowanie danych do przetwarzania\n",
    "    audio_samples = []\n",
    "    all_labels = []\n",
    "    sample_ids = []\n",
    "    \n",
    "    for i, sample in enumerate(dataset['train']):\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Przygotowywanie {i}/{len(dataset['train'])} próbek\")\n",
    "        sample_ids.append(i)\n",
    "        audio_samples.append((sample['audio']['array'], sample['audio']['sampling_rate']))\n",
    "        all_labels.append(sample['emotion'])\n",
    "    \n",
    "    # Funkcja do przetwarzania pojedynczej próbki\n",
    "    def process_single_sample(i, audio_data):\n",
    "        audio_array, sr = audio_data\n",
    "        try:\n",
    "            feature = extract_features(\n",
    "                audio_array, sr, feature_type, max_length,\n",
    "                n_mels=n_mels, n_mfcc=n_mfcc, n_chroma=n_chroma,\n",
    "                n_fft=n_fft, hop_length=hop_length,\n",
    "                normalize=normalize_features\n",
    "            )\n",
    "            \n",
    "            if feature.size == 0 or (feature.ndim > 1 and feature.shape[1] == 0):\n",
    "                return i, None, \"Empty feature\"\n",
    "                \n",
    "            return i, feature, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            return i, None, str(e)\n",
    "    \n",
    "    # Równoległe przetwarzanie próbek\n",
    "    print(f\"Rozpoczęcie równoległego przetwarzania na {n_jobs if n_jobs > 0 else 'wszystkich dostępnych'} rdzeniach...\")\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_single_sample)(i, audio_data) \n",
    "        for i, audio_data in enumerate(audio_samples)\n",
    "    )\n",
    "    \n",
    "    # Zbieranie wyników\n",
    "    processed_features = []\n",
    "    valid_indices = []\n",
    "    error_count = 0\n",
    "    \n",
    "    for i, feature, error in results:\n",
    "        if feature is not None:\n",
    "            processed_features.append(feature)\n",
    "            valid_indices.append(i)\n",
    "        else:\n",
    "            error_count += 1\n",
    "            # Dodanie logowania błędu, aby wiedzieć dlaczego próbka została odrzucona\n",
    "            if i % 100 == 0 or \"Empty feature\" not in error:  # Loguj co 100 błędów lub niestandardowe błędy\n",
    "                print(f\"Błąd przy próbce {i}: {error}\")\n",
    "            \n",
    "    # Konwersja list na tablice numpy\n",
    "    if len(processed_features) == 0:\n",
    "        raise ValueError(f\"Nie udało się przetworzyć żadnych próbek dla cechy {feature_type}\")\n",
    "    \n",
    "    features = np.array(processed_features)\n",
    "    valid_labels = [all_labels[i] for i in valid_indices]\n",
    "    \n",
    "    # Przekształcenie do odpowiedniego formatu 4D: [próbki, kanały, wysokość, szerokość]\n",
    "    features = features.reshape(features.shape[0], 1, features.shape[1], features.shape[2])\n",
    "    \n",
    "    # Kodowanie etykiet\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(valid_labels)\n",
    "    num_classes = len(np.unique(encoded_labels))\n",
    "    \n",
    "    # Normalizacja całego zbioru danych (opcjonalnie)\n",
    "    if normalize_dataset:\n",
    "        mean = np.mean(features)\n",
    "        std = np.std(features)\n",
    "        if std > 0:\n",
    "            features = (features - mean) / std\n",
    "    \n",
    "    # Tworzenie foldów dla walidacji krzyżowej\n",
    "    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cv_splits = list(skf.split(features, encoded_labels))\n",
    "    \n",
    "    # Przygotowanie słownika wynikowego\n",
    "    result = {\n",
    "        'feature_type': feature_type,\n",
    "        'features': features,\n",
    "        'labels': encoded_labels,\n",
    "        'label_encoder': label_encoder,\n",
    "        'num_classes': num_classes,\n",
    "        'cv_splits': cv_splits,\n",
    "        'params': {\n",
    "            'max_length': max_length,\n",
    "            'n_mels': n_mels,\n",
    "            'n_mfcc': n_mfcc,\n",
    "            'n_chroma': n_chroma,\n",
    "            'n_fft': n_fft,\n",
    "            'hop_length': hop_length,\n",
    "            'normalize_features': normalize_features,\n",
    "            'normalize_dataset': normalize_dataset\n",
    "        },\n",
    "        'processing_time': time.time() - start_time\n",
    "    }\n",
    "    \n",
    "    # Wyświetl statystyki\n",
    "    print(f\"Całkowita liczba próbek: {len(audio_samples)}\")\n",
    "    print(f\"Liczba ważnych próbek: {len(valid_indices)}\")\n",
    "    print(f\"Liczba pustych/błędnych cech: {error_count}\")\n",
    "    print(f\"Liczba klas emocji: {num_classes}\")\n",
    "    print(f\"Mapowanie klas: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")\n",
    "    print(f\"Czas przetwarzania: {result['processing_time']:.2f} sekund\")\n",
    "    \n",
    "    # Zapisz wyniki do cache\n",
    "    print(f\"Zapisywanie przetworzonych cech do pliku cache: {cache_file}\")\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_cross_validation(dataset, feature_type, model_class=AudioResNet, \n",
    "                               batch_size=32, learning_rate=0.001, weight_decay=1e-5,\n",
    "                               epochs=50, patience=10, n_jobs=-1, cache_dir=\"processed_features\"):\n",
    "    \"\"\"\n",
    "    Przeprowadza trening modelu z walidacją krzyżową.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Zbiór danych do przetwarzania\n",
    "        feature_type: Typ cechy do ekstrakcji\n",
    "        model_class: Klasa modelu do użycia\n",
    "        batch_size: Rozmiar batcha\n",
    "        learning_rate: Współczynnik uczenia\n",
    "        weight_decay: Współczynnik regularyzacji\n",
    "        epochs: Maksymalna liczba epok\n",
    "        patience: Liczba epok bez poprawy, po której nastąpi early stopping\n",
    "        n_jobs: Liczba równoległych procesów\n",
    "        cache_dir: Katalog cache dla przetworzonych cech\n",
    "        \n",
    "    Returns:\n",
    "        dict: Wyniki walidacji krzyżowej\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Przetwarzanie danych z walidacją krzyżową\n",
    "    data = process_dataset(dataset, feature_type, n_jobs=n_jobs, cache_dir=cache_dir, cv_folds=5)\n",
    "    \n",
    "    features = data['features']\n",
    "    labels = data['labels']\n",
    "    cv_splits = data['cv_splits']\n",
    "    num_classes = data['num_classes']\n",
    "    \n",
    "    # Wyniki dla każdego foldu\n",
    "    cv_results = []\n",
    "    \n",
    "    # Wykrywanie urządzenia\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Używane urządzenie: {device}\")\n",
    "    \n",
    "    # Przeprowadzenie treningu dla każdego foldu\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv_splits):\n",
    "        print(f\"\\n{'=' * 30} Fold {fold+1}/{len(cv_splits)} {'=' * 30}\")\n",
    "        \n",
    "        # Przygotowanie danych dla tego foldu\n",
    "        X_train, X_val = features[train_idx], features[val_idx]\n",
    "        y_train, y_val = labels[train_idx], labels[val_idx]\n",
    "        \n",
    "        # Konwersja do tensorów PyTorch\n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        y_train_tensor = torch.LongTensor(y_train)\n",
    "        X_val_tensor = torch.FloatTensor(X_val)\n",
    "        y_val_tensor = torch.LongTensor(y_val)\n",
    "        \n",
    "        # Tworzenie DataLoader\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "        \n",
    "        # Tworzenie modelu\n",
    "        input_shape = features[0].shape\n",
    "        model = model_class(input_shape, num_classes).to(device)\n",
    "        \n",
    "        # Definiowanie funkcji straty i optymalizatora\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "        \n",
    "        # Śledzenie najlepszego modelu\n",
    "        best_val_loss = float('inf')\n",
    "        epochs_no_improve = 0\n",
    "        best_epoch = 0\n",
    "        best_model_state = None\n",
    "        \n",
    "        # Statystyki treningu\n",
    "        history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': []\n",
    "        }\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Główna pętla treningu\n",
    "        for epoch in range(epochs):\n",
    "            # Tryb treningowy\n",
    "            model.train()\n",
    "            total_train_loss = 0\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                # Zerowanie gradientów\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                # Backward pass i optymalizacja\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Obliczanie średniej straty treningowej\n",
    "            avg_train_loss = total_train_loss / len(train_dataset)\n",
    "            \n",
    "            # Tryb ewaluacji\n",
    "            model.eval()\n",
    "            total_val_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    total_val_loss += loss.item() * inputs.size(0)\n",
    "                    \n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    correct += (predictions == targets).sum().item()\n",
    "                    total += targets.size(0)\n",
    "            \n",
    "            # Obliczanie średniej straty walidacyjnej i dokładności\n",
    "            avg_val_loss = total_val_loss / len(val_dataset)\n",
    "            val_accuracy = 100.0 * correct / total\n",
    "            \n",
    "            # Aktualizacja scheduler'a\n",
    "            scheduler.step(avg_val_loss)\n",
    "            \n",
    "            # Zapisywanie historii\n",
    "            history['train_loss'].append(avg_train_loss)\n",
    "            history['val_loss'].append(avg_val_loss)\n",
    "            history['val_acc'].append(val_accuracy)\n",
    "            \n",
    "            print(f\"Epoka {epoch+1}/{epochs}, Strata treningu: {avg_train_loss:.4f}, \"\n",
    "                  f\"Strata walidacji: {avg_val_loss:.4f}, Dokładność walidacji: {val_accuracy:.2f}%\")\n",
    "            \n",
    "            # Sprawdzanie Early Stopping\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_epoch = epoch\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= patience:\n",
    "                    print(f\"Early stopping triggered! Brak poprawy przez {patience} epok.\")\n",
    "                    break\n",
    "        \n",
    "        # Czas treningu\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Ładowanie najlepszego modelu\n",
    "        model.load_state_dict(best_model_state)\n",
    "        \n",
    "        # Ewaluacja najlepszego modelu\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                correct += (predictions == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "        \n",
    "        final_accuracy = 100.0 * correct / total\n",
    "        \n",
    "        # Zapisywanie wyników tego foldu\n",
    "        fold_result = {\n",
    "            'fold': fold + 1,\n",
    "            'best_epoch': best_epoch + 1,\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'final_accuracy': final_accuracy,\n",
    "            'training_time': training_time,\n",
    "            'history': history,\n",
    "            'model_state': best_model_state\n",
    "        }\n",
    "        \n",
    "        cv_results.append(fold_result)\n",
    "        \n",
    "        print(f\"\\nWyniki dla foldu {fold+1}:\")\n",
    "        print(f\"Najlepsza epoka: {best_epoch+1}\")\n",
    "        print(f\"Najlepsza strata walidacji: {best_val_loss:.4f}\")\n",
    "        print(f\"Końcowa dokładność: {final_accuracy:.2f}%\")\n",
    "        print(f\"Czas treningu: {training_time:.2f} sekund\")\n",
    "    \n",
    "    # Obliczanie średnich wyników\n",
    "    avg_accuracy = np.mean([res['final_accuracy'] for res in cv_results])\n",
    "    avg_val_loss = np.mean([res['best_val_loss'] for res in cv_results])\n",
    "    avg_training_time = np.mean([res['training_time'] for res in cv_results])\n",
    "    \n",
    "    print(f\"\\n{'=' * 30} Wyniki walidacji krzyżowej {'=' * 30}\")\n",
    "    print(f\"Średnia dokładność: {avg_accuracy:.2f}% ± {np.std([res['final_accuracy'] for res in cv_results]):.2f}%\")\n",
    "    print(f\"Średnia strata walidacji: {avg_val_loss:.4f}\")\n",
    "    print(f\"Średni czas treningu: {avg_training_time:.2f} sekund\")\n",
    "    \n",
    "    # Tworzenie słownika wynikowego\n",
    "    final_results = {\n",
    "        'feature_type': feature_type,\n",
    "        'cv_results': cv_results,\n",
    "        'avg_accuracy': avg_accuracy,\n",
    "        'avg_val_loss': avg_val_loss,\n",
    "        'avg_training_time': avg_training_time,\n",
    "        'params': data['params'],\n",
    "        'label_encoder': data['label_encoder'],\n",
    "        'num_classes': num_classes\n",
    "    }\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Funkcja collate_fn dla DataLoader, z poprawioną obsługą ZCR i RMS.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for feature, label in batch:\n",
    "        # Pomiń None i tensory bez wymiarów\n",
    "        if feature is None or feature.numel() == 0:\n",
    "            continue\n",
    "            \n",
    "        # Upewnij się, że tensor ma prawidłowy format\n",
    "        if feature.dim() == 2:  # Jeden wymiar + kanał\n",
    "            # Rozszerz do 4D\n",
    "            feature = feature.unsqueeze(0).unsqueeze(0)  # [H,W] -> [1,1,H,W]\n",
    "        elif feature.dim() == 3:  # Cechy 2D bez kanału lub 1D z batch\n",
    "            if feature.shape[0] == 1:  # Format [1, H, W]\n",
    "                feature = feature.unsqueeze(0)  # [1,H,W] -> [1,1,H,W]\n",
    "            else:  # Format [B, H, W]\n",
    "                feature = feature.unsqueeze(1)  # [B,H,W] -> [B,1,H,W]\n",
    "                \n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "    \n",
    "    # if len(features) == 0:\n",
    "    #     print(\"Ostrzeżenie: Wszystkie elementy zostały odrzucone! Zwracam pusty tensor.\")\n",
    "    #     # Zwróć dummy tensor zamiast pustego\n",
    "    #     return torch.zeros((1, 1, 4, 4)), torch.zeros(1, dtype=torch.long)\n",
    "    \n",
    "    # Dopełnij tensory do wspólnego rozmiaru\n",
    "    try:\n",
    "        max_height = max([f.shape[2] for f in features])\n",
    "        max_width = max([f.shape[3] for f in features])\n",
    "        \n",
    "        for i in range(len(features)):\n",
    "            if features[i].shape[2] < max_height or features[i].shape[3] < max_width:\n",
    "                # Dopełnij zerami do pełnego rozmiaru\n",
    "                padded = torch.zeros(features[i].shape[0], features[i].shape[1], \n",
    "                                    max_height, max_width, \n",
    "                                    device=features[i].device, dtype=features[i].dtype)\n",
    "                padded[:, :, :features[i].shape[2], :features[i].shape[3]] = features[i]\n",
    "                features[i] = padded\n",
    "        \n",
    "        features_batch = torch.cat(features, dim=0)\n",
    "        labels_batch = torch.tensor(labels)\n",
    "        \n",
    "        return features_batch, labels_batch\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd podczas tworzenia batch: {e}\")\n",
    "        print(f\"Kształty tensorów: {[f.shape for f in features]}\")\n",
    "        # Zwróć dummy tensor, aby zobaczyć gdzie jest problem\n",
    "        return torch.zeros((1, 1, 4, 4)), torch.zeros(1, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotowywanie danych z odpowiednią augmentacją\n",
    "def prepare_datasets(X_train, X_val, X_test, y_train, y_val, y_test, feature_type, batch_size):\n",
    "    \"\"\"\n",
    "    Przygotowuje zestawy danych z odpowiednią strategią augmentacji.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tworzenie datasetów z przekazaniem informacji o typie cechy\n",
    "    train_dataset = AugmentedAudioDataset(\n",
    "        X_train, y_train, \n",
    "        feature_type=feature_type,\n",
    "        augment=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = AugmentedAudioDataset(\n",
    "        X_val, y_val, \n",
    "        feature_type=feature_type,\n",
    "        augment=False\n",
    "    )\n",
    "    \n",
    "    test_dataset = AugmentedAudioDataset(\n",
    "        X_test, y_test, \n",
    "        feature_type=feature_type,\n",
    "        augment=False\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=audio_collate_fn\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        collate_fn=audio_collate_fn\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        collate_fn=audio_collate_fn\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Główna funkcja trenująca model dla wybranej cechy\n",
    "def train_model_for_feature(dataset, feature_type, max_length=3.0):\n",
    "    \"\"\"\n",
    "    Trenuje model ResNet dla wybranej reprezentacji dźwięku.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Dataset zawierający próbki audio i etykiety\n",
    "        feature_type: Typ cechy do ekstrakcji (np. 'melspectrogram', 'mfcc')\n",
    "        max_length: Maksymalna długość próbki audio w sekundach\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (model, test_loader, label_encoder, history, feature_dir, timestamp, feature_type, training_time)\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    feature_dir = os.path.join(results_dir, feature_type)\n",
    "    os.makedirs(feature_dir, exist_ok=True)\n",
    "    \n",
    "    # Przetwarzanie danych\n",
    "    processed_data = process_dataset(dataset, feature_type, max_length)\n",
    "    \n",
    "    # Wyodrębnienie potrzebnych wartości ze słownika\n",
    "    features = processed_data['features']\n",
    "    labels = processed_data['labels']\n",
    "    label_encoder = processed_data['label_encoder']\n",
    "    num_classes = processed_data['num_classes']    \n",
    "    # Podział na zbiory\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=SEED, stratify=labels)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=SEED, stratify=y_train)\n",
    "    \n",
    "    # Inicjalizacja modelu, funkcji straty i optymalizatora\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Używane urządzenie: {device}\")\n",
    "    \n",
    "    model = AudioResNet(num_classes=num_classes, dropout_rate=DROPOUT_RATE)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "    \n",
    "    # Wykorzystanie funkcji prepare_datasets do przygotowania danych\n",
    "    train_loader, val_loader, test_loader = prepare_datasets(\n",
    "        X_train, X_val, X_test, \n",
    "        y_train, y_val, y_test, \n",
    "        feature_type=feature_type,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    # Ścieżka do zapisywania modelu\n",
    "    model_path = os.path.join(feature_dir, f'best_model_{feature_type}_{timestamp}.pt')\n",
    "    early_stopping = EarlyStopping(patience=EARLY_STOPPING_PATIENCE, path=model_path)\n",
    "    \n",
    "    # Śledzenie historii treningu\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_accuracy': []\n",
    "    }\n",
    "    \n",
    "    # Trenowanie modelu\n",
    "    print(f\"Rozpoczynanie treningu dla cechy: {feature_type}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Faza treningu\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_loss = running_loss/len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        \n",
    "        # Faza walidacji\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Obliczanie straty walidacyjnej\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Obliczanie dokładności\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        \n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "        \n",
    "        print(f'Epoka {epoch+1}/{NUM_EPOCHS}, Strata treningu: {train_loss:.4f}, '\n",
    "              f'Strata walidacji: {val_loss:.4f}, Dokładność walidacji: {val_accuracy:.2f}%')\n",
    "        \n",
    "        # Aktualizacja schedulera\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Sprawdzenie warunku early stopping\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping aktywowane!\")\n",
    "            break\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Trening zakończony po {epoch+1} epokach. Czas: {training_time:.2f} sekund\")\n",
    "    \n",
    "    # Wczytanie najlepszego modelu\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    return model, test_loader, label_encoder, history, feature_dir, timestamp, feature_type, training_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, label_encoder, history, feature_dir, timestamp, \n",
    "                  feature_type, training_time, device=None, save_results=True):\n",
    "    \"\"\"\n",
    "    Przeprowadza ewaluację modelu i generuje wizualizacje wyników.\n",
    "    \n",
    "    Args:\n",
    "        model: Wytrenowany model\n",
    "        test_loader: DataLoader z danymi testowymi\n",
    "        label_encoder: Enkoder etykiet\n",
    "        history: Historia treningu\n",
    "        feature_dir: Katalog do zapisywania wyników\n",
    "        timestamp: Znacznik czasowy\n",
    "        feature_type: Typ cechy\n",
    "        training_time: Czas treningu\n",
    "        device: Urządzenie do ewaluacji (CPU/GPU)\n",
    "        save_results: Czy zapisywać wyniki do plików\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (test_accuracy, history)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                # Sprawdzenie czy batch nie jest pusty\n",
    "                if inputs.numel() == 0 or labels.numel() == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Weryfikacja wymiarów danych wejściowych\n",
    "                if inputs.dim() != 4:\n",
    "                    continue\n",
    "                \n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Obliczanie straty testowej\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                # Obliczanie dokładności\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Zapisanie predykcji i rzeczywistych etykiet\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        if len(test_loader) > 0:\n",
    "            test_loss = test_loss / len(test_loader)\n",
    "        else:\n",
    "            return 0.0, history\n",
    "            \n",
    "        test_accuracy = 100 * test_correct / test_total if test_total > 0 else 0.0\n",
    "        \n",
    "        if save_results and all_preds and all_labels:\n",
    "            # Macierz konfuzji\n",
    "            cm = confusion_matrix(all_labels, all_preds)\n",
    "            class_names = label_encoder.classes_\n",
    "            \n",
    "            # Wizualizacja macierzy konfuzji\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', \n",
    "                       xticklabels=class_names, yticklabels=class_names)\n",
    "            plt.title(f'Znormalizowana macierz konfuzji - {feature_type}')\n",
    "            plt.ylabel('Rzeczywista etykieta')\n",
    "            plt.xlabel('Przewidziana etykieta')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(feature_dir, f'confusion_matrix_{feature_type}_{timestamp}.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Raport klasyfikacji\n",
    "            report = classification_report(all_labels, all_preds, \n",
    "                                          target_names=class_names, output_dict=True)\n",
    "            report_df = pd.DataFrame(report).transpose()\n",
    "            report_df.to_csv(os.path.join(feature_dir, f'classification_report_{feature_type}_{timestamp}.csv'))\n",
    "            \n",
    "            # Wizualizacja historii treningu\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(history['train_loss'], label='Trening')\n",
    "            plt.plot(history['val_loss'], label='Walidacja')\n",
    "            plt.title(f'Strata podczas treningu - {feature_type}')\n",
    "            plt.xlabel('Epoka')\n",
    "            plt.ylabel('Strata')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(history['val_accuracy'], label='Walidacja')\n",
    "            plt.title(f'Dokładność podczas treningu - {feature_type}')\n",
    "            plt.xlabel('Epoka')\n",
    "            plt.ylabel('Dokładność (%)')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(feature_dir, f'training_history_{feature_type}_{timestamp}.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Zapisanie hiperparametrów i wyników\n",
    "            results = {\n",
    "                'feature_type': feature_type,\n",
    "                'hyperparameters': {\n",
    "                    'batch_size': BATCH_SIZE,\n",
    "                    'initial_lr': LEARNING_RATE,\n",
    "                    'weight_decay': WEIGHT_DECAY,   \n",
    "                    'dropout_rate': DROPOUT_RATE,\n",
    "                    'early_stopping_patience': EARLY_STOPPING_PATIENCE,\n",
    "                    'max_epochs': NUM_EPOCHS,\n",
    "                    'actual_epochs': len(history['train_loss'])\n",
    "                },\n",
    "                'performance': {\n",
    "                    'test_accuracy': test_accuracy,\n",
    "                    'test_loss': test_loss,\n",
    "                    'val_accuracy': history['val_accuracy'][-1] if history['val_accuracy'] else None,\n",
    "                    'val_loss': history['val_loss'][-1] if history['val_loss'] else None,\n",
    "                    'training_time': training_time\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Zapisanie wyników do pliku\n",
    "            with open(os.path.join(feature_dir, f'results_{feature_type}_{timestamp}.txt'), 'w') as f:\n",
    "                for section, values in results.items():\n",
    "                    if isinstance(values, dict):\n",
    "                        f.write(f\"{section.upper()}:\\n\")\n",
    "                        for key, value in values.items():\n",
    "                            f.write(f\"  {key}: {value}\\n\")\n",
    "                        f.write(\"\\n\")\n",
    "                    else:\n",
    "                        f.write(f\"{section}: {values}\\n\\n\")\n",
    "                        \n",
    "        return test_accuracy, history\n",
    "        \n",
    "    except Exception as e:\n",
    "        return 0.0, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista wszystkich cech do przetestowania\n",
    "feature_types = [\n",
    "    \"spectrogram\",\n",
    "    \"melspectrogram\",\n",
    "    \"mfcc\",\n",
    "    \"chroma\",\n",
    "    \"spectral_contrast\",\n",
    "    \"zcr\",\n",
    "    \"rms\",\n",
    "    \"tempogram\",\n",
    "    \"tonnetz\", \n",
    "    \"delta_mfcc\", \n",
    "    \"delta_tempogram\"  \n",
    "]\n",
    "\n",
    "def run_feature_comparison_experiment(dataset, feature_types_to_run=None, \n",
    "                                     skip_trained=True, save_interim=True,\n",
    "                                     n_mels=128, n_mfcc=40, n_chroma=12,\n",
    "                                     n_fft=2048, hop_length=512, \n",
    "                                     normalize_features=True, normalize_dataset=True):\n",
    "    \"\"\"\n",
    "    Uruchamia eksperymenty dla różnych reprezentacji dźwięku i porównuje wyniki.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Zbiór danych do przetwarzania\n",
    "        feature_types_to_run: Lista typów cech do uruchomienia (domyślnie wszystkie)\n",
    "        skip_trained: Czy pomijać cechy, dla których istnieją już wyniki\n",
    "        save_interim: Czy zapisywać wyniki częściowe po każdym typie cechy\n",
    "        n_mels: Liczba pasm melowych dla melspektrogramu\n",
    "        n_mfcc: Liczba współczynników MFCC\n",
    "        n_chroma: Liczba pasm chromatycznych\n",
    "        n_fft: Długość okna FFT\n",
    "        hop_length: Długość przeskoku między kolejnymi ramkami\n",
    "        normalize_features: Czy normalizować pojedyncze cechy\n",
    "        normalize_dataset: Czy normalizować cały zbiór danych\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame z podsumowaniem wyników\n",
    "    \"\"\"\n",
    "    \n",
    "    # Katalog wyników\n",
    "    results_dir = 'feature_comparison_results'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Inicjalizacja słownika wyników\n",
    "    results = {}\n",
    "    \n",
    "    # Użyj przekazanej listy cech lub domyślnie wszystkich\n",
    "    if feature_types_to_run is None:\n",
    "        feature_types_to_run = feature_types\n",
    "    \n",
    "    # Sprawdź, czy istnieją wcześniejsze wyniki\n",
    "    summary_path = os.path.join(results_dir, 'feature_comparison_summary.csv')\n",
    "    if os.path.exists(summary_path) and skip_trained:\n",
    "        try:\n",
    "            existing_results = pd.read_csv(summary_path)\n",
    "            trained_features = existing_results['Feature Type'].tolist()\n",
    "            \n",
    "            # Wczytaj istniejące wyniki\n",
    "            for ft in trained_features:\n",
    "                if ft in feature_types_to_run:\n",
    "                    accuracy = existing_results[existing_results['Feature Type'] == ft]['Test Accuracy (%)'].values[0]\n",
    "                    results[ft] = {\n",
    "                        'accuracy': accuracy,\n",
    "                        'history': None  # Historia nie jest zapisywana w CSV\n",
    "                    }\n",
    "            \n",
    "            # Usuń już przetrenowane cechy z listy do uruchomienia\n",
    "            feature_types_to_run = [ft for ft in feature_types_to_run if ft not in trained_features]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Nie udało się wczytać istniejących wyników: {e}\")\n",
    "    \n",
    "    # Uruchamiaj eksperymenty dla każdego typu cechy\n",
    "    start_time_all = time.time()\n",
    "    \n",
    "    for i, feature_type in enumerate(feature_types_to_run):\n",
    "        try:\n",
    "            # Trenowanie modelu z przekazaniem wszystkich parametrów\n",
    "            model, test_loader, label_encoder, history, feature_dir, timestamp, feature_type, training_time = train_model_for_feature(\n",
    "                dataset, feature_type, max_length=MAX_LENGTH,\n",
    "                n_mels=n_mels, n_mfcc=n_mfcc, n_chroma=n_chroma,\n",
    "                n_fft=n_fft, hop_length=hop_length,\n",
    "                normalize_features=normalize_features, \n",
    "                normalize_dataset=normalize_dataset,\n",
    "            )\n",
    "            \n",
    "            # Ewaluacja modelu\n",
    "            device = next(model.parameters()).device\n",
    "            accuracy, history = evaluate_model(\n",
    "                model, test_loader, label_encoder, history, \n",
    "                feature_dir, timestamp, feature_type, \n",
    "                training_time, device\n",
    "            )\n",
    "            \n",
    "            # Zapisz wyniki\n",
    "            results[feature_type] = {\n",
    "                'accuracy': accuracy,\n",
    "                'history': history\n",
    "            }\n",
    "            \n",
    "            # Zapisz częściowe wyniki, jeśli włączono tę opcję\n",
    "            if save_interim:\n",
    "                interim_results = {k: results[k]['accuracy'] for k in results}\n",
    "                interim_df = pd.DataFrame({\n",
    "                    'Feature Type': list(interim_results.keys()),\n",
    "                    'Test Accuracy (%)': list(interim_results.values())\n",
    "                }).sort_values('Test Accuracy (%)', ascending=False)\n",
    "                \n",
    "                interim_df.to_csv(os.path.join(results_dir, 'interim_results.csv'), index=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Zapisz informację o błędzie\n",
    "            results[feature_type] = {\n",
    "                'accuracy': 0.0,\n",
    "                'history': None,\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    total_time = time.time() - start_time_all\n",
    "    \n",
    "    # Dodaj wcześniej przetrenowane cechy\n",
    "    all_results = {}\n",
    "    all_results.update(results)\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        'Feature Type': list(all_results.keys()),\n",
    "        'Test Accuracy (%)': [all_results[ft]['accuracy'] for ft in all_results.keys()]\n",
    "    })\n",
    "    \n",
    "    results_df = results_df.sort_values('Test Accuracy (%)', ascending=False)\n",
    "    \n",
    "    # Zapisz podsumowanie do pliku CSV\n",
    "    results_df.to_csv(os.path.join(results_dir, 'feature_comparison_summary.csv'), index=False)\n",
    "    \n",
    "    # Wizualizacja porównania dokładności\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(results_df['Feature Type'], results_df['Test Accuracy (%)'])\n",
    "    plt.title('Porównanie dokładności dla różnych reprezentacji audio')\n",
    "    plt.xlabel('Typ cechy')\n",
    "    plt.ylabel('Dokładność testu (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, 'accuracy_comparison.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Dodaj wizualizację czasu treningu jeśli dostępne\n",
    "    if any('training_time' in all_results.get(ft, {}) for ft in all_results):\n",
    "        times_df = pd.DataFrame({\n",
    "            'Feature Type': [ft for ft in all_results if 'training_time' in all_results[ft]],\n",
    "            'Training Time (s)': [all_results[ft].get('training_time', 0) for ft in all_results \n",
    "                                 if 'training_time' in all_results[ft]]\n",
    "        })\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(times_df['Feature Type'], times_df['Training Time (s)'])\n",
    "        plt.title('Porównanie czasu treningu dla różnych reprezentacji audio')\n",
    "        plt.xlabel('Typ cechy')\n",
    "        plt.ylabel('Czas treningu (s)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, 'training_time_comparison.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_accuracy_from_results(feature_type, results_base_dir='feature_comparison_results'):\n",
    "    \"\"\"\n",
    "    Odczytuje dokładność z zapisanych wyników dla określonego typu cechy.\n",
    "    \n",
    "    Args:\n",
    "        feature_type: Typ cechy (np. 'mfcc', 'spectrogram')\n",
    "        results_base_dir: Katalog bazowy zawierający wyniki\n",
    "        \n",
    "    Returns:\n",
    "        Dokładność jako liczba zmiennoprzecinkowa lub None, jeśli nie znaleziono\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import json\n",
    "    \n",
    "    feature_dir = os.path.join(results_base_dir, feature_type)\n",
    "    \n",
    "    if not os.path.exists(feature_dir):\n",
    "        return None\n",
    "    \n",
    "    # Szukanie pliku results.json w podfolderach\n",
    "    for root, dirs, files in os.walk(feature_dir):\n",
    "        for file in files:\n",
    "            if file == 'results.json':\n",
    "                try:\n",
    "                    with open(os.path.join(root, file), 'r') as f:\n",
    "                        results = json.load(f)\n",
    "                        # Sprawdź różne możliwe klucze dla dokładności\n",
    "                        for key in ['accuracy', 'test_accuracy', 'val_accuracy']:\n",
    "                            if key in results:\n",
    "                                return float(results[key])\n",
    "                except Exception as e:\n",
    "                    print(f\"Błąd podczas odczytu pliku {os.path.join(root, file)}: {str(e)}\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_experiment(dataset, feature_type=None, skip_trained=False, results_base_dir='feature_comparison_results'):\n",
    "    \"\"\"\n",
    "    Funkcja uruchamiająca trening dla wybranej cechy lub wszystkich cech.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Zbiór danych do treningu\n",
    "        feature_type: Konkretna cecha do treningu (None oznacza wszystkie cechy)\n",
    "        skip_trained: Czy pomijać cechy, dla których istnieją już wyniki\n",
    "        results_base_dir: Katalog bazowy do zapisywania wyników\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame z podsumowaniem wyników\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Lista wszystkich dostępnych typów cech\n",
    "    all_feature_types = [\n",
    "        \"spectrogram\", \"melspectrogram\", \"mfcc\", \"chroma\", \n",
    "        \"spectral_contrast\", \"zcr\", \"rms\", \"tempogram\",\n",
    "        \"tonnetz\", \"delta_mfcc\", \"delta_tempogram\"\n",
    "    ]\n",
    "    \n",
    "    # Ustal, które cechy trenować\n",
    "    feature_types_to_train = [feature_type] if feature_type else all_feature_types\n",
    "    \n",
    "    # Tworzenie katalogów dla wyników\n",
    "    os.makedirs(results_base_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Słowniki do przechowywania wyników i czasów treningu\n",
    "    results = {}\n",
    "    training_times = {}\n",
    "    \n",
    "    # Trening dla każdej cechy\n",
    "    for feat_type in feature_types_to_train:\n",
    "        # Sprawdź, czy już istnieją wyniki dla tej cechy\n",
    "        feature_dir = os.path.join(results_base_dir, feat_type)\n",
    "        \n",
    "        if skip_trained and os.path.exists(feature_dir) and len(os.listdir(feature_dir)) > 0:\n",
    "            print(f\"\\nPomijanie cechy {feat_type.upper()} - znaleziono istniejące wyniki.\")\n",
    "            \n",
    "            # Odczytaj dokładność z istniejących wyników\n",
    "            accuracy = read_accuracy_from_results(feat_type, results_base_dir)\n",
    "            if accuracy:\n",
    "                results[feat_type] = accuracy\n",
    "                print(f\"Odczytana dokładność: {accuracy:.2f}%\")\n",
    "            continue\n",
    "        \n",
    "        # Początek treningu dla danej cechy\n",
    "        print(f\"\\n{'=' * 50}\")\n",
    "        print(f\"Trening modelu na reprezentacji: {feat_type.upper()}\")\n",
    "        print(f\"{'=' * 50}\\n\")\n",
    "        \n",
    "        # Pomiar czasu treningu\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Trening modelu\n",
    "        try:\n",
    "            model, test_loader, label_encoder, history, feature_dir, feat_timestamp, _, training_time = train_model_for_feature(dataset, feat_type)\n",
    "            \n",
    "            # Ewaluacja modelu\n",
    "            device = next(model.parameters()).device\n",
    "            accuracy, _ = evaluate_model(model, test_loader, label_encoder, history, \n",
    "                                        feature_dir, feat_timestamp, feat_type, \n",
    "                                        time.time() - start_time, device)\n",
    "            \n",
    "            results[feat_type] = accuracy\n",
    "            training_times[feat_type] = time.time() - start_time\n",
    "            \n",
    "            print(f\"\\nTrening dla {feat_type} zakończony sukcesem. Dokładność: {accuracy:.2f}%\")\n",
    "            print(f\"Czas treningu: {training_times[feat_type]:.2f} sekund\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nBłąd podczas treningu dla cechy {feat_type}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Generowanie raportu podsumowującego (tylko jeśli trenowano więcej niż jedną cechę)\n",
    "    if len(results) > 1:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Wszystkie treningi zakończone. Generowanie raportu zbiorczego...\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "        \n",
    "        # Tworzenie DataFrame z wynikami\n",
    "        df = pd.DataFrame({\n",
    "            'Feature Type': list(results.keys()),\n",
    "            'Test Accuracy (%)': [results[ft] for ft in results.keys()],\n",
    "            'Training Time (s)': [training_times.get(ft, 0) for ft in results.keys()]\n",
    "        })\n",
    "        \n",
    "        # Sortowanie według dokładności\n",
    "        df = df.sort_values('Test Accuracy (%)', ascending=False)\n",
    "        \n",
    "        # Zapis do CSV\n",
    "        csv_path = os.path.join(results_base_dir, f'accuracy_summary_{timestamp}.csv')\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Zapisano podsumowanie do: {csv_path}\")\n",
    "        \n",
    "        # Tworzenie wykresu dokładności przy użyciu Plotly\n",
    "        fig_accuracy = px.bar(\n",
    "            df, \n",
    "            x='Feature Type', \n",
    "            y='Test Accuracy (%)', \n",
    "            title='Porównanie dokładności dla różnych reprezentacji audio',\n",
    "            color_discrete_sequence=['purple']  # Kolor fioletowy\n",
    "        )\n",
    "        \n",
    "        fig_accuracy.update_layout(\n",
    "            xaxis_title='Typ cechy',\n",
    "            yaxis_title='Dokładność testu (%)',\n",
    "            xaxis_tickangle=-45,\n",
    "            yaxis_range=[0, max(df['Test Accuracy (%)']) * 1.1],\n",
    "            template='plotly_white'\n",
    "        )\n",
    "        \n",
    "        # Dodanie wartości nad słupkami\n",
    "        fig_accuracy.update_traces(\n",
    "            texttemplate='%{y:.1f}%', \n",
    "            textposition='outside'\n",
    "        )\n",
    "        \n",
    "        # Zapisanie wykresu dokładności\n",
    "        accuracy_plot_path = os.path.join(results_base_dir, f'accuracy_comparison_{timestamp}.html')\n",
    "        fig_accuracy.write_html(accuracy_plot_path)\n",
    "        \n",
    "        # Tworzenie wykresu czasu treningu przy użyciu Plotly\n",
    "        fig_time = px.bar(\n",
    "            df, \n",
    "            x='Feature Type', \n",
    "            y='Training Time (s)', \n",
    "            title='Porównanie czasu treningu dla różnych reprezentacji audio',\n",
    "            color_discrete_sequence=['purple']  # Kolor fioletowy\n",
    "        )\n",
    "        \n",
    "        fig_time.update_layout(\n",
    "            xaxis_title='Typ cechy',\n",
    "            yaxis_title='Czas treningu (s)',\n",
    "            xaxis_tickangle=-45,\n",
    "            yaxis_range=[0, max(df['Training Time (s)']) * 1.1],\n",
    "            template='plotly_white'\n",
    "        )\n",
    "        \n",
    "        # Dodanie wartości nad słupkami\n",
    "        fig_time.update_traces(\n",
    "            texttemplate='%{y:.0f}s', \n",
    "            textposition='outside'\n",
    "        )\n",
    "        \n",
    "        # Zapisanie wykresu czasu treningu\n",
    "        time_plot_path = os.path.join(results_base_dir, f'training_time_comparison_{timestamp}.html')\n",
    "        fig_time.write_html(time_plot_path)\n",
    "    \n",
    "        \n",
    "        fig_combined = make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            subplot_titles=('Porównanie dokładności dla różnych reprezentacji audio', \n",
    "                           'Porównanie czasu treningu dla różnych reprezentacji audio')\n",
    "        )\n",
    "        \n",
    "        # Dodanie słupków dokładności\n",
    "        fig_combined.add_trace(\n",
    "            go.Bar(\n",
    "                x=df['Feature Type'], \n",
    "                y=df['Test Accuracy (%)'],\n",
    "                text=df['Test Accuracy (%)'].apply(lambda x: f'{x:.1f}%'),\n",
    "                textposition='outside',\n",
    "                marker_color='purple',\n",
    "                name='Dokładność'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Dodanie słupków czasu treningu\n",
    "        fig_combined.add_trace(\n",
    "            go.Bar(\n",
    "                x=df['Feature Type'], \n",
    "                y=df['Training Time (s)'],\n",
    "                text=df['Training Time (s)'].apply(lambda x: f'{int(x)}s'),\n",
    "                textposition='outside',\n",
    "                marker_color='purple',\n",
    "                name='Czas treningu'\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # Aktualizacja układu\n",
    "        fig_combined.update_layout(\n",
    "            height=600,\n",
    "            width=1200,\n",
    "            showlegend=False,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "        \n",
    "        # Aktualizacja osi X i Y dla obu wykresów\n",
    "        fig_combined.update_xaxes(title_text='Typ cechy', tickangle=-45, row=1, col=1)\n",
    "        fig_combined.update_xaxes(title_text='Typ cechy', tickangle=-45, row=1, col=2)\n",
    "        fig_combined.update_yaxes(title_text='Dokładność testu (%)', range=[0, max(df['Test Accuracy (%)']) * 1.1], row=1, col=1)\n",
    "        fig_combined.update_yaxes(title_text='Czas treningu (s)', range=[0, max(df['Training Time (s)']) * 1.1], row=1, col=2)\n",
    "        \n",
    "        # Zapisanie połączonego wykresu\n",
    "        combined_plot_path = os.path.join(results_base_dir, f'feature_comparison_{timestamp}.html')\n",
    "        fig_combined.write_html(combined_plot_path)\n",
    "        \n",
    "        print(f\"Zapisano interaktywne wizualizacje do: {accuracy_plot_path}, {time_plot_path}, {combined_plot_path}\")\n",
    "        print(\"\\nPodsumowanie wyników:\")\n",
    "        print(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Jeśli trenowano tylko jedną cechę, zwróć wynik\n",
    "    elif len(results) == 1:\n",
    "        feature = list(results.keys())[0]\n",
    "        print(f\"\\nWynik dla cechy {feature}: {results[feature]:.2f}%\")\n",
    "        return results[feature]\n",
    "    \n",
    "    # Jeśli nie trenowano żadnej cechy\n",
    "    else:\n",
    "        print(\"\\nNie przeprowadzono żadnego treningu.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchom trening dla wszystkich typów cech\n",
    "# results_df = run_training_experiment(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uruchom trening tylko dla melspektrogramu\n",
    "# accuracy = run_training_experiment(dataset, feature_type=\"chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pomijanie cechy SPECTROGRAM - znaleziono istniejące wyniki.\n",
      "\n",
      "Pomijanie cechy MELSPECTROGRAM - znaleziono istniejące wyniki.\n",
      "\n",
      "Pomijanie cechy MFCC - znaleziono istniejące wyniki.\n",
      "\n",
      "Pomijanie cechy CHROMA - znaleziono istniejące wyniki.\n",
      "\n",
      "Pomijanie cechy SPECTRAL_CONTRAST - znaleziono istniejące wyniki.\n",
      "\n",
      "Pomijanie cechy ZCR - znaleziono istniejące wyniki.\n",
      "\n",
      "Pomijanie cechy RMS - znaleziono istniejące wyniki.\n",
      "\n",
      "Pomijanie cechy TEMPOGRAM - znaleziono istniejące wyniki.\n",
      "\n",
      "Pomijanie cechy TONNETZ - znaleziono istniejące wyniki.\n",
      "\n",
      "Pomijanie cechy DELTA_MFCC - znaleziono istniejące wyniki.\n",
      "\n",
      "Pomijanie cechy DELTA_TEMPOGRAM - znaleziono istniejące wyniki.\n",
      "\n",
      "Nie przeprowadzono żadnego treningu.\n"
     ]
    }
   ],
   "source": [
    "# # Uruchom trening pomijając cechy, dla których już istnieją wyniki\n",
    "results_df = run_training_experiment(dataset, skip_trained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_all_visualizations():\n",
    "    \"\"\"Generuje i zapisuje wszystkie wizualizacje wyników.\"\"\"\n",
    "    # Znajdź katalog wyników\n",
    "    base_dir = find_results_directory()\n",
    "    if base_dir is None:\n",
    "        return\n",
    "    \n",
    "    # Pobierz wyniki\n",
    "    results_df = read_results_from_files(base_dir)\n",
    "    emotions_df = read_emotion_results(base_dir)\n",
    "    \n",
    "    # Określ katalog zapisu\n",
    "    save_dir = base_dir\n",
    "    \n",
    "    # Przetwórz wyniki dokładności\n",
    "    if results_df is not None and not results_df.empty:\n",
    "        # Sortowanie według dokładności malejąco\n",
    "        results_df = results_df.sort_values('Test Accuracy (%)', ascending=False)\n",
    "        \n",
    "        # Wyświetl DataFrame dla podglądu\n",
    "        print(f\"\\nZnalezione wyniki dokładności:\\n{results_df}\")\n",
    "        \n",
    "        # Zapisz DataFrame do CSV\n",
    "        csv_path = os.path.join(save_dir, 'feature_comparison_summary_auto.csv')\n",
    "        results_df.to_csv(csv_path, index=False)\n",
    "        print(f\"Zapisano wyniki dokładności do: {csv_path}\")\n",
    "        \n",
    "        # Generuj wykres porównania dokładności\n",
    "        combined_path = generate_accuracy_comparison_plot(results_df, save_dir)\n",
    "        print(f\"Zapisano wykres porównania dokładności do: {combined_path}\")\n",
    "    else:\n",
    "        print(\"Brak danych dokładności do wygenerowania wykresów.\")\n",
    "    \n",
    "    # Przetwórz wyniki emocji\n",
    "    if emotions_df is not None and not emotions_df.empty:\n",
    "        # Zapisz DataFrame do CSV\n",
    "        emotions_csv_path = os.path.join(save_dir, 'emotions_comparison_auto.csv')\n",
    "        emotions_df.to_csv(emotions_csv_path, index=False)\n",
    "        print(f\"\\nZapisano wyniki emocji do: {emotions_csv_path}\")\n",
    "        \n",
    "        # Generuj wizualizacje emocji\n",
    "        emotion_paths = generate_emotion_visualizations(emotions_df, results_df, save_dir)\n",
    "        print(\"\\nWygenerowane wizualizacje emocji:\")\n",
    "        for name, path in emotion_paths.items():\n",
    "            if path:\n",
    "                print(f\"- {name}: {path}\")\n",
    "        \n",
    "        print(\"\\nGenerowanie wszystkich wizualizacji zakończone pomyślnie.\")\n",
    "    else:\n",
    "        print(\"Brak danych emocji do wygenerowania wykresów.\")\n",
    "\n",
    "# Uruchom generowanie wszystkich wizualizacji\n",
    "generate_all_visualizations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Audio Emotion Recog",
   "language": "python",
   "name": "audio_emotion_recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
