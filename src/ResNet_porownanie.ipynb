{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importowanie niezbędnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardowe biblioteki Pythona\n",
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Biblioteki do pracy z dźwiękiem i sygnałami\n",
    "import librosa\n",
    "\n",
    "# Biblioteki naukowe i manipulacja danymi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Biblioteki do wizualizacji\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Biblioteki ML i uczenia głębokiego\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Biblioteki do przygotowania danych i oceny modelu\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Tworzenie połączonego wykresu przy użyciu subplots\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Biblioteki specyficzne dla projektu\n",
    "from create_data import download_and_save_dataset\n",
    "from datasets import load_from_disk\n",
    "from config import (\n",
    "    BATCH_SIZE, DATASET_PATH, DROPOUT_RATE, EARLY_STOPPING_PATIENCE, \n",
    "    LEARNING_RATE, MAX_LENGTH, NUM_EPOCHS, SEED, WEIGHT_DECAY\n",
    ")\n",
    "from helpers.augment_for_all_types import AugmentedAudioDataset\n",
    "from helpers.early_stopping import EarlyStopping\n",
    "from helpers.resnet_model_definition import AudioResNet\n",
    "from helpers.utils import find_results_directory, read_results_from_files\n",
    "from helpers.data_proccesing import read_emotion_results\n",
    "from helpers.vizualization import generate_accuracy_comparison_plot, generate_emotion_visualizations\n",
    "\n",
    "# Ustawienie seed dla powtarzalności wyników\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Utworzenie katalogu dla wyników\n",
    "results_dir = 'feature_comparison_results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczęcie ładowania datasetu z dysku...\n"
     ]
    }
   ],
   "source": [
    "# Weryfikacja istnienia folderu z danymi oraz załadowanie zbioru danych\n",
    "dataset_path = DATASET_PATH\n",
    "if os.path.exists(dataset_path):\n",
    "    try:\n",
    "        print(\"Rozpoczęcie ładowania datasetu z dysku...\")\n",
    "        dataset = load_from_disk(dataset_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Wystąpił błąd podczas ładowania datasetu: {e}\")\n",
    "        print(\"Inicjowanie ponownego pobierania datasetu...\")\n",
    "        dataset = download_and_save_dataset()\n",
    "else:\n",
    "    print(\"Folder 'data' nie został znaleziony. Inicjowanie pobierania datasetu...\")\n",
    "    dataset = download_and_save_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_array, sr, feature_type, max_length=3.0, \n",
    "                     n_mels=128, n_mfcc=40, n_chroma=12, \n",
    "                     n_fft=2048, hop_length=512, normalize=True):\n",
    "    \"\"\"Ekstrakcja różnych cech z sygnału audio.\n",
    "    \n",
    "    Args:\n",
    "        audio_array: Sygnał audio w formie tablicy numpy\n",
    "        sr: Częstotliwość próbkowania\n",
    "        feature_type: Typ cechy do ekstrakcji\n",
    "        max_length: Maksymalna długość sygnału w sekundach\n",
    "        n_mels: Liczba pasm melowych dla melspektrogramu\n",
    "        n_mfcc: Liczba współczynników MFCC\n",
    "        n_chroma: Liczba pasm chromatycznych\n",
    "        n_fft: Długość okna dla krótkoterminowej transformaty Fouriera\n",
    "        hop_length: Przesunięcie okna między kolejnymi ramkami\n",
    "        normalize: Czy normalizować wynikowe cechy\n",
    "        \n",
    "    Returns:\n",
    "        Wyekstrahowane cechy w formie tablicy numpy\n",
    "    \"\"\"\n",
    "    # Ustalenie docelowej długości sygnału\n",
    "    target_length = int(max_length * sr)\n",
    "    if len(audio_array) > target_length:\n",
    "        audio_array = audio_array[:target_length]\n",
    "    else:\n",
    "        padding = np.zeros(target_length - len(audio_array))\n",
    "        audio_array = np.concatenate([audio_array, padding])\n",
    "    \n",
    "    feature = None\n",
    "    \n",
    "    if feature_type == \"melspectrogram\":\n",
    "        # Ekstrakcja melspektrogramu\n",
    "        S = librosa.feature.melspectrogram(\n",
    "            y=audio_array, sr=sr, n_mels=n_mels,\n",
    "            n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "        feature = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    elif feature_type == \"spectrogram\":\n",
    "        # Obliczanie standardowego spektrogramu\n",
    "        D = np.abs(librosa.stft(audio_array, n_fft=n_fft, hop_length=hop_length))\n",
    "        feature = librosa.amplitude_to_db(D, ref=np.max)\n",
    "    \n",
    "    elif feature_type == \"mfcc\":\n",
    "        # Obliczanie MFCC (Mel-frequency cepstral coefficients)\n",
    "        feature = librosa.feature.mfcc(\n",
    "            y=audio_array, sr=sr, n_mfcc=n_mfcc,\n",
    "            n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "    \n",
    "    elif feature_type == \"chroma\":\n",
    "        # Obliczanie chromagramu\n",
    "        feature = librosa.feature.chroma_stft(\n",
    "            y=audio_array, sr=sr, n_chroma=n_chroma,\n",
    "            n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "    \n",
    "    elif feature_type == \"spectral_contrast\":\n",
    "        # Obliczanie spektralnego kontrastu\n",
    "        feature = librosa.feature.spectral_contrast(\n",
    "            y=audio_array, sr=sr, n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "    \n",
    "    elif feature_type == \"zcr\":\n",
    "        # Obliczanie Zero Crossing Rate\n",
    "        feature = librosa.feature.zero_crossing_rate(\n",
    "            audio_array, hop_length=hop_length\n",
    "        )\n",
    "        # Rozszerzanie wymiaru dla ZCR\n",
    "        expanded = np.zeros((n_mels, feature.shape[1]))\n",
    "        normalized_feature = (feature - np.min(feature)) / (np.max(feature) - np.min(feature) + 1e-8)\n",
    "        for i in range(n_mels):\n",
    "            scale_factor = 1.0 - (i / float(n_mels))\n",
    "            expanded[i, :] = normalized_feature * scale_factor\n",
    "        feature = expanded\n",
    "\n",
    "    elif feature_type == \"rms\":\n",
    "        # Obliczanie RMS Energy\n",
    "        feature = librosa.feature.rms(\n",
    "            y=audio_array, hop_length=hop_length\n",
    "        )\n",
    "        # Rozszerzanie wymiaru dla RMS\n",
    "        expanded = np.zeros((n_mels, feature.shape[1]))\n",
    "        normalized_feature = (feature - np.min(feature)) / (np.max(feature) - np.min(feature) + 1e-8)\n",
    "        for i in range(n_mels):\n",
    "            scale_factor = np.exp(-3.0 * (i / float(n_mels)))\n",
    "            expanded[i, :] = normalized_feature * scale_factor\n",
    "        feature = expanded\n",
    "\n",
    "    elif feature_type == \"tempogram\":\n",
    "        # Obliczanie tempogramu\n",
    "        feature = librosa.feature.tempogram(\n",
    "            y=audio_array, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "    \n",
    "    elif feature_type == \"tonnetz\":\n",
    "        # Obliczanie Tonnetz - harmonicznych relacji\n",
    "        y_harm = librosa.effects.harmonic(audio_array, margin=4.0)\n",
    "        chroma = librosa.feature.chroma_cqt(\n",
    "            y=y_harm, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "        feature = librosa.feature.tonnetz(chroma=chroma, sr=sr)\n",
    "    \n",
    "    elif feature_type == \"delta_mfcc\":\n",
    "        # Obliczanie Delta MFCC - zmian w MFCC\n",
    "        mfccs = librosa.feature.mfcc(\n",
    "            y=audio_array, sr=sr, n_mfcc=n_mfcc,\n",
    "            n_fft=n_fft, hop_length=hop_length\n",
    "        )\n",
    "        feature = librosa.feature.delta(mfccs)\n",
    "    \n",
    "    elif feature_type == \"delta_tempogram\":\n",
    "        # Obliczanie Delta Tempogram - zmian w tempie\n",
    "        tempogram = librosa.feature.tempogram(\n",
    "            y=audio_array, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "        feature = librosa.feature.delta(tempogram)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Nieznany typ cechy: {feature_type}\")\n",
    "    \n",
    "    # Normalizacja cech (opcjonalna)\n",
    "    if normalize and feature is not None:\n",
    "        if feature_type in [\"mfcc\", \"delta_mfcc\"]:\n",
    "            # Normalizacja MFCC - zaimplementowana\n",
    "            feature = librosa.util.normalize(feature)\n",
    "        elif feature_type in [\"melspectrogram\", \"spectrogram\"]:\n",
    "            # Spektrogramy - przekształcone do dB\n",
    "            pass\n",
    "        else:\n",
    "            # Standardowa normalizacja min-max dla pozostałych cech\n",
    "            feature_min = np.min(feature)\n",
    "            feature_max = np.max(feature)\n",
    "            if feature_max > feature_min:\n",
    "                feature = (feature - feature_min) / (feature_max - feature_min)\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Równoległe Przetwarzanie Zbioru Danych Audio\n",
    "\n",
    "Funkcję `process_dataset` przetwarza zbiór danych audio na wybrany typ cechy (np. melspectrogram, mfcc, chroma) w sposób równoległy, wykorzystując wiele rdzeni procesora. Funkcja ekstraktuje cechy za pomocą `extract_features`, normalizuje dane, koduje etykiety, tworzy podziały do walidacji krzyżowej i zapisuje wyniki do pamięci podręcznej, aby uniknąć ponownego przetwarzania. Wyświetla również statystyki, takie jak liczba przetworzonych próbek i czas wykonania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset, feature_type, max_length=3.0,\n",
    "                    n_mels=128, n_mfcc=40, n_chroma=12,\n",
    "                    n_fft=2048, hop_length=512, \n",
    "                    normalize_features=True, normalize_dataset=True,\n",
    "                    n_jobs=-1, cache_dir=\"processed_features\",\n",
    "                    force_recompute=False, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Równoległe przetwarzanie całego zbioru danych audio na wybrany typ cechy z obsługą cache i walidacją krzyżową.\n",
    "    \n",
    "    Argumenty:\n",
    "        dataset: Zbiór danych zawierający próbki audio.\n",
    "        feature_type: Typ cechy do ekstrakcji.\n",
    "        max_length: Maksymalna długość próbki audio w sekundach.\n",
    "        n_mels: Liczba pasm melowych dla melspektrogramu.\n",
    "        n_mfcc: Liczba współczynników MFCC.\n",
    "        n_chroma: Liczba pasm chromatycznych.\n",
    "        n_fft: Długość okna FFT.\n",
    "        hop_length: Długość przeskoku między kolejnymi ramkami.\n",
    "        normalize_features: Flaga określająca, czy normalizować pojedyncze cechy.\n",
    "        normalize_dataset: Flaga określająca, czy normalizować cały zbiór danych.\n",
    "        n_jobs: Liczba równoległych procesów (-1 oznacza wszystkie dostępne rdzenie).\n",
    "        cache_dir: Katalog do zapisywania przetworzonych cech.\n",
    "        force_recompute: Flaga wymuszająca ponowne obliczenie cech, nawet jeśli istnieją w pamięci podręcznej.\n",
    "        cv_folds: Liczba foldów do walidacji krzyżowej.\n",
    "        \n",
    "    Zwraca:\n",
    "        dict: Słownik zawierający dane treningowe, walidacyjne i testowe oraz metadane.\n",
    "    \"\"\"\n",
    "\n",
    "    # Tworzenie katalogu pamięci podręcznej, jeśli nie istnieje\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    \n",
    "    # Generowanie unikalnego identyfikatora dla zestawu parametrów\n",
    "    params_str = f\"{feature_type}_{max_length}_{n_mels}_{n_mfcc}_{n_chroma}_{n_fft}_{hop_length}_{normalize_features}_{normalize_dataset}_{cv_folds}\"\n",
    "    cache_id = hashlib.md5(params_str.encode()).hexdigest()\n",
    "    cache_file = os.path.join(cache_dir, f\"{feature_type}_{cache_id}.pkl\")\n",
    "    \n",
    "    # Sprawdzanie istnienia pliku pamięci podręcznej\n",
    "    if os.path.exists(cache_file) and not force_recompute:\n",
    "        print(f\"Wczytywanie przetworzonych cech z pliku pamięci podręcznej: {cache_file}\")\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    print(f\"Przetwarzanie próbek audio dla cechy: {feature_type}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Przygotowanie danych do przetwarzania\n",
    "    audio_samples = []\n",
    "    all_labels = []\n",
    "    sample_ids = []\n",
    "    \n",
    "    for i, sample in enumerate(dataset['train']):\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Przygotowywanie {i}/{len(dataset['train'])} próbek\")\n",
    "        sample_ids.append(i)\n",
    "        audio_samples.append((sample['audio']['array'], sample['audio']['sampling_rate']))\n",
    "        all_labels.append(sample['emotion'])\n",
    "    \n",
    "    # Funkcja do przetwarzania pojedynczej próbki audio\n",
    "    def process_single_sample(i, audio_data):\n",
    "        audio_array, sr = audio_data\n",
    "        try:\n",
    "            feature = extract_features(\n",
    "                audio_array, sr, feature_type, max_length,\n",
    "                n_mels=n_mels, n_mfcc=n_mfcc, n_chroma=n_chroma,\n",
    "                n_fft=n_fft, hop_length=hop_length,\n",
    "                normalize=normalize_features\n",
    "            )\n",
    "            \n",
    "            if feature.size == 0 or (feature.ndim > 1 and feature.shape[1] == 0):\n",
    "                return i, None, \"Pusta cecha\"\n",
    "                \n",
    "            return i, feature, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            return i, None, str(e)\n",
    "    \n",
    "    # Równoległe przetwarzanie próbek audio\n",
    "    print(f\"Rozpoczęcie równoległego przetwarzania na {n_jobs if n_jobs > 0 else 'wszystkich dostępnych'} rdzeniach...\")\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_single_sample)(i, audio_data) \n",
    "        for i, audio_data in enumerate(audio_samples)\n",
    "    )\n",
    "    \n",
    "    # Zbieranie wyników przetwarzania\n",
    "    processed_features = []\n",
    "    valid_indices = []\n",
    "    error_count = 0\n",
    "    \n",
    "    for i, feature, error in results:\n",
    "        if feature is not None:\n",
    "            processed_features.append(feature)\n",
    "            valid_indices.append(i)\n",
    "        else:\n",
    "            error_count += 1\n",
    "            # Logowanie błędów dla odrzuconych próbek\n",
    "            if i % 100 == 0 or \"Pusta cecha\" not in error:  # Logowanie co 100 błędów lub niestandardowe błędy\n",
    "                print(f\"Błąd przy próbce {i}: {error}\")\n",
    "            \n",
    "    # Konwersja listy cech na tablicę numpy\n",
    "    if len(processed_features) == 0:\n",
    "        raise ValueError(f\"Nie udało się przetworzyć żadnych próbek dla cechy {feature_type}\")\n",
    "    \n",
    "    features = np.array(processed_features)\n",
    "    valid_labels = [all_labels[i] for i in valid_indices]\n",
    "    \n",
    "    # Przekształcenie do formatu 4D: [próbki, kanały, wysokość, szerokość]\n",
    "    features = features.reshape(features.shape[0], 1, features.shape[1], features.shape[2])\n",
    "    \n",
    "    # Kodowanie etykiet\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(valid_labels)\n",
    "    num_classes = len(np.unique(encoded_labels))\n",
    "    \n",
    "    # Normalizacja całego zbioru danych (opcjonalnie)\n",
    "    if normalize_dataset:\n",
    "        mean = np.mean(features)\n",
    "        std = np.std(features)\n",
    "        if std > 0:\n",
    "            features = (features - mean) / std\n",
    "    \n",
    "    # Tworzenie foldów dla walidacji krzyżowej\n",
    "    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cv_splits = list(skf.split(features, encoded_labels))\n",
    "    \n",
    "    # Przygotowanie słownika wynikowego\n",
    "    result = {\n",
    "        'feature_type': feature_type,\n",
    "        'features': features,\n",
    "        'labels': encoded_labels,\n",
    "        'label_encoder': label_encoder,\n",
    "        'num_classes': num_classes,\n",
    "        'cv_splits': cv_splits,\n",
    "        'params': {\n",
    "            'max_length': max_length,\n",
    "            'n_mels': n_mels,\n",
    "            'n_mfcc': n_mfcc,\n",
    "            'n_chroma': n_chroma,\n",
    "            'n_fft': n_fft,\n",
    "            'hop_length': hop_length,\n",
    "            'normalize_features': normalize_features,\n",
    "            'normalize_dataset': normalize_dataset\n",
    "        },\n",
    "        'processing_time': time.time() - start_time\n",
    "    }\n",
    "    \n",
    "    # Wyświetlanie statystyk przetwarzania\n",
    "    print(f\"Całkowita liczba próbek: {len(audio_samples)}\")\n",
    "    print(f\"Liczba ważnych próbek: {len(valid_indices)}\")\n",
    "    print(f\"Liczba pustych/błędnych cech: {error_count}\")\n",
    "    print(f\"Liczba klas emocji: {num_classes}\")\n",
    "    print(f\"Mapowanie klas: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")\n",
    "    print(f\"Czas przetwarzania: {result['processing_time']:.2f} sekund\")\n",
    "    \n",
    "    # Zapis wyników do pamięci podręcznej\n",
    "    print(f\"Zapisywanie przetworzonych cech do pliku pamięci podręcznej: {cache_file}\")\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Trening Modelu z Walidacją Krzyżową\n",
    "\n",
    " Funkcja `train_with_cross_validation` realizuje trening modelu z wykorzystaniem walidacji krzyżowej. Funkcja przetwarza zbiór danych na wybrane cechy audio za pomocą process_dataset, a następnie trenuje model (domyślnie `AudioResNet` z resnet_model_definition.py) na każdym foldzie walidacji krzyżowej, monitorując stratę i dokładność. Wykorzystuje mechanizm wczesnego zatrzymania (early stopping) i harmonogram uczenia, zapisuje najlepsze modele dla każdego foldu i oblicza średnie wyniki, takie jak dokładność i czas treningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_cross_validation(dataset, feature_type, model_class=AudioResNet, \n",
    "                               batch_size=32, learning_rate=0.001, weight_decay=1e-5,\n",
    "                               epochs=50, patience=10, n_jobs=-1, cache_dir=\"processed_features\"):\n",
    "    \"\"\"\n",
    "    Funkcja realizuje trening modelu z wykorzystaniem walidacji krzyżowej.\n",
    "    \n",
    "    Argumenty:\n",
    "        dataset: Zbiór danych, który będzie przetwarzany.\n",
    "        feature_type: Typ cechy, która ma być wyodrębniona.\n",
    "        model_class: Klasa modelu, która ma być użyta do treningu.\n",
    "        batch_size: Rozmiar partii danych do przetwarzania.\n",
    "        learning_rate: Wartość współczynnika uczenia.\n",
    "        weight_decay: Wartość współczynnika regularyzacji.\n",
    "        epochs: Maksymalna liczba epok treningowych.\n",
    "        patience: Liczba epok bez poprawy, po której następuje zatrzymanie treningu.\n",
    "        n_jobs: Liczba procesów równoległych do użycia.\n",
    "        cache_dir: Katalog, w którym będą przechowywane przetworzone cechy.\n",
    "        \n",
    "    Zwraca:\n",
    "        dict: Wyniki walidacji krzyżowej.\n",
    "    \"\"\"\n",
    "\n",
    "    # Przetwarzanie danych z walidacją krzyżową\n",
    "    data = process_dataset(dataset, feature_type, n_jobs=n_jobs, cache_dir=cache_dir, cv_folds=5)\n",
    "    \n",
    "    features = data['features']\n",
    "    labels = data['labels']\n",
    "    cv_splits = data['cv_splits']\n",
    "    num_classes = data['num_classes']\n",
    "    \n",
    "    # Inicjalizacja listy wyników dla każdego foldu\n",
    "    cv_results = []\n",
    "    \n",
    "    # Ustalenie urządzenia do obliczeń\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Używane urządzenie: {device}\")\n",
    "    \n",
    "    # Pętla treningowa dla każdego foldu\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv_splits):\n",
    "        print(f\"\\n{'=' * 30} Fold {fold+1}/{len(cv_splits)} {'=' * 30}\")\n",
    "        \n",
    "        # Przygotowanie danych dla bieżącego foldu\n",
    "        X_train, X_val = features[train_idx], features[val_idx]\n",
    "        y_train, y_val = labels[train_idx], labels[val_idx]\n",
    "        \n",
    "        # Konwersja danych do tensorów PyTorch\n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        y_train_tensor = torch.LongTensor(y_train)\n",
    "        X_val_tensor = torch.FloatTensor(X_val)\n",
    "        y_val_tensor = torch.LongTensor(y_val)\n",
    "        \n",
    "        # Tworzenie zbiorów danych dla DataLoader\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "        \n",
    "        # Inicjalizacja modelu\n",
    "        input_shape = features[0].shape\n",
    "        model = model_class(input_shape, num_classes).to(device)\n",
    "        \n",
    "        # Ustalenie funkcji straty oraz optymalizatora\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "        \n",
    "        # Inicjalizacja zmiennych do śledzenia najlepszego modelu\n",
    "        best_val_loss = float('inf')\n",
    "        epochs_no_improve = 0\n",
    "        best_epoch = 0\n",
    "        best_model_state = None\n",
    "        \n",
    "        # Historia statystyk treningu\n",
    "        history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': []\n",
    "        }\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Pętla treningowa\n",
    "        for epoch in range(epochs):\n",
    "            # Ustawienie modelu w tryb treningowy\n",
    "            model.train()\n",
    "            total_train_loss = 0\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                # Zerowanie gradientów\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Przechodzenie przez model\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                # Wsteczna propagacja i aktualizacja wag\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Obliczanie średniej straty treningowej\n",
    "            avg_train_loss = total_train_loss / len(train_dataset)\n",
    "            \n",
    "            # Ustawienie modelu w tryb ewaluacji\n",
    "            model.eval()\n",
    "            total_val_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    total_val_loss += loss.item() * inputs.size(0)\n",
    "                    \n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    correct += (predictions == targets).sum().item()\n",
    "                    total += targets.size(0)\n",
    "            \n",
    "            # Obliczanie średniej straty walidacyjnej oraz dokładności\n",
    "            avg_val_loss = total_val_loss / len(val_dataset)\n",
    "            val_accuracy = 100.0 * correct / total\n",
    "            \n",
    "            # Aktualizacja harmonogramu uczenia\n",
    "            scheduler.step(avg_val_loss)\n",
    "            \n",
    "            # Zapis statystyk do historii\n",
    "            history['train_loss'].append(avg_train_loss)\n",
    "            history['val_loss'].append(avg_val_loss)\n",
    "            history['val_acc'].append(val_accuracy)\n",
    "            \n",
    "            print(f\"Epoka {epoch+1}/{epochs}, Strata treningu: {avg_train_loss:.4f}, \"\n",
    "                  f\"Strata walidacji: {avg_val_loss:.4f}, Dokładność walidacji: {val_accuracy:.2f}%\")\n",
    "            \n",
    "            # Sprawdzanie warunków do zatrzymania treningu\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_epoch = epoch\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= patience:\n",
    "                    print(f\"Zatrzymanie treningu! Brak poprawy przez {patience} epok.\")\n",
    "                    break\n",
    "        \n",
    "        # Obliczanie czasu treningu\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Przywracanie najlepszego modelu\n",
    "        model.load_state_dict(best_model_state)\n",
    "        \n",
    "        # Ewaluacja najlepszego modelu\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                correct += (predictions == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "        \n",
    "        final_accuracy = 100.0 * correct / total\n",
    "        \n",
    "        # Zapis wyników dla bieżącego foldu\n",
    "        fold_result = {\n",
    "            'fold': fold + 1,\n",
    "            'best_epoch': best_epoch + 1,\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'final_accuracy': final_accuracy,\n",
    "            'training_time': training_time,\n",
    "            'history': history,\n",
    "            'model_state': best_model_state\n",
    "        }\n",
    "        \n",
    "        cv_results.append(fold_result)\n",
    "        \n",
    "        print(f\"\\nWyniki dla foldu {fold+1}:\")\n",
    "        print(f\"Najlepsza epoka: {best_epoch+1}\")\n",
    "        print(f\"Najlepsza strata walidacji: {best_val_loss:.4f}\")\n",
    "        print(f\"Końcowa dokładność: {final_accuracy:.2f}%\")\n",
    "        print(f\"Czas treningu: {training_time:.2f} sekund\")\n",
    "    \n",
    "    # Obliczanie średnich wyników\n",
    "    avg_accuracy = np.mean([res['final_accuracy'] for res in cv_results])\n",
    "    avg_val_loss = np.mean([res['best_val_loss'] for res in cv_results])\n",
    "    avg_training_time = np.mean([res['training_time'] for res in cv_results])\n",
    "    \n",
    "    print(f\"\\n{'=' * 30} Wyniki walidacji krzyżowej {'=' * 30}\")\n",
    "    print(f\"Średnia dokładność: {avg_accuracy:.2f}% ± {np.std([res['final_accuracy'] for res in cv_results]):.2f}%\")\n",
    "    print(f\"Średnia strata walidacji: {avg_val_loss:.4f}\")\n",
    "    print(f\"Średni czas treningu: {avg_training_time:.2f} sekund\")\n",
    "    \n",
    "    # Tworzenie słownika z wynikami\n",
    "    final_results = {\n",
    "        'feature_type': feature_type,\n",
    "        'cv_results': cv_results,\n",
    "        'avg_accuracy': avg_accuracy,\n",
    "        'avg_val_loss': avg_val_loss,\n",
    "        'avg_training_time': avg_training_time,\n",
    "        'params': data['params'],\n",
    "        'label_encoder': data['label_encoder'],\n",
    "        'num_classes': num_classes\n",
    "    }\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja Collate dla DataLoader Audio\n",
    "\n",
    "Funkcja `audio_collate_fn` jest używana jako `collate_fn` w DataLoader do obsługi danych audio, w szczególności cech takich jak ZCR (Zero Crossing Rate) i RMS (RMS Energy). Funkcja przetwarza batch danych, pomijając puste tensory, dostosowuje wymiary tensorów (rozszerzając je do formatu 4D: [batch, kanały, wysokość, szerokość]), dopełnia je zerami do wspólnego rozmiaru i łączy w jeden batch tensorów cech oraz etykiet. W przypadku błędów zwraca dummy tensor, aby zapobiec przerwaniu procesu treningu.\n",
    "Uzasadnienie użytych featurów:\n",
    "Cechy audio, takie jak ZCR i RMS, są istotne w analizie sygnału, ponieważ dostarczają informacji o dynamice i energii dźwięku, co może być kluczowe w rozpoznawaniu emocji. Funkcja audio_collate_fn została zaprojektowana, aby obsługiwać te cechy, które często mają nietypowe wymiary (np. rozszerzone do 2D w procesie ekstrakcji), zapewniając ich poprawną integrację w batchach danych. Dopełnianie tensorów zerami pozwala na ujednolicenie rozmiarów danych wejściowych do modelu, co jest niezbędne dla architektur głębokich, takich jak ResNet, oczekujących spójnych wymiarów inputu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Funkcja collate_fn dla DataLoader, która obsługuje ZCR i RMS.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for feature, label in batch:\n",
    "        # Pomija elementy None oraz tensory bez wymiarów\n",
    "        if feature is None or feature.numel() == 0:\n",
    "            continue\n",
    "            \n",
    "        # Sprawdza, czy tensor ma prawidłowy format\n",
    "        if feature.dim() == 2:  # Jeden wymiar + kanał\n",
    "            # Rozszerza tensor do formatu 4D\n",
    "            feature = feature.unsqueeze(0).unsqueeze(0)  # [H,W] -> [1,1,H,W]\n",
    "        elif feature.dim() == 3:  # Cechy 2D bez kanału lub 1D z batch\n",
    "            if feature.shape[0] == 1:  # Format [1, H, W]\n",
    "                feature = feature.unsqueeze(0)  # [1,H,W] -> [1,1,H,W]\n",
    "            else:  # Format [B, H, W]\n",
    "                feature = feature.unsqueeze(1)  # [B,H,W] -> [B,1,H,W]\n",
    "                \n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "    \n",
    "    # Dopełnia tensory do wspólnego rozmiaru\n",
    "    try:\n",
    "        max_height = max([f.shape[2] for f in features])\n",
    "        max_width = max([f.shape[3] for f in features])\n",
    "        \n",
    "        for i in range(len(features)):\n",
    "            if features[i].shape[2] < max_height or features[i].shape[3] < max_width:\n",
    "                # Dopełnia zerami do pełnego rozmiaru\n",
    "                padded = torch.zeros(features[i].shape[0], features[i].shape[1], \n",
    "                                    max_height, max_width, \n",
    "                                    device=features[i].device, dtype=features[i].dtype)\n",
    "                padded[:, :, :features[i].shape[2], :features[i].shape[3]] = features[i]\n",
    "                features[i] = padded\n",
    "        \n",
    "        features_batch = torch.cat(features, dim=0)\n",
    "        labels_batch = torch.tensor(labels)\n",
    "        \n",
    "        return features_batch, labels_batch\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd podczas tworzenia batch: {e}\")\n",
    "        print(f\"Kształty tensorów: {[f.shape for f in features]}\")\n",
    "        # Zwraca dummy tensor w przypadku błędu\n",
    "        return torch.zeros((1, 1, 4, 4)), torch.zeros(1, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie Danych i Trening Modelu dla Wybranej Cechy\n",
    "\n",
    "Funkcja `prepare_dataset`s tworzy zestawy danych treningowe, walidacyjne i testowe z zastosowaniem augmentacji dla danych treningowych, korzystając z klasy     `AugmentedAudioDataset`. Funkcja `train_model_for_feature` przetwarza zbiór danych na wybraną cechę audio (np. melspectrogram), dzieli dane na podzbiory, inicjalizuje model AudioResNet, trenuje go z użyciem optymalizatora Adam, harmonogramu uczenia i mechanizmu wczesnego zatrzymania (`EarlyStopping`), a także zapisuje najlepszy model i historię treningu.\n",
    "\n",
    "W poniższym bloku wykorzystujemy klasę `AugmentedAudioDataset` zdefiniowaną w pliku `augment_for_all_types.py`. Ten plik definiuje framework do augmentacji danych audio, oferując różne strategie augmentacji (np. `SpectrogramAugmentation`, `MFCCAugmentation`) dla różnych typów cech (melspectrogram, mfcc, zcr, itp.). Wykorzystuje wzorzec projektowy strategii, umożliwiając dodawanie szumu, maskowanie częstotliwości czy przesunięcia czasowe, co zwiększa różnorodność danych treningowych i pomaga w zapobieganiu przeuczeniu. Klasa `AugmentedAudioDataset` integruje augmentację z procesem ładowania danych do modelu.\n",
    "Wykorzystana również klasa `EarlyStopping` monitoruje stratę walidacyjną podczas treningu. Jeśli strata nie poprawia się przez określoną liczbę epok (parametr patience), trening zostaje zatrzymany, a najlepszy model zapisany. Mechanizm ten zapobiega przeuczeniu i oszczędza czas obliczeń, zatrzymując trening, gdy dalsza poprawa jest mało prawdopodobna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotowanie zestawów danych z odpowiednią augmentacją\n",
    "def prepare_datasets(X_train, X_val, X_test, y_train, y_val, y_test, feature_type, batch_size):\n",
    "    \"\"\"\n",
    "    Przygotowuje zestawy danych z zastosowaniem strategii augmentacji.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tworzenie zbiorów danych z informacją o typie cechy\n",
    "    train_dataset = AugmentedAudioDataset(\n",
    "        X_train, y_train, \n",
    "        feature_type=feature_type,\n",
    "        augment=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = AugmentedAudioDataset(\n",
    "        X_val, y_val, \n",
    "        feature_type=feature_type,\n",
    "        augment=False\n",
    "    )\n",
    "    \n",
    "    test_dataset = AugmentedAudioDataset(\n",
    "        X_test, y_test, \n",
    "        feature_type=feature_type,\n",
    "        augment=False\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=audio_collate_fn\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        collate_fn=audio_collate_fn\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        collate_fn=audio_collate_fn\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Funkcja do trenowania modelu dla wybranej cechy\n",
    "def train_model_for_feature(dataset, feature_type, max_length=3.0):\n",
    "    \"\"\"\n",
    "    Trenuje model ResNet dla wybranej reprezentacji dźwięku.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Zbiór danych zawierający próbki audio i etykiety\n",
    "        feature_type: Typ cechy do ekstrakcji (np. 'melspectrogram', 'mfcc')\n",
    "        max_length: Maksymalna długość próbki audio w sekundach\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (model, test_loader, label_encoder, history, feature_dir, timestamp, feature_type, training_time)\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    feature_dir = os.path.join(results_dir, feature_type)\n",
    "    os.makedirs(feature_dir, exist_ok=True)\n",
    "    \n",
    "    # Przetwarzanie danych\n",
    "    processed_data = process_dataset(dataset, feature_type, max_length)\n",
    "    \n",
    "    # Wyodrębnienie istotnych wartości ze słownika\n",
    "    features = processed_data['features']\n",
    "    labels = processed_data['labels']\n",
    "    label_encoder = processed_data['label_encoder']\n",
    "    num_classes = processed_data['num_classes']    \n",
    "    # Podział na zbiory\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=SEED, stratify=labels)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=SEED, stratify=y_train)\n",
    "    \n",
    "    # Inicjalizacja modelu, funkcji straty i optymalizatora\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Używane urządzenie: {device}\")\n",
    "    \n",
    "    model = AudioResNet(num_classes=num_classes, dropout_rate=DROPOUT_RATE)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    \n",
    "    # Przygotowanie danych za pomocą funkcji prepare_datasets\n",
    "    train_loader, val_loader, test_loader = prepare_datasets(\n",
    "        X_train, X_val, X_test, \n",
    "        y_train, y_val, y_test, \n",
    "        feature_type=feature_type,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    # Ścieżka do zapisywania modelu\n",
    "    model_path = os.path.join(feature_dir, f'best_model_{feature_type}_{timestamp}.pt')\n",
    "    early_stopping = EarlyStopping(patience=EARLY_STOPPING_PATIENCE, path=model_path)\n",
    "    \n",
    "    # Historia treningu\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_accuracy': []\n",
    "    }\n",
    "    \n",
    "    # Proces treningu modelu\n",
    "    print(f\"Rozpoczynanie treningu dla cechy: {feature_type}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Faza treningu\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        \n",
    "        # Faza walidacji\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Obliczanie straty walidacyjnej\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Obliczanie dokładności\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        \n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "        \n",
    "        print(f'Epoka {epoch+1}/{NUM_EPOCHS}, Strata treningu: {train_loss:.4f}, '\n",
    "              f'Strata walidacji: {val_loss:.4f}, Dokładność walidacji: {val_accuracy:.2f}%')\n",
    "        \n",
    "        # Aktualizacja schedulera\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Sprawdzenie warunku early stopping\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Aktywacja early stopping!\")\n",
    "            break\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Zakończenie treningu po {epoch+1} epokach. Czas: {training_time:.2f} sekund\")\n",
    "    \n",
    "    # Wczytanie najlepszego modelu\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    return model, test_loader, label_encoder, history, feature_dir, timestamp, feature_type, training_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja Modelu i Wizualizacja Wyników\n",
    "\n",
    "Funkcja `evaluate_model` przeprowadza ewaluację wytrenowanego modelu na danych testowych. Funkcja oblicza stratę i dokładność testową, generuje macierz konfuzji, raport klasyfikacji oraz wizualizacje historii treningu (strata i dokładność w czasie). Wyniki, w tym hiperparametry i metryki wydajności, są zapisywane do plików w celu dalszej analizy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, label_encoder, history, feature_dir, timestamp, \n",
    "                  feature_type, training_time, device=None, save_results=True):\n",
    "    \"\"\"\n",
    "    Ewaluacja modelu oraz generowanie wizualizacji wyników.\n",
    "    \n",
    "    Args:\n",
    "        model: Wytrenowany model do ewaluacji.\n",
    "        test_loader: DataLoader zawierający dane testowe.\n",
    "        label_encoder: Enkoder etykiet do konwersji etykiet.\n",
    "        history: Historia treningu modelu.\n",
    "        feature_dir: Katalog przeznaczony do zapisywania wyników.\n",
    "        timestamp: Znacznik czasowy dla unikalności plików.\n",
    "        feature_type: Typ cechy, która jest analizowana.\n",
    "        training_time: Czas trwania treningu modelu.\n",
    "        device: Urządzenie, na którym przeprowadzana jest ewaluacja (CPU/GPU).\n",
    "        save_results: Flaga określająca, czy wyniki mają być zapisywane do plików.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Zawiera dokładność testu oraz historię treningu.\n",
    "    \"\"\"\n",
    "    \n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                # Sprawdzenie, czy batch zawiera dane\n",
    "                if inputs.numel() == 0 or labels.numel() == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Weryfikacja wymiarów danych wejściowych\n",
    "                if inputs.dim() != 4:\n",
    "                    continue\n",
    "                \n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Obliczanie straty testowej\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                # Obliczanie dokładności\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Zbieranie predykcji oraz rzeczywistych etykiet\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        if len(test_loader) > 0:\n",
    "            test_loss = test_loss / len(test_loader)\n",
    "        else:\n",
    "            return 0.0, history\n",
    "            \n",
    "        test_accuracy = 100 * test_correct / test_total if test_total > 0 else 0.0\n",
    "        \n",
    "        if save_results and all_preds and all_labels:\n",
    "            # Obliczanie macierzy konfuzji\n",
    "            cm = confusion_matrix(all_labels, all_preds)\n",
    "            class_names = label_encoder.classes_\n",
    "            \n",
    "            # Wizualizacja macierzy konfuzji\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', \n",
    "                       xticklabels=class_names, yticklabels=class_names)\n",
    "            plt.title(f'Znormalizowana macierz konfuzji - {feature_type}')\n",
    "            plt.ylabel('Rzeczywista etykieta')\n",
    "            plt.xlabel('Przewidziana etykieta')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(feature_dir, f'confusion_matrix_{feature_type}_{timestamp}.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Generowanie raportu klasyfikacji\n",
    "            report = classification_report(all_labels, all_preds, \n",
    "                                          target_names=class_names, output_dict=True)\n",
    "            report_df = pd.DataFrame(report).transpose()\n",
    "            report_df.to_csv(os.path.join(feature_dir, f'classification_report_{feature_type}_{timestamp}.csv'))\n",
    "            \n",
    "            # Wizualizacja historii treningu\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(history['train_loss'], label='Trening')\n",
    "            plt.plot(history['val_loss'], label='Walidacja')\n",
    "            plt.title(f'Strata podczas treningu - {feature_type}')\n",
    "            plt.xlabel('Epoka')\n",
    "            plt.ylabel('Strata')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(history['val_accuracy'], label='Walidacja')\n",
    "            plt.title(f'Dokładność podczas treningu - {feature_type}')\n",
    "            plt.xlabel('Epoka')\n",
    "            plt.ylabel('Dokładność (%)')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(feature_dir, f'training_history_{feature_type}_{timestamp}.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Zapisanie hiperparametrów oraz wyników\n",
    "            results = {\n",
    "                'feature_type': feature_type,\n",
    "                'hyperparameters': {\n",
    "                    'batch_size': BATCH_SIZE,\n",
    "                    'initial_lr': LEARNING_RATE,\n",
    "                    'weight_decay': WEIGHT_DECAY,   \n",
    "                    'dropout_rate': DROPOUT_RATE,\n",
    "                    'early_stopping_patience': EARLY_STOPPING_PATIENCE,\n",
    "                    'max_epochs': NUM_EPOCHS,\n",
    "                    'actual_epochs': len(history['train_loss'])\n",
    "                },\n",
    "                'performance': {\n",
    "                    'test_accuracy': test_accuracy,\n",
    "                    'test_loss': test_loss,\n",
    "                    'val_accuracy': history['val_accuracy'][-1] if history['val_accuracy'] else None,\n",
    "                    'val_loss': history['val_loss'][-1] if history['val_loss'] else None,\n",
    "                    'training_time': training_time\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Zapisanie wyników do pliku\n",
    "            with open(os.path.join(feature_dir, f'results_{feature_type}_{timestamp}.txt'), 'w') as f:\n",
    "                for section, values in results.items():\n",
    "                    if isinstance(values, dict):\n",
    "                        f.write(f\"{section.upper()}:\\n\")\n",
    "                        for key, value in values.items():\n",
    "                            f.write(f\"  {key}: {value}\\n\")\n",
    "                        f.write(\"\\n\")\n",
    "                    else:\n",
    "                        f.write(f\"{section}: {values}\\n\\n\")\n",
    "                        \n",
    "        return test_accuracy, history\n",
    "        \n",
    "    except Exception as e:\n",
    "        return 0.0, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksperyment Porównawczy Różnych Reprezentacji Audio\n",
    "\n",
    "Funkcja `run_feature_comparison_experiment` przeprowadza eksperymenty porównawcze dla różnych reprezentacji dźwięku. Funkcja trenuje modele dla każdego typu cechy (np. melspectrogram, mfcc), ewaluuje ich dokładność na danych testowych, zapisuje wyniki częściowe i końcowe do plików CSV oraz generuje wizualizacje porównujące dokładność i czas treningu dla różnych cech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista typów cech do przetestowania\n",
    "feature_types = [\n",
    "    \"spectrogram\",\n",
    "    \"melspectrogram\",\n",
    "    \"mfcc\",\n",
    "    \"chroma\",\n",
    "    \"spectral_contrast\",\n",
    "    \"zcr\",\n",
    "    \"rms\",\n",
    "    \"tempogram\",\n",
    "    \"tonnetz\", \n",
    "    \"delta_mfcc\", \n",
    "    \"delta_tempogram\"  \n",
    "]\n",
    "\n",
    "def run_feature_comparison_experiment(dataset, feature_types_to_run=None, \n",
    "                                     skip_trained=True, save_interim=True,\n",
    "                                     n_mels=128, n_mfcc=40, n_chroma=12,\n",
    "                                     n_fft=2048, hop_length=512, \n",
    "                                     normalize_features=True, normalize_dataset=True):\n",
    "    \"\"\"\n",
    "    Uruchamia eksperymenty dla różnych reprezentacji dźwięku oraz porównuje wyniki.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Zbiór danych do przetwarzania.\n",
    "        feature_types_to_run: Lista typów cech do uruchomienia (domyślnie wszystkie).\n",
    "        skip_trained: Flaga określająca, czy pomijać cechy, dla których istnieją już wyniki.\n",
    "        save_interim: Flaga określająca, czy zapisywać wyniki częściowe po każdym typie cechy.\n",
    "        n_mels: Liczba pasm melowych dla melspektrogramu.\n",
    "        n_mfcc: Liczba współczynników MFCC.\n",
    "        n_chroma: Liczba pasm chromatycznych.\n",
    "        n_fft: Długość okna FFT.\n",
    "        hop_length: Długość przeskoku między kolejnymi ramkami.\n",
    "        normalize_features: Flaga określająca, czy normalizować pojedyncze cechy.\n",
    "        normalize_dataset: Flaga określająca, czy normalizować cały zbiór danych.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame z podsumowaniem wyników.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Katalog do przechowywania wyników\n",
    "    results_dir = 'feature_comparison_results'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Inicjalizacja słownika do przechowywania wyników\n",
    "    results = {}\n",
    "    \n",
    "    # Użycie przekazanej listy cech lub domyślnie wszystkich\n",
    "    if feature_types_to_run is None:\n",
    "        feature_types_to_run = feature_types\n",
    "    \n",
    "    # Sprawdzenie istnienia wcześniejszych wyników\n",
    "    summary_path = os.path.join(results_dir, 'feature_comparison_summary.csv')\n",
    "    if os.path.exists(summary_path) and skip_trained:\n",
    "        try:\n",
    "            existing_results = pd.read_csv(summary_path)\n",
    "            trained_features = existing_results['Feature Type'].tolist()\n",
    "            \n",
    "            # Wczytanie istniejących wyników\n",
    "            for ft in trained_features:\n",
    "                if ft in feature_types_to_run:\n",
    "                    accuracy = existing_results[existing_results['Feature Type'] == ft]['Test Accuracy (%)'].values[0]\n",
    "                    results[ft] = {\n",
    "                        'accuracy': accuracy,\n",
    "                        'history': None\n",
    "                    }\n",
    "            \n",
    "            # Usunięcie przetrenowanych cech z listy do uruchomienia\n",
    "            feature_types_to_run = [ft for ft in feature_types_to_run if ft not in trained_features]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Nie udało się wczytać istniejących wyników: {e}\")\n",
    "    \n",
    "    # Uruchamianie eksperymentów dla każdego typu cechy\n",
    "    start_time_all = time.time()\n",
    "    \n",
    "    for i, feature_type in enumerate(feature_types_to_run):\n",
    "        try:\n",
    "            # Trenowanie modelu z przekazaniem wszystkich parametrów\n",
    "            model, test_loader, label_encoder, history, feature_dir, timestamp, feature_type, training_time = train_model_for_feature(\n",
    "                dataset, feature_type, max_length=MAX_LENGTH,\n",
    "                n_mels=n_mels, n_mfcc=n_mfcc, n_chroma=n_chroma,\n",
    "                n_fft=n_fft, hop_length=hop_length,\n",
    "                normalize_features=normalize_features, \n",
    "                normalize_dataset=normalize_dataset,\n",
    "            )\n",
    "            \n",
    "            # Ewaluacja modelu\n",
    "            device = next(model.parameters()).device\n",
    "            accuracy, history = evaluate_model(\n",
    "                model, test_loader, label_encoder, history, \n",
    "                feature_dir, timestamp, feature_type, \n",
    "                training_time, device\n",
    "            )\n",
    "            \n",
    "            # Zapis wyników\n",
    "            results[feature_type] = {\n",
    "                'accuracy': accuracy,\n",
    "                'history': history\n",
    "            }\n",
    "            \n",
    "            # Zapis częściowych wyników, jeśli włączono tę opcję\n",
    "            if save_interim:\n",
    "                interim_results = {k: results[k]['accuracy'] for k in results}\n",
    "                interim_df = pd.DataFrame({\n",
    "                    'Feature Type': list(interim_results.keys()),\n",
    "                    'Test Accuracy (%)': list(interim_results.values())\n",
    "                }).sort_values('Test Accuracy (%)', ascending=False)\n",
    "                \n",
    "                interim_df.to_csv(os.path.join(results_dir, 'interim_results.csv'), index=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Zapis informacji o błędzie\n",
    "            results[feature_type] = {\n",
    "                'accuracy': 0.0,\n",
    "                'history': None,\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    total_time = time.time() - start_time_all\n",
    "    \n",
    "    # Dodanie wcześniej przetrenowanych cech\n",
    "    all_results = {}\n",
    "    all_results.update(results)\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        'Feature Type': list(all_results.keys()),\n",
    "        'Test Accuracy (%)': [all_results[ft]['accuracy'] for ft in all_results.keys()]\n",
    "    })\n",
    "    \n",
    "    results_df = results_df.sort_values('Test Accuracy (%)', ascending=False)\n",
    "    \n",
    "    # Zapis podsumowania do pliku CSV\n",
    "    results_df.to_csv(os.path.join(results_dir, 'feature_comparison_summary.csv'), index=False)\n",
    "    \n",
    "    # Wizualizacja porównania dokładności\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(results_df['Feature Type'], results_df['Test Accuracy (%)'])\n",
    "    plt.title('Porównanie dokładności dla różnych reprezentacji audio')\n",
    "    plt.xlabel('Typ cechy')\n",
    "    plt.ylabel('Dokładność testu (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, 'accuracy_comparison.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Dodanie wizualizacji czasu treningu, jeśli dostępne\n",
    "    if any('training_time' in all_results.get(ft, {}) for ft in all_results):\n",
    "        times_df = pd.DataFrame({\n",
    "            'Feature Type': [ft for ft in all_results if 'training_time' in all_results[ft]],\n",
    "            'Training Time (s)': [all_results[ft].get('training_time', 0) for ft in all_results \n",
    "                                 if 'training_time' in all_results[ft]]\n",
    "        })\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(times_df['Feature Type'], times_df['Training Time (s)'])\n",
    "        plt.title('Porównanie czasu treningu dla różnych reprezentacji audio')\n",
    "        plt.xlabel('Typ cechy')\n",
    "        plt.ylabel('Czas treningu (s)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, 'training_time_comparison.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odczyt Dokładności z Zapisanych Wyników\n",
    "\n",
    " Funkcja `read_accuracy_from_results` odczytuje dokładność testową dla określonego typu cechy audio z zapisanych wyników w katalogu **feature_comparison_results**. Funkcja przeszukuje podfoldery w poszukiwaniu pliku **results.json** i próbuje wyciągnąć wartość dokładności z różnych możliwych kluczy (accuracy, test_accuracy, val_accuracy), zwracając ją jako liczbę zmiennoprzecinkową lub None, jeśli wynik nie zostanie znaleziony.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_accuracy_from_results(feature_type, results_base_dir='feature_comparison_results'):\n",
    "    \"\"\"\n",
    "    Odczytuje dokładność z zapisanych wyników dla określonego typu cechy.\n",
    "    \n",
    "    Args:\n",
    "        feature_type: Typ cechy (np. 'mfcc', 'spectrogram').\n",
    "        results_base_dir: Katalog bazowy zawierający wyniki.\n",
    "        \n",
    "    Returns:\n",
    "        Dokładność jako liczba zmiennoprzecinkowa lub None, jeśli nie znaleziono.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import json\n",
    "    \n",
    "    feature_dir = os.path.join(results_base_dir, feature_type)\n",
    "    \n",
    "    if not os.path.exists(feature_dir):\n",
    "        return None\n",
    "    \n",
    "    # Wyszukiwanie pliku results.json w podfolderach\n",
    "    for root, dirs, files in os.walk(feature_dir):\n",
    "        for file in files:\n",
    "            if file == 'results.json':\n",
    "                try:\n",
    "                    with open(os.path.join(root, file), 'r') as f:\n",
    "                        results = json.load(f)\n",
    "                        # Sprawdzanie różnych możliwych kluczy dla dokładności\n",
    "                        for key in ['accuracy', 'test_accuracy', 'val_accuracy']:\n",
    "                            if key in results:\n",
    "                                return float(results[key])\n",
    "                except Exception as e:\n",
    "                    print(f\"Wystąpił błąd podczas odczytu pliku {os.path.join(root, file)}: {str(e)}\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening i Porównanie Modeli dla Różnych Cech Audio\n",
    "\n",
    "Funkcja `run_training_experiment` przeprowadza trening modeli dla wybranej cechy audio lub wszystkich dostępnych reprezentacji (np. melspectrogram, mfcc). Funkcja pomija cechy z istniejącymi wynikami (jeśli ustawiono skip_trained), trenuje modele, ewaluuje ich dokładność, mierzy czas treningu i generuje szczegółowe raporty oraz interaktywne wizualizacje (wykresy dokładności i czasu treningu) przy użyciu bibliotek Plotly i Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_experiment(dataset, feature_type=None, skip_trained=False, results_base_dir='feature_comparison_results'):\n",
    "    \"\"\"\n",
    "    Uruchamia trening dla wybranej cechy lub wszystkich cech.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Zbiór danych do treningu.\n",
    "        feature_type: Konkretna cecha do treningu (None oznacza wszystkie cechy).\n",
    "        skip_trained: Flaga wskazująca, czy pomijać cechy, dla których istnieją już wyniki.\n",
    "        results_base_dir: Katalog bazowy do zapisywania wyników.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame z podsumowaniem wyników.\n",
    "    \"\"\"\n",
    "\n",
    "    # Lista wszystkich dostępnych typów cech\n",
    "    all_feature_types = [\n",
    "        \"spectrogram\", \"melspectrogram\", \"mfcc\", \"chroma\", \n",
    "        \"spectral_contrast\", \"zcr\", \"rms\", \"tempogram\",\n",
    "        \"tonnetz\", \"delta_mfcc\", \"delta_tempogram\"\n",
    "    ]\n",
    "    \n",
    "    # Ustalenie, które cechy będą trenowane\n",
    "    feature_types_to_train = [feature_type] if feature_type else all_feature_types\n",
    "    \n",
    "    # Tworzenie katalogów dla wyników\n",
    "    os.makedirs(results_base_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Słowniki do przechowywania wyników i czasów treningu\n",
    "    results = {}\n",
    "    training_times = {}\n",
    "    \n",
    "    # Trening dla każdej cechy\n",
    "    for feat_type in feature_types_to_train:\n",
    "        # Sprawdzenie, czy istnieją wyniki dla danej cechy\n",
    "        feature_dir = os.path.join(results_base_dir, feat_type)\n",
    "        \n",
    "        if skip_trained and os.path.exists(feature_dir) and len(os.listdir(feature_dir)) > 0:\n",
    "            print(f\"\\nPomijanie cechy {feat_type.upper()} - znaleziono istniejące wyniki.\")\n",
    "            \n",
    "            # Odczyt dokładności z istniejących wyników\n",
    "            accuracy = read_accuracy_from_results(feat_type, results_base_dir)\n",
    "            if accuracy:\n",
    "                results[feat_type] = accuracy\n",
    "                print(f\"Odczytana dokładność: {accuracy:.2f}%\")\n",
    "            continue\n",
    "        \n",
    "        # Rozpoczęcie treningu dla danej cechy\n",
    "        print(f\"\\n{'=' * 50}\")\n",
    "        print(f\"Trening modelu na reprezentacji: {feat_type.upper()}\")\n",
    "        print(f\"{'=' * 50}\\n\")\n",
    "        \n",
    "        # Pomiar czasu treningu\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Trening modelu\n",
    "        try:\n",
    "            model, test_loader, label_encoder, history, feature_dir, feat_timestamp, _, training_time = train_model_for_feature(dataset, feat_type)\n",
    "            \n",
    "            # Ewaluacja modelu\n",
    "            device = next(model.parameters()).device\n",
    "            accuracy, _ = evaluate_model(model, test_loader, label_encoder, history, \n",
    "                                        feature_dir, feat_timestamp, feat_type, \n",
    "                                        time.time() - start_time, device)\n",
    "            \n",
    "            results[feat_type] = accuracy\n",
    "            training_times[feat_type] = time.time() - start_time\n",
    "            \n",
    "            print(f\"\\nTrening dla {feat_type} zakończony sukcesem. Dokładność: {accuracy:.2f}%\")\n",
    "            print(f\"Czas treningu: {training_times[feat_type]:.2f} sekund\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nBłąd podczas treningu dla cechy {feat_type}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Generowanie raportu podsumowującego (tylko jeśli trenowano więcej niż jedną cechę)\n",
    "    if len(results) > 1:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Wszystkie treningi zakończone. Generowanie raportu zbiorczego...\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "        \n",
    "        # Tworzenie DataFrame z wynikami\n",
    "        df = pd.DataFrame({\n",
    "            'Feature Type': list(results.keys()),\n",
    "            'Test Accuracy (%)': [results[ft] for ft in results.keys()],\n",
    "            'Training Time (s)': [training_times.get(ft, 0) for ft in results.keys()]\n",
    "        })\n",
    "        \n",
    "        # Sortowanie według dokładności\n",
    "        df = df.sort_values('Test Accuracy (%)', ascending=False)\n",
    "        \n",
    "        # Zapis do CSV\n",
    "        csv_path = os.path.join(results_base_dir, f'accuracy_summary_{timestamp}.csv')\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Zapisano podsumowanie do: {csv_path}\")\n",
    "        \n",
    "        # Tworzenie wykresu dokładności przy użyciu Plotly\n",
    "        fig_accuracy = px.bar(\n",
    "            df, \n",
    "            x='Feature Type', \n",
    "            y='Test Accuracy (%)', \n",
    "            title='Porównanie dokładności dla różnych reprezentacji audio',\n",
    "            color_discrete_sequence=['purple']\n",
    "        )\n",
    "        \n",
    "        fig_accuracy.update_layout(\n",
    "            xaxis_title='Typ cechy',\n",
    "            yaxis_title='Dokładność testu (%)',\n",
    "            xaxis_tickangle=-45,\n",
    "            yaxis_range=[0, max(df['Test Accuracy (%)']) * 1.1],\n",
    "            template='plotly_white'\n",
    "        )\n",
    "        \n",
    "        # Dodanie wartości nad słupkami\n",
    "        fig_accuracy.update_traces(\n",
    "            texttemplate='%{y:.1f}%', \n",
    "            textposition='outside'\n",
    "        )\n",
    "        \n",
    "        # Zapisanie wykresu dokładności\n",
    "        accuracy_plot_path = os.path.join(results_base_dir, f'accuracy_comparison_{timestamp}.html')\n",
    "        fig_accuracy.write_html(accuracy_plot_path)\n",
    "        \n",
    "        # Tworzenie wykresu czasu treningu przy użyciu Plotly\n",
    "        fig_time = px.bar(\n",
    "            df, \n",
    "            x='Feature Type', \n",
    "            y='Training Time (s)', \n",
    "            title='Porównanie czasu treningu dla różnych reprezentacji audio',\n",
    "            color_discrete_sequence=['purple']  # Kolor fioletowy\n",
    "        )\n",
    "        \n",
    "        fig_time.update_layout(\n",
    "            xaxis_title='Typ cechy',\n",
    "            yaxis_title='Czas treningu (s)',\n",
    "            xaxis_tickangle=-45,\n",
    "            yaxis_range=[0, max(df['Training Time (s)']) * 1.1],\n",
    "            template='plotly_white'\n",
    "        )\n",
    "        \n",
    "        # Dodanie wartości nad słupkami\n",
    "        fig_time.update_traces(\n",
    "            texttemplate='%{y:.0f}s', \n",
    "            textposition='outside'\n",
    "        )\n",
    "        \n",
    "        # Zapisanie wykresu czasu treningu\n",
    "        time_plot_path = os.path.join(results_base_dir, f'training_time_comparison_{timestamp}.html')\n",
    "        fig_time.write_html(time_plot_path)\n",
    "    \n",
    "        \n",
    "        fig_combined = make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            subplot_titles=('Porównanie dokładności dla różnych reprezentacji audio', \n",
    "                           'Porównanie czasu treningu dla różnych reprezentacji audio')\n",
    "        )\n",
    "        \n",
    "        # Dodanie słupków dokładności\n",
    "        fig_combined.add_trace(\n",
    "            go.Bar(\n",
    "                x=df['Feature Type'], \n",
    "                y=df['Test Accuracy (%)'],\n",
    "                text=df['Test Accuracy (%)'].apply(lambda x: f'{x:.1f}%'),\n",
    "                textposition='outside',\n",
    "                marker_color='purple',\n",
    "                name='Dokładność'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Dodanie słupków czasu treningu\n",
    "        fig_combined.add_trace(\n",
    "            go.Bar(\n",
    "                x=df['Feature Type'], \n",
    "                y=df['Training Time (s)'],\n",
    "                text=df['Training Time (s)'].apply(lambda x: f'{int(x)}s'),\n",
    "                textposition='outside',\n",
    "                marker_color='purple',\n",
    "                name='Czas treningu'\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # Aktualizacja układu\n",
    "        fig_combined.update_layout(\n",
    "            height=600,\n",
    "            width=1200,\n",
    "            showlegend=False,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "        \n",
    "        # Aktualizacja osi X i Y dla obu wykresów\n",
    "        fig_combined.update_xaxes(title_text='Typ cechy', tickangle=-45, row=1, col=1)\n",
    "        fig_combined.update_xaxes(title_text='Typ cechy', tickangle=-45, row=1, col=2)\n",
    "        fig_combined.update_yaxes(title_text='Dokładność testu (%)', range=[0, max(df['Test Accuracy (%)']) * 1.1], row=1, col=1)\n",
    "        fig_combined.update_yaxes(title_text='Czas treningu (s)', range=[0, max(df['Training Time (s)']) * 1.1], row=1, col=2)\n",
    "        \n",
    "        # Zapisanie połączonego wykresu\n",
    "        combined_plot_path = os.path.join(results_base_dir, f'feature_comparison_{timestamp}.html')\n",
    "        fig_combined.write_html(combined_plot_path)\n",
    "        \n",
    "        print(f\"Zapisano interaktywne wizualizacje do: {accuracy_plot_path}, {time_plot_path}, {combined_plot_path}\")\n",
    "        print(\"\\nPodsumowanie wyników:\")\n",
    "        print(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Zwrócenie wyniku dla pojedynczej cechy\n",
    "    elif len(results) == 1:\n",
    "        feature = list(results.keys())[0]\n",
    "        print(f\"\\nWynik dla cechy {feature}: {results[feature]:.2f}%\")\n",
    "        return results[feature]\n",
    "    \n",
    "    # Informacja o braku przeprowadzonego treningu\n",
    "    else:\n",
    "        print(\"\\nNie przeprowadzono żadnego treningu.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: SPECTROGRAM\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: spectrogram...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 1619.00 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\spectrogram_8c93236ae30e113bf579a1f68a321f42.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: spectrogram...\n",
      "Epoka 1/50, Strata treningu: 1.7640, Strata walidacji: 4.1592, Dokładność walidacji: 29.01%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectrogram\\best_model_spectrogram_20250516_200832.pt\n",
      "Epoka 2/50, Strata treningu: 1.3373, Strata walidacji: 1.8547, Dokładność walidacji: 37.94%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectrogram\\best_model_spectrogram_20250516_200832.pt\n",
      "Epoka 3/50, Strata treningu: 1.1993, Strata walidacji: 2.2171, Dokładność walidacji: 33.19%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 4/50, Strata treningu: 1.0907, Strata walidacji: 7.3837, Dokładność walidacji: 24.97%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 5/50, Strata treningu: 0.9915, Strata walidacji: 3.0310, Dokładność walidacji: 35.84%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 6/50, Strata treningu: 0.9097, Strata walidacji: 1.7818, Dokładność walidacji: 39.47%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectrogram\\best_model_spectrogram_20250516_200832.pt\n",
      "Epoka 7/50, Strata treningu: 0.8088, Strata walidacji: 3.5374, Dokładność walidacji: 34.31%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 8/50, Strata treningu: 0.7532, Strata walidacji: 2.1345, Dokładność walidacji: 39.47%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 9/50, Strata treningu: 0.6871, Strata walidacji: 1.1968, Dokładność walidacji: 59.55%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectrogram\\best_model_spectrogram_20250516_200832.pt\n",
      "Epoka 10/50, Strata treningu: 0.6075, Strata walidacji: 1.0826, Dokładność walidacji: 64.02%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectrogram\\best_model_spectrogram_20250516_200832.pt\n",
      "Epoka 11/50, Strata treningu: 0.5542, Strata walidacji: 1.4818, Dokładność walidacji: 53.00%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 12/50, Strata treningu: 0.5131, Strata walidacji: 1.0029, Dokładność walidacji: 66.11%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectrogram\\best_model_spectrogram_20250516_200832.pt\n",
      "Epoka 13/50, Strata treningu: 0.4437, Strata walidacji: 1.2187, Dokładność walidacji: 62.90%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 14/50, Strata treningu: 0.3867, Strata walidacji: 2.5289, Dokładność walidacji: 45.89%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 15/50, Strata treningu: 0.3434, Strata walidacji: 0.7080, Dokładność walidacji: 75.17%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectrogram\\best_model_spectrogram_20250516_200832.pt\n",
      "Epoka 16/50, Strata treningu: 0.3252, Strata walidacji: 1.1386, Dokładność walidacji: 64.85%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 17/50, Strata treningu: 0.2892, Strata walidacji: 1.5473, Dokładność walidacji: 56.49%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 18/50, Strata treningu: 0.2716, Strata walidacji: 1.1488, Dokładność walidacji: 66.81%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 19/50, Strata treningu: 0.2270, Strata walidacji: 1.7111, Dokładność walidacji: 57.46%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 20/50, Strata treningu: 0.1068, Strata walidacji: 0.4771, Dokładność walidacji: 83.68%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectrogram\\best_model_spectrogram_20250516_200832.pt\n",
      "Epoka 21/50, Strata treningu: 0.0523, Strata walidacji: 0.6225, Dokładność walidacji: 81.73%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 22/50, Strata treningu: 0.0465, Strata walidacji: 0.6898, Dokładność walidacji: 78.94%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 23/50, Strata treningu: 0.0340, Strata walidacji: 0.5484, Dokładność walidacji: 81.73%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 24/50, Strata treningu: 0.0302, Strata walidacji: 0.6025, Dokładność walidacji: 81.73%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 25/50, Strata treningu: 0.0153, Strata walidacji: 0.4518, Dokładność walidacji: 86.19%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectrogram\\best_model_spectrogram_20250516_200832.pt\n",
      "Epoka 26/50, Strata treningu: 0.0123, Strata walidacji: 0.4586, Dokładność walidacji: 87.17%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 27/50, Strata treningu: 0.0115, Strata walidacji: 0.4915, Dokładność walidacji: 85.50%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 28/50, Strata treningu: 0.0093, Strata walidacji: 0.5071, Dokładność walidacji: 85.63%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 29/50, Strata treningu: 0.0076, Strata walidacji: 0.5317, Dokładność walidacji: 85.22%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 30/50, Strata treningu: 0.0072, Strata walidacji: 0.4693, Dokładność walidacji: 85.91%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 31/50, Strata treningu: 0.0054, Strata walidacji: 0.4831, Dokładność walidacji: 86.47%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 32/50, Strata treningu: 0.0045, Strata walidacji: 0.4927, Dokładność walidacji: 85.63%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 32 epokach. Czas: 12795.42 sekund\n",
      "\n",
      "Trening dla spectrogram zakończony sukcesem. Dokładność: 86.51%\n",
      "Czas treningu: 14935.19 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: MELSPECTROGRAM\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: melspectrogram...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 30.28 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\melspectrogram_53ee30be77b7cdc4bd886fd7c06dddfc.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: melspectrogram...\n",
      "Epoka 1/50, Strata treningu: 1.8588, Strata walidacji: 3.8844, Dokładność walidacji: 21.62%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250517_001727.pt\n",
      "Epoka 2/50, Strata treningu: 1.2123, Strata walidacji: 3.1739, Dokładność walidacji: 36.82%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250517_001727.pt\n",
      "Epoka 3/50, Strata treningu: 0.9285, Strata walidacji: 1.4416, Dokładność walidacji: 50.91%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250517_001727.pt\n",
      "Epoka 4/50, Strata treningu: 0.7123, Strata walidacji: 2.0079, Dokładność walidacji: 47.14%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 5/50, Strata treningu: 0.6550, Strata walidacji: 0.7198, Dokładność walidacji: 74.06%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250517_001727.pt\n",
      "Epoka 6/50, Strata treningu: 0.4802, Strata walidacji: 1.2342, Dokładność walidacji: 63.32%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 7/50, Strata treningu: 0.4168, Strata walidacji: 0.7734, Dokładność walidacji: 76.15%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 8/50, Strata treningu: 0.3132, Strata walidacji: 0.8451, Dokładność walidacji: 74.48%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 9/50, Strata treningu: 0.3042, Strata walidacji: 1.0497, Dokładność walidacji: 70.99%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 10/50, Strata treningu: 0.1169, Strata walidacji: 0.4399, Dokładność walidacji: 84.94%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250517_001727.pt\n",
      "Epoka 11/50, Strata treningu: 0.0570, Strata walidacji: 0.2995, Dokładność walidacji: 89.96%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250517_001727.pt\n",
      "Epoka 12/50, Strata treningu: 0.0465, Strata walidacji: 0.3783, Dokładność walidacji: 88.15%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 13/50, Strata treningu: 0.0336, Strata walidacji: 0.3180, Dokładność walidacji: 89.82%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 14/50, Strata treningu: 0.0345, Strata walidacji: 0.8957, Dokładność walidacji: 79.50%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 15/50, Strata treningu: 0.0751, Strata walidacji: 0.3920, Dokładność walidacji: 87.59%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 16/50, Strata treningu: 0.0224, Strata walidacji: 0.3215, Dokładność walidacji: 89.96%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 17/50, Strata treningu: 0.0134, Strata walidacji: 0.3187, Dokładność walidacji: 89.54%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 18/50, Strata treningu: 0.0073, Strata walidacji: 0.2982, Dokładność walidacji: 89.68%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250517_001727.pt\n",
      "Epoka 19/50, Strata treningu: 0.0058, Strata walidacji: 0.2423, Dokładność walidacji: 92.33%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\melspectrogram\\best_model_melspectrogram_20250517_001727.pt\n",
      "Epoka 20/50, Strata treningu: 0.0074, Strata walidacji: 0.2844, Dokładność walidacji: 91.49%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 21/50, Strata treningu: 0.0059, Strata walidacji: 0.3043, Dokładność walidacji: 90.93%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 22/50, Strata treningu: 0.0047, Strata walidacji: 0.2751, Dokładność walidacji: 91.35%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 23/50, Strata treningu: 0.0023, Strata walidacji: 0.2562, Dokładność walidacji: 91.91%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 24/50, Strata treningu: 0.0030, Strata walidacji: 0.2689, Dokładność walidacji: 91.35%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 25/50, Strata treningu: 0.0049, Strata walidacji: 0.3047, Dokładność walidacji: 91.21%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 26/50, Strata treningu: 0.0025, Strata walidacji: 0.2747, Dokładność walidacji: 92.05%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 26 epokach. Czas: 1387.11 sekund\n",
      "\n",
      "Trening dla melspectrogram zakończony sukcesem. Dokładność: 91.97%\n",
      "Czas treningu: 1431.47 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: MFCC\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: mfcc...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 18.48 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\mfcc_de6bae255cca45e44a8891b16617e85d.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: mfcc...\n",
      "Epoka 1/50, Strata treningu: 1.8858, Strata walidacji: 1.6433, Dokładność walidacji: 40.73%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250517_004119.pt\n",
      "Epoka 2/50, Strata treningu: 1.2819, Strata walidacji: 1.1671, Dokładność walidacji: 53.28%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250517_004119.pt\n",
      "Epoka 3/50, Strata treningu: 1.0729, Strata walidacji: 0.9454, Dokładność walidacji: 65.83%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250517_004119.pt\n",
      "Epoka 4/50, Strata treningu: 0.8489, Strata walidacji: 1.8440, Dokładność walidacji: 51.60%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 5/50, Strata treningu: 0.7886, Strata walidacji: 0.7318, Dokładność walidacji: 70.43%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250517_004119.pt\n",
      "Epoka 6/50, Strata treningu: 0.6477, Strata walidacji: 0.7123, Dokładność walidacji: 74.76%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250517_004119.pt\n",
      "Epoka 7/50, Strata treningu: 0.5780, Strata walidacji: 0.8778, Dokładność walidacji: 67.50%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 8/50, Strata treningu: 0.4849, Strata walidacji: 0.8393, Dokładność walidacji: 71.13%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 9/50, Strata treningu: 0.4370, Strata walidacji: 0.5956, Dokładność walidacji: 80.06%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250517_004119.pt\n",
      "Epoka 10/50, Strata treningu: 0.3715, Strata walidacji: 0.8631, Dokładność walidacji: 72.66%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 11/50, Strata treningu: 0.3466, Strata walidacji: 0.6886, Dokładność walidacji: 76.71%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 12/50, Strata treningu: 0.3013, Strata walidacji: 0.5342, Dokładność walidacji: 80.89%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250517_004119.pt\n",
      "Epoka 13/50, Strata treningu: 0.2858, Strata walidacji: 0.5480, Dokładność walidacji: 80.61%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 14/50, Strata treningu: 0.2309, Strata walidacji: 0.4324, Dokładność walidacji: 87.17%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250517_004119.pt\n",
      "Epoka 15/50, Strata treningu: 0.1866, Strata walidacji: 0.6220, Dokładność walidacji: 80.61%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 16/50, Strata treningu: 0.2074, Strata walidacji: 0.6729, Dokładność walidacji: 81.03%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 17/50, Strata treningu: 0.1488, Strata walidacji: 0.4244, Dokładność walidacji: 87.03%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250517_004119.pt\n",
      "Epoka 18/50, Strata treningu: 0.1838, Strata walidacji: 0.5746, Dokładność walidacji: 82.15%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 19/50, Strata treningu: 0.1850, Strata walidacji: 0.5164, Dokładność walidacji: 83.68%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 20/50, Strata treningu: 0.1701, Strata walidacji: 0.3921, Dokładność walidacji: 87.17%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250517_004119.pt\n",
      "Epoka 21/50, Strata treningu: 0.1455, Strata walidacji: 0.5894, Dokładność walidacji: 81.59%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 22/50, Strata treningu: 0.1610, Strata walidacji: 0.5421, Dokładność walidacji: 83.96%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 23/50, Strata treningu: 0.0780, Strata walidacji: 0.6085, Dokładność walidacji: 84.94%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 24/50, Strata treningu: 0.0554, Strata walidacji: 0.4679, Dokładność walidacji: 86.89%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 25/50, Strata treningu: 0.0318, Strata walidacji: 0.2933, Dokładność walidacji: 92.61%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250517_004119.pt\n",
      "Epoka 26/50, Strata treningu: 0.0135, Strata walidacji: 0.2662, Dokładność walidacji: 93.58%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\mfcc\\best_model_mfcc_20250517_004119.pt\n",
      "Epoka 27/50, Strata treningu: 0.0062, Strata walidacji: 0.2881, Dokładność walidacji: 93.03%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 28/50, Strata treningu: 0.0154, Strata walidacji: 0.4412, Dokładność walidacji: 89.40%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 29/50, Strata treningu: 0.0247, Strata walidacji: 0.3693, Dokładność walidacji: 91.77%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 30/50, Strata treningu: 0.0549, Strata walidacji: 0.3259, Dokładność walidacji: 90.24%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 31/50, Strata treningu: 0.0134, Strata walidacji: 0.2984, Dokładność walidacji: 92.47%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 32/50, Strata treningu: 0.0033, Strata walidacji: 0.2938, Dokładność walidacji: 92.61%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 33/50, Strata treningu: 0.0025, Strata walidacji: 0.3282, Dokładność walidacji: 92.05%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 33 epokach. Czas: 683.59 sekund\n",
      "\n",
      "Trening dla mfcc zakończony sukcesem. Dokładność: 92.98%\n",
      "Czas treningu: 705.08 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: CHROMA\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: chroma...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 23.46 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\chroma_f7c54044e13af32ceb625a21ae0ad422.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: chroma...\n",
      "Epoka 1/50, Strata treningu: 2.2299, Strata walidacji: 1.6315, Dokładność walidacji: 40.86%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\chroma\\best_model_chroma_20250517_005304.pt\n",
      "Epoka 2/50, Strata treningu: 1.5651, Strata walidacji: 1.4170, Dokładność walidacji: 42.96%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\chroma\\best_model_chroma_20250517_005304.pt\n",
      "Epoka 3/50, Strata treningu: 1.3510, Strata walidacji: 1.3786, Dokładność walidacji: 51.88%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\chroma\\best_model_chroma_20250517_005304.pt\n",
      "Epoka 4/50, Strata treningu: 1.1343, Strata walidacji: 1.3552, Dokładność walidacji: 49.65%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\chroma\\best_model_chroma_20250517_005304.pt\n",
      "Epoka 5/50, Strata treningu: 0.9800, Strata walidacji: 1.5765, Dokładność walidacji: 51.74%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 6/50, Strata treningu: 0.8280, Strata walidacji: 1.7176, Dokładność walidacji: 45.47%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 7/50, Strata treningu: 0.7237, Strata walidacji: 2.4345, Dokładność walidacji: 39.05%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 8/50, Strata treningu: 0.6072, Strata walidacji: 1.9336, Dokładność walidacji: 46.44%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 9/50, Strata treningu: 0.3126, Strata walidacji: 1.8964, Dokładność walidacji: 54.53%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 10/50, Strata treningu: 0.1714, Strata walidacji: 1.9337, Dokładność walidacji: 53.14%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 11/50, Strata treningu: 0.1149, Strata walidacji: 2.1415, Dokładność walidacji: 52.02%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 11 epokach. Czas: 106.52 sekund\n",
      "\n",
      "Trening dla chroma zakończony sukcesem. Dokładność: 48.16%\n",
      "Czas treningu: 131.87 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: SPECTRAL_CONTRAST\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: spectral_contrast...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 12.62 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\spectral_contrast_c67aaf46a546d07787a9bc50c190a605.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: spectral_contrast...\n",
      "Epoka 1/50, Strata treningu: 2.1982, Strata walidacji: 2.4457, Dokładność walidacji: 30.40%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectral_contrast\\best_model_spectral_contrast_20250517_005516.pt\n",
      "Epoka 2/50, Strata treningu: 1.7832, Strata walidacji: 2.8840, Dokładność walidacji: 28.31%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 3/50, Strata treningu: 1.5885, Strata walidacji: 1.5178, Dokładność walidacji: 38.35%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectral_contrast\\best_model_spectral_contrast_20250517_005516.pt\n",
      "Epoka 4/50, Strata treningu: 1.4393, Strata walidacji: 1.4584, Dokładność walidacji: 43.10%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\spectral_contrast\\best_model_spectral_contrast_20250517_005516.pt\n",
      "Epoka 5/50, Strata treningu: 1.2013, Strata walidacji: 1.5730, Dokładność walidacji: 42.26%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 6/50, Strata treningu: 1.1447, Strata walidacji: 2.4473, Dokładność walidacji: 30.82%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 7/50, Strata treningu: 0.9707, Strata walidacji: 1.7274, Dokładność walidacji: 43.65%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 8/50, Strata treningu: 0.8331, Strata walidacji: 1.5420, Dokładność walidacji: 46.44%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 9/50, Strata treningu: 0.4573, Strata walidacji: 1.8208, Dokładność walidacji: 48.95%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 10/50, Strata treningu: 0.2631, Strata walidacji: 2.7329, Dokładność walidacji: 44.07%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 11/50, Strata treningu: 0.2661, Strata walidacji: 2.0991, Dokładność walidacji: 49.23%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 11 epokach. Czas: 92.97 sekund\n",
      "\n",
      "Trening dla spectral_contrast zakończony sukcesem. Dokładność: 42.59%\n",
      "Czas treningu: 107.04 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: ZCR\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: zcr...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 10.26 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\zcr_1bb58748091eb5860417275cc92ce18f.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: zcr...\n",
      "Epoka 1/50, Strata treningu: 2.2592, Strata walidacji: 1.9055, Dokładność walidacji: 19.94%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\zcr\\best_model_zcr_20250517_005703.pt\n",
      "Epoka 2/50, Strata treningu: 1.9205, Strata walidacji: 1.9401, Dokładność walidacji: 21.76%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 3/50, Strata treningu: 1.8429, Strata walidacji: 1.8527, Dokładność walidacji: 25.52%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\zcr\\best_model_zcr_20250517_005703.pt\n",
      "Epoka 4/50, Strata treningu: 1.7551, Strata walidacji: 1.7363, Dokładność walidacji: 27.62%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\zcr\\best_model_zcr_20250517_005703.pt\n",
      "Epoka 5/50, Strata treningu: 1.7439, Strata walidacji: 1.7745, Dokładność walidacji: 21.62%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 6/50, Strata treningu: 1.7358, Strata walidacji: 1.7422, Dokładność walidacji: 25.10%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 7/50, Strata treningu: 1.6982, Strata walidacji: 1.7025, Dokładność walidacji: 30.40%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\zcr\\best_model_zcr_20250517_005703.pt\n",
      "Epoka 8/50, Strata treningu: 1.6779, Strata walidacji: 1.7601, Dokładność walidacji: 26.22%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 9/50, Strata treningu: 1.6576, Strata walidacji: 1.7394, Dokładność walidacji: 25.66%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 10/50, Strata treningu: 1.6332, Strata walidacji: 1.8217, Dokładność walidacji: 22.59%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 11/50, Strata treningu: 1.6155, Strata walidacji: 1.7298, Dokładność walidacji: 25.24%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 12/50, Strata treningu: 1.5166, Strata walidacji: 1.7349, Dokładność walidacji: 28.87%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 13/50, Strata treningu: 1.4550, Strata walidacji: 1.8447, Dokładność walidacji: 28.31%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 14/50, Strata treningu: 1.3790, Strata walidacji: 1.8551, Dokładność walidacji: 24.27%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 14 epokach. Czas: 690.67 sekund\n",
      "\n",
      "Trening dla zcr zakończony sukcesem. Dokładność: 26.09%\n",
      "Czas treningu: 707.91 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: RMS\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: rms...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 15.53 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\rms_0f95119d57261dd135d27ffb480e633b.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: rms...\n",
      "Epoka 1/50, Strata treningu: 2.1957, Strata walidacji: 1.8325, Dokładność walidacji: 23.29%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\rms\\best_model_rms_20250517_010851.pt\n",
      "Epoka 2/50, Strata treningu: 1.8615, Strata walidacji: 1.8082, Dokładność walidacji: 23.99%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\rms\\best_model_rms_20250517_010851.pt\n",
      "Epoka 3/50, Strata treningu: 1.7491, Strata walidacji: 1.8808, Dokładność walidacji: 20.92%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 4/50, Strata treningu: 1.6966, Strata walidacji: 1.7145, Dokładność walidacji: 30.26%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\rms\\best_model_rms_20250517_010851.pt\n",
      "Epoka 5/50, Strata treningu: 1.6780, Strata walidacji: 1.7519, Dokładność walidacji: 24.69%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 6/50, Strata treningu: 1.6321, Strata walidacji: 1.7776, Dokładność walidacji: 27.06%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 7/50, Strata treningu: 1.6050, Strata walidacji: 1.7180, Dokładność walidacji: 27.62%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 8/50, Strata treningu: 1.5917, Strata walidacji: 1.6886, Dokładność walidacji: 30.26%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\rms\\best_model_rms_20250517_010851.pt\n",
      "Epoka 9/50, Strata treningu: 1.5443, Strata walidacji: 1.6430, Dokładność walidacji: 33.89%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\rms\\best_model_rms_20250517_010851.pt\n",
      "Epoka 10/50, Strata treningu: 1.5187, Strata walidacji: 1.6843, Dokładność walidacji: 29.43%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 11/50, Strata treningu: 1.4951, Strata walidacji: 1.9569, Dokładność walidacji: 28.17%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 12/50, Strata treningu: 1.4517, Strata walidacji: 1.8419, Dokładność walidacji: 27.48%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 13/50, Strata treningu: 1.3966, Strata walidacji: 1.8265, Dokładność walidacji: 27.89%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 14/50, Strata treningu: 1.2164, Strata walidacji: 1.9629, Dokładność walidacji: 31.38%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 15/50, Strata treningu: 1.1130, Strata walidacji: 1.9294, Dokładność walidacji: 29.29%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 16/50, Strata treningu: 1.0181, Strata walidacji: 2.8020, Dokładność walidacji: 24.83%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 16 epokach. Czas: 807.98 sekund\n",
      "\n",
      "Trening dla rms zakończony sukcesem. Dokładność: 36.57%\n",
      "Czas treningu: 830.58 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: TEMPOGRAM\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: tempogram...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 41.02 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\tempogram_0fa2708c9788e12fe31c7b96ae59978d.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: tempogram...\n",
      "Epoka 1/50, Strata treningu: 2.0652, Strata walidacji: 2.6976, Dokładność walidacji: 15.20%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250517_012241.pt\n",
      "Epoka 2/50, Strata treningu: 1.8596, Strata walidacji: 1.9419, Dokładność walidacji: 22.73%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250517_012241.pt\n",
      "Epoka 3/50, Strata treningu: 1.8288, Strata walidacji: 2.4851, Dokładność walidacji: 17.99%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 4/50, Strata treningu: 1.8036, Strata walidacji: 1.9990, Dokładność walidacji: 18.69%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 5/50, Strata treningu: 1.7927, Strata walidacji: 1.7717, Dokładność walidacji: 21.34%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250517_012241.pt\n",
      "Epoka 6/50, Strata treningu: 1.7855, Strata walidacji: 1.7848, Dokładność walidacji: 22.04%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 7/50, Strata treningu: 1.7873, Strata walidacji: 1.7731, Dokładność walidacji: 23.99%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 8/50, Strata treningu: 1.7770, Strata walidacji: 1.7969, Dokładność walidacji: 19.53%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 9/50, Strata treningu: 1.7773, Strata walidacji: 1.8216, Dokładność walidacji: 23.85%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 10/50, Strata treningu: 1.7670, Strata walidacji: 1.7592, Dokładność walidacji: 24.69%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250517_012241.pt\n",
      "Epoka 11/50, Strata treningu: 1.7580, Strata walidacji: 1.7623, Dokładność walidacji: 24.13%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 12/50, Strata treningu: 1.7484, Strata walidacji: 1.7614, Dokładność walidacji: 24.69%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 13/50, Strata treningu: 1.7412, Strata walidacji: 2.0183, Dokładność walidacji: 17.99%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 14/50, Strata treningu: 1.7453, Strata walidacji: 1.7505, Dokładność walidacji: 25.38%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250517_012241.pt\n",
      "Epoka 15/50, Strata treningu: 1.7441, Strata walidacji: 1.7687, Dokładność walidacji: 23.15%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 16/50, Strata treningu: 1.7405, Strata walidacji: 1.7471, Dokładność walidacji: 24.83%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250517_012241.pt\n",
      "Epoka 17/50, Strata treningu: 1.7422, Strata walidacji: 1.9003, Dokładność walidacji: 19.80%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 18/50, Strata treningu: 1.7289, Strata walidacji: 1.7814, Dokładność walidacji: 24.41%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 19/50, Strata treningu: 1.7325, Strata walidacji: 2.0047, Dokładność walidacji: 19.53%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 20/50, Strata treningu: 1.7318, Strata walidacji: 1.8509, Dokładność walidacji: 18.97%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 21/50, Strata treningu: 1.7017, Strata walidacji: 1.7800, Dokładność walidacji: 25.38%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 22/50, Strata treningu: 1.6978, Strata walidacji: 1.7353, Dokładność walidacji: 25.80%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250517_012241.pt\n",
      "Epoka 23/50, Strata treningu: 1.6804, Strata walidacji: 1.7838, Dokładność walidacji: 26.78%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 24/50, Strata treningu: 1.6755, Strata walidacji: 1.9969, Dokładność walidacji: 21.48%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 25/50, Strata treningu: 1.6755, Strata walidacji: 1.7494, Dokładność walidacji: 25.80%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 26/50, Strata treningu: 1.6659, Strata walidacji: 1.7337, Dokładność walidacji: 27.62%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tempogram\\best_model_tempogram_20250517_012241.pt\n",
      "Epoka 27/50, Strata treningu: 1.6506, Strata walidacji: 1.7382, Dokładność walidacji: 27.34%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 28/50, Strata treningu: 1.6470, Strata walidacji: 1.8017, Dokładność walidacji: 25.94%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 29/50, Strata treningu: 1.6366, Strata walidacji: 1.8254, Dokładność walidacji: 25.52%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 30/50, Strata treningu: 1.6317, Strata walidacji: 1.7723, Dokładność walidacji: 25.52%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 31/50, Strata treningu: 1.5653, Strata walidacji: 1.8058, Dokładność walidacji: 28.45%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 32/50, Strata treningu: 1.5454, Strata walidacji: 2.0414, Dokładność walidacji: 22.73%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 33/50, Strata treningu: 1.5155, Strata walidacji: 1.8565, Dokładność walidacji: 23.57%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 33 epokach. Czas: 4805.77 sekund\n",
      "\n",
      "Trening dla tempogram zakończony sukcesem. Dokładność: 26.31%\n",
      "Czas treningu: 4881.91 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: TONNETZ\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: tonnetz...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 183.71 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\tonnetz_7167c47d6c727ab781906e64fa4abba3.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: tonnetz...\n",
      "Epoka 1/50, Strata treningu: 2.4703, Strata walidacji: 2.1197, Dokładność walidacji: 28.45%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tonnetz\\best_model_tonnetz_20250517_024403.pt\n",
      "Epoka 2/50, Strata treningu: 1.8942, Strata walidacji: 1.9166, Dokładność walidacji: 31.80%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tonnetz\\best_model_tonnetz_20250517_024403.pt\n",
      "Epoka 3/50, Strata treningu: 1.6930, Strata walidacji: 1.7860, Dokładność walidacji: 32.91%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tonnetz\\best_model_tonnetz_20250517_024403.pt\n",
      "Epoka 4/50, Strata treningu: 1.5542, Strata walidacji: 1.6155, Dokładność walidacji: 36.54%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tonnetz\\best_model_tonnetz_20250517_024403.pt\n",
      "Epoka 5/50, Strata treningu: 1.4523, Strata walidacji: 1.6773, Dokładność walidacji: 37.94%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 6/50, Strata treningu: 1.2529, Strata walidacji: 1.6128, Dokładność walidacji: 40.03%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\tonnetz\\best_model_tonnetz_20250517_024403.pt\n",
      "Epoka 7/50, Strata treningu: 1.1274, Strata walidacji: 1.7388, Dokładność walidacji: 37.24%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 8/50, Strata treningu: 1.0114, Strata walidacji: 1.7610, Dokładność walidacji: 34.03%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 9/50, Strata treningu: 0.8521, Strata walidacji: 2.2166, Dokładność walidacji: 33.75%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 10/50, Strata treningu: 0.7098, Strata walidacji: 2.3435, Dokładność walidacji: 33.33%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 11/50, Strata treningu: 0.3423, Strata walidacji: 2.8402, Dokładność walidacji: 38.91%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 12/50, Strata treningu: 0.2114, Strata walidacji: 3.1291, Dokładność walidacji: 38.63%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 13/50, Strata treningu: 0.2270, Strata walidacji: 3.2449, Dokładność walidacji: 37.38%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 13 epokach. Czas: 112.33 sekund\n",
      "\n",
      "Trening dla tonnetz zakończony sukcesem. Dokładność: 37.46%\n",
      "Czas treningu: 298.56 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: DELTA_MFCC\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: delta_mfcc...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 13.71 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\delta_mfcc_d569b0771144337dc2547e81c8ebe308.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: delta_mfcc...\n",
      "Epoka 1/50, Strata treningu: 2.1133, Strata walidacji: 2.2227, Dokładność walidacji: 26.92%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_mfcc\\best_model_delta_mfcc_20250517_024902.pt\n",
      "Epoka 2/50, Strata treningu: 1.6494, Strata walidacji: 2.6599, Dokładność walidacji: 30.68%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 3/50, Strata treningu: 1.3655, Strata walidacji: 1.4629, Dokładność walidacji: 41.84%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_mfcc\\best_model_delta_mfcc_20250517_024902.pt\n",
      "Epoka 4/50, Strata treningu: 1.1502, Strata walidacji: 1.3408, Dokładność walidacji: 49.37%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_mfcc\\best_model_delta_mfcc_20250517_024902.pt\n",
      "Epoka 5/50, Strata treningu: 0.9250, Strata walidacji: 1.5542, Dokładność walidacji: 45.89%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 6/50, Strata treningu: 0.7736, Strata walidacji: 2.7781, Dokładność walidacji: 34.87%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 7/50, Strata treningu: 0.6462, Strata walidacji: 2.5851, Dokładność walidacji: 46.03%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 8/50, Strata treningu: 0.4824, Strata walidacji: 1.8069, Dokładność walidacji: 50.63%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 9/50, Strata treningu: 0.2340, Strata walidacji: 1.2765, Dokładność walidacji: 60.25%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_mfcc\\best_model_delta_mfcc_20250517_024902.pt\n",
      "Epoka 10/50, Strata treningu: 0.0930, Strata walidacji: 1.6287, Dokładność walidacji: 56.07%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 11/50, Strata treningu: 0.0608, Strata walidacji: 1.8107, Dokładność walidacji: 55.93%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 12/50, Strata treningu: 0.0442, Strata walidacji: 1.8108, Dokładność walidacji: 58.58%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 13/50, Strata treningu: 0.0480, Strata walidacji: 1.9369, Dokładność walidacji: 57.04%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 14/50, Strata treningu: 0.0284, Strata walidacji: 1.5603, Dokładność walidacji: 63.32%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 15/50, Strata treningu: 0.0212, Strata walidacji: 1.5528, Dokładność walidacji: 63.60%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 16/50, Strata treningu: 0.0141, Strata walidacji: 1.5768, Dokładność walidacji: 64.16%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 16 epokach. Czas: 328.49 sekund\n",
      "\n",
      "Trening dla delta_mfcc zakończony sukcesem. Dokładność: 62.32%\n",
      "Czas treningu: 345.24 sekund\n",
      "\n",
      "==================================================\n",
      "Trening modelu na reprezentacji: DELTA_TEMPOGRAM\n",
      "==================================================\n",
      "\n",
      "Przetwarzanie próbek audio dla cechy: delta_tempogram...\n",
      "Przygotowywanie 0/4481 próbek\n",
      "Przygotowywanie 500/4481 próbek\n",
      "Przygotowywanie 1000/4481 próbek\n",
      "Przygotowywanie 1500/4481 próbek\n",
      "Przygotowywanie 2000/4481 próbek\n",
      "Przygotowywanie 2500/4481 próbek\n",
      "Przygotowywanie 3000/4481 próbek\n",
      "Przygotowywanie 3500/4481 próbek\n",
      "Przygotowywanie 4000/4481 próbek\n",
      "Rozpoczęcie równoległego przetwarzania na wszystkich dostępnych rdzeniach...\n",
      "Całkowita liczba próbek: 4481\n",
      "Liczba ważnych próbek: 4481\n",
      "Liczba pustych/błędnych cech: 0\n",
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {'anger': 0, 'fear': 1, 'happiness': 2, 'neutral': 3, 'sadness': 4, 'surprised': 5}\n",
      "Czas przetwarzania: 36.88 sekund\n",
      "Zapisywanie przetworzonych cech do pliku pamięci podręcznej: processed_features\\delta_tempogram_27ff0d1000b7677f7601949700eb5524.pkl\n",
      "Używane urządzenie: cpu\n",
      "Rozpoczynanie treningu dla cechy: delta_tempogram...\n",
      "Epoka 1/50, Strata treningu: 2.1932, Strata walidacji: 1.8811, Dokładność walidacji: 17.43%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_tempogram\\best_model_delta_tempogram_20250517_025447.pt\n",
      "Epoka 2/50, Strata treningu: 1.9587, Strata walidacji: 1.8571, Dokładność walidacji: 18.27%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_tempogram\\best_model_delta_tempogram_20250517_025447.pt\n",
      "Epoka 3/50, Strata treningu: 1.8754, Strata walidacji: 1.8064, Dokładność walidacji: 17.43%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_tempogram\\best_model_delta_tempogram_20250517_025447.pt\n",
      "Epoka 4/50, Strata treningu: 1.8487, Strata walidacji: 2.6819, Dokładność walidacji: 20.08%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 5/50, Strata treningu: 1.8280, Strata walidacji: 1.7908, Dokładność walidacji: 19.53%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_tempogram\\best_model_delta_tempogram_20250517_025447.pt\n",
      "Epoka 6/50, Strata treningu: 1.8117, Strata walidacji: 1.7948, Dokładność walidacji: 21.48%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 7/50, Strata treningu: 1.7950, Strata walidacji: 1.7783, Dokładność walidacji: 19.94%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_tempogram\\best_model_delta_tempogram_20250517_025447.pt\n",
      "Epoka 8/50, Strata treningu: 1.7925, Strata walidacji: 1.7754, Dokładność walidacji: 21.34%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_tempogram\\best_model_delta_tempogram_20250517_025447.pt\n",
      "Epoka 9/50, Strata treningu: 1.7983, Strata walidacji: 1.7797, Dokładność walidacji: 20.50%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 10/50, Strata treningu: 1.7896, Strata walidacji: 1.7841, Dokładność walidacji: 20.36%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 11/50, Strata treningu: 1.7845, Strata walidacji: 2.1393, Dokładność walidacji: 19.94%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 12/50, Strata treningu: 1.7823, Strata walidacji: 1.7602, Dokładność walidacji: 20.92%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_tempogram\\best_model_delta_tempogram_20250517_025447.pt\n",
      "Epoka 13/50, Strata treningu: 1.7826, Strata walidacji: 1.8034, Dokładność walidacji: 19.67%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 14/50, Strata treningu: 1.7606, Strata walidacji: 1.7708, Dokładność walidacji: 19.67%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 15/50, Strata treningu: 1.7696, Strata walidacji: 1.7696, Dokładność walidacji: 22.73%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 16/50, Strata treningu: 1.7555, Strata walidacji: 1.7656, Dokładność walidacji: 22.87%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 17/50, Strata treningu: 1.7439, Strata walidacji: 1.7915, Dokładność walidacji: 22.45%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 18/50, Strata treningu: 1.7382, Strata walidacji: 1.7571, Dokładność walidacji: 23.01%\n",
      "Strata walidacyjna uległa poprawie. Zapis modelu do feature_comparison_results\\delta_tempogram\\best_model_delta_tempogram_20250517_025447.pt\n",
      "Epoka 19/50, Strata treningu: 1.7263, Strata walidacji: 1.7602, Dokładność walidacji: 22.73%\n",
      "Counter wczesnego zatrzymywania: 1 z 7\n",
      "Epoka 20/50, Strata treningu: 1.7194, Strata walidacji: 1.7638, Dokładność walidacji: 22.87%\n",
      "Counter wczesnego zatrzymywania: 2 z 7\n",
      "Epoka 21/50, Strata treningu: 1.7209, Strata walidacji: 1.7742, Dokładność walidacji: 23.01%\n",
      "Counter wczesnego zatrzymywania: 3 z 7\n",
      "Epoka 22/50, Strata treningu: 1.7018, Strata walidacji: 1.7803, Dokładność walidacji: 23.99%\n",
      "Counter wczesnego zatrzymywania: 4 z 7\n",
      "Epoka 23/50, Strata treningu: 1.6816, Strata walidacji: 1.7993, Dokładność walidacji: 22.45%\n",
      "Counter wczesnego zatrzymywania: 5 z 7\n",
      "Epoka 24/50, Strata treningu: 1.6721, Strata walidacji: 1.7798, Dokładność walidacji: 22.45%\n",
      "Counter wczesnego zatrzymywania: 6 z 7\n",
      "Epoka 25/50, Strata treningu: 1.6654, Strata walidacji: 1.7902, Dokładność walidacji: 22.73%\n",
      "Counter wczesnego zatrzymywania: 7 z 7\n",
      "Aktywacja early stopping!\n",
      "Zakończenie treningu po 25 epokach. Czas: 3678.87 sekund\n",
      "\n",
      "Trening dla delta_tempogram zakończony sukcesem. Dokładność: 24.41%\n",
      "Czas treningu: 3745.79 sekund\n",
      "\n",
      "==================================================\n",
      "Wszystkie treningi zakończone. Generowanie raportu zbiorczego...\n",
      "==================================================\n",
      "\n",
      "Zapisano podsumowanie do: feature_comparison_results\\accuracy_summary_20250516_200832.csv\n",
      "Zapisano interaktywne wizualizacje do: feature_comparison_results\\accuracy_comparison_20250516_200832.html, feature_comparison_results\\training_time_comparison_20250516_200832.html, feature_comparison_results\\feature_comparison_20250516_200832.html\n",
      "\n",
      "Podsumowanie wyników:\n",
      "         Feature Type  Test Accuracy (%)  Training Time (s)\n",
      "2                mfcc          92.976589         705.077297\n",
      "1      melspectrogram          91.973244        1431.467628\n",
      "0         spectrogram          86.510591       14935.194999\n",
      "9          delta_mfcc          62.318841         345.235790\n",
      "3              chroma          48.160535         131.865898\n",
      "4   spectral_contrast          42.586399         107.042374\n",
      "8             tonnetz          37.458194         298.556895\n",
      "6                 rms          36.566332         830.577176\n",
      "7           tempogram          26.309922        4881.912961\n",
      "5                 zcr          26.086957         707.905367\n",
      "10    delta_tempogram          24.414716        3745.786781\n"
     ]
    }
   ],
   "source": [
    "# Uruchom trening dla wszystkich typów cech\n",
    "results_df = run_training_experiment(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trening przeprowadzany wyłącznie dla melspektrogramu\n",
    "# accuracy = run_training_experiment(dataset, feature_type=\"chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = run_training_experiment(dataset, feature_type=\"melspectrogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = run_training_experiment(dataset, feature_type=\"mfcc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rozpoczyna trening, pomijając cechy, dla których wyniki są już dostępne\n",
    "# results_df = run_training_experiment(dataset, skip_trained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generowanie Wizualizacji Wyników Analizy\n",
    "\n",
    " Funkcja `generate_all_visualizations` automatycznie generuje i zapisuje wizualizacje wyników analizy różnych cech audio. Funkcja wyszukuje katalog z wynikami, odczytuje dane dotyczące dokładności i emocji, sortuje wyniki według dokładności, zapisuje je do plików CSV oraz tworzy wykresy porównawcze i wizualizacje emocji, zapisując je w odpowiednich lokalizacjach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Znalezione wyniki dokładności:\n",
      "         Feature Type  Test Accuracy (%)  Training Time (s)\n",
      "4                mfcc          92.976589         702.907264\n",
      "3      melspectrogram          91.973244        1419.448323\n",
      "7         spectrogram          86.510591       14884.568313\n",
      "1          delta_mfcc          62.318841         343.071561\n",
      "0              chroma          48.160535         130.665853\n",
      "6   spectral_contrast          42.586399         106.098412\n",
      "9             tonnetz          37.458194         297.145460\n",
      "5                 rms          36.566332         825.372480\n",
      "8           tempogram          26.309922        4864.870266\n",
      "10                zcr          26.086957         702.820685\n",
      "2     delta_tempogram          24.414716        3730.550771\n",
      "Zapisano wyniki dokładności do: feature_comparison_results\\feature_comparison_summary_auto.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "purple"
         },
         "name": "Dokładność",
         "text": [
          "93.0%",
          "92.0%",
          "86.5%",
          "62.3%",
          "48.2%",
          "42.6%",
          "37.5%",
          "36.6%",
          "26.3%",
          "26.1%",
          "24.4%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "mfcc",
          "melspectrogram",
          "spectrogram",
          "delta_mfcc",
          "chroma",
          "spectral_contrast",
          "tonnetz",
          "rms",
          "tempogram",
          "zcr",
          "delta_tempogram"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "j4uXbYA+V0ARxNGhSf5WQGSiR4WtoFVAEz+jxM8oT0AzzypqjBRIQLztPyAPS0VAtoSvGaa6QkDWk/qSfUhCQJGDswtXTzpAIQtZyEIWOkDagzLPKmo4QA==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "purple"
         },
         "name": "Czas treningu",
         "text": [
          "702s",
          "1419s",
          "14884s",
          "343s",
          "130s",
          "106s",
          "297s",
          "825s",
          "4864s",
          "702s",
          "3730s"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "mfcc",
          "melspectrogram",
          "spectrogram",
          "delta_mfcc",
          "chroma",
          "spectral_contrast",
          "tonnetz",
          "rms",
          "tempogram",
          "zcr",
          "delta_tempogram"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "AACAE0L3hUAAADAVyy2WQAAAfL5IEs1AAABAHSVxdUAAAICrTlVgQAAAAGBMhlpAAAAAzlOSckAAAMDW+sqJQAAAwMneALNAAABAw5D2hUAAALD+GSWtQA==",
          "dtype": "f8"
         },
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Porównanie dokładności dla różnych reprezentacji audio",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Porównanie czasu treningu dla różnych reprezentacji audio",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 600,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "tickangle": -45,
         "title": {
          "text": "Typ cechy"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "tickangle": -45,
         "title": {
          "text": "Typ cechy"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Dokładność testu (%)"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Czas treningu (s)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zapisano wykres porównania dokładności do: feature_comparison_results\\combined_comparison_auto.html\n",
      "\n",
      "Zapisano wyniki emocji do: feature_comparison_results\\emotions_comparison_auto.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Emotion: %{x}<br>Feature Type: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z:.1f}",
         "type": "heatmap",
         "x": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "xaxis": "x",
         "y": [
          "mfcc",
          "melspectrogram",
          "spectrogram",
          "delta_mfcc",
          "chroma",
          "spectral_contrast",
          "tonnetz",
          "rms",
          "tempogram",
          "zcr",
          "delta_tempogram"
         ],
         "yaxis": "y",
         "z": {
          "bdata": "i+GCJ7AmV0DIZ91givxXQGLEiBEjxlZAx3Ecx3GcV0CGz7zqHBZYQKuqqqqqqlVAwDravE9xV0Df9KY3velXQDqQaIXNAVZAYEJ7Ce0lV0CCJb38aQtYQH41JtIDFVVAWK9evXp1V0Do1o8I4uhWQBxMkc+6QVNApAcqZ7fwVUBQXkN5DYVXQLRb+NWYSFJArK+++uqrT0DaS2gvob1OQOgpon69sEpAvrH6Az1SUEBbJoscIKRSQDJXym9sM0pAFcTkCmJyQUDRRRdddLFMQHkN5TWU10BAkiRJkiRpQUDvy2MrgoZQQAAAAAAAAElAbjR1fu0hR0Bm5SfEWflJQDMzMzMzM0NAl0nPiGSZQEAWHOPbkndNQPq7GFSEWzJAt+aHRcrAQ0DxqzGRHqhCQOqll1566T1AAAAAAADAQkC1faEwbV9IQD0CJobocD9Azdah32wdREBSGwkDAas7QARV+pnT4DZAE3OyLhiRQkBkIQtZyEJMQA2KOrm8CD5AoK7R2URiO0Ci028rzRo3QMRJ3ZfHVjRA9+WxFUHDOUB1KJqNm29EQNP16fp0fRpAa7LJJptsMUCFeqiHeqgzQHRrflikDEBALrrooosuMkB9DM7H4HxEQBC8nIKXUxBAr0ie7PfRNEAYb2WfQ2oqQGc84xnPeDZATDbZZJNNPkC6MLUY7AhDQJBt27Zt2/Y/",
          "dtype": "f8",
          "shape": "11, 6"
         }
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "F1-score (%)"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(252,251,253)"
          ],
          [
           0.125,
           "rgb(239,237,245)"
          ],
          [
           0.25,
           "rgb(218,218,235)"
          ],
          [
           0.375,
           "rgb(188,189,220)"
          ],
          [
           0.5,
           "rgb(158,154,200)"
          ],
          [
           0.625,
           "rgb(128,125,186)"
          ],
          [
           0.75,
           "rgb(106,81,163)"
          ],
          [
           0.875,
           "rgb(84,39,143)"
          ],
          [
           1,
           "rgb(63,0,125)"
          ]
         ]
        },
        "height": 800,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "F1-score dla każdej emocji i typu cechy (%)"
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Emocja"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Typ cechy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Feature Type=melspectrogram<br>Emotion=%{x}<br>F1-score=%{y}<extra></extra>",
         "legendgroup": "melspectrogram",
         "marker": {
          "color": "rgb(218,218,235)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "melspectrogram",
         "offsetgroup": "melspectrogram",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "wDravE9xV0Df9KY3velXQDqQaIXNAVZAYEJ7Ce0lV0CCJb38aQtYQH41JtIDFVVA",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Feature Type=mfcc<br>Emotion=%{x}<br>F1-score=%{y}<extra></extra>",
         "legendgroup": "mfcc",
         "marker": {
          "color": "rgb(188,189,220)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "mfcc",
         "offsetgroup": "mfcc",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "i+GCJ7AmV0DIZ91givxXQGLEiBEjxlZAx3Ecx3GcV0CGz7zqHBZYQKuqqqqqqlVA",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Feature Type=spectrogram<br>Emotion=%{x}<br>F1-score=%{y}<extra></extra>",
         "legendgroup": "spectrogram",
         "marker": {
          "color": "rgb(158,154,200)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "spectrogram",
         "offsetgroup": "spectrogram",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "WK9evXp1V0Do1o8I4uhWQBxMkc+6QVNApAcqZ7fwVUBQXkN5DYVXQLRb+NWYSFJA",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 600,
        "legend": {
         "title": {
          "text": "Typ cechy"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Porównanie F1-score dla 3 najlepszych reprezentacji"
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Emocja"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "F1-score (%)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "chroma",
         "r": {
          "bdata": "FcTkCmJyQUDRRRdddLFMQHkN5TWU10BAkiRJkiRpQUDvy2MrgoZQQAAAAAAAAElA",
          "dtype": "f8"
         },
         "subplot": "polar",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "delta_mfcc",
         "r": {
          "bdata": "rK+++uqrT0DaS2gvob1OQOgpon69sEpAvrH6Az1SUEBbJoscIKRSQDJXym9sM0pA",
          "dtype": "f8"
         },
         "subplot": "polar2",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "delta_tempogram",
         "r": {
          "bdata": "r0ie7PfRNEAYb2WfQ2oqQGc84xnPeDZATDbZZJNNPkC6MLUY7AhDQJBt27Zt2/Y/",
          "dtype": "f8"
         },
         "subplot": "polar3",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "melspectrogram",
         "r": {
          "bdata": "wDravE9xV0Df9KY3velXQDqQaIXNAVZAYEJ7Ce0lV0CCJb38aQtYQH41JtIDFVVA",
          "dtype": "f8"
         },
         "subplot": "polar4",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "mfcc",
         "r": {
          "bdata": "i+GCJ7AmV0DIZ91givxXQGLEiBEjxlZAx3Ecx3GcV0CGz7zqHBZYQKuqqqqqqlVA",
          "dtype": "f8"
         },
         "subplot": "polar5",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "rms",
         "r": {
          "bdata": "zdah32wdREBSGwkDAas7QARV+pnT4DZAE3OyLhiRQkBkIQtZyEJMQA2KOrm8CD5A",
          "dtype": "f8"
         },
         "subplot": "polar6",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "spectral_contrast",
         "r": {
          "bdata": "bjR1fu0hR0Bm5SfEWflJQDMzMzMzM0NAl0nPiGSZQEAWHOPbkndNQPq7GFSEWzJA",
          "dtype": "f8"
         },
         "subplot": "polar7",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "spectrogram",
         "r": {
          "bdata": "WK9evXp1V0Do1o8I4uhWQBxMkc+6QVNApAcqZ7fwVUBQXkN5DYVXQLRb+NWYSFJA",
          "dtype": "f8"
         },
         "subplot": "polar8",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "tempogram",
         "r": {
          "bdata": "oK7R2URiO0Ci028rzRo3QMRJ3ZfHVjRA9+WxFUHDOUB1KJqNm29EQNP16fp0fRpA",
          "dtype": "f8"
         },
         "subplot": "polar9",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "tonnetz",
         "r": {
          "bdata": "t+aHRcrAQ0DxqzGRHqhCQOqll1566T1AAAAAAADAQkC1faEwbV9IQD0CJobocD9A",
          "dtype": "f8"
         },
         "subplot": "polar10",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "purple"
         },
         "name": "zcr",
         "r": {
          "bdata": "a7LJJptsMUCFeqiHeqgzQHRrflikDEBALrrooosuMkB9DM7H4HxEQBC8nIKXUxBA",
          "dtype": "f8"
         },
         "subplot": "polar11",
         "theta": [
          "anger",
          "fear",
          "happiness",
          "neutral",
          "sadness",
          "surprised"
         ],
         "type": "scatterpolar"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "chroma",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "delta_mfcc",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "delta_tempogram",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "melspectrogram",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.71875,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "mfcc",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.71875,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "rms",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.71875,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "spectral_contrast",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "spectrogram",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "tempogram",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "tonnetz",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.15625,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "zcr",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.15625,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 1520,
        "polar": {
         "domain": {
          "x": [
           0,
           0.2888888888888889
          ],
          "y": [
           0.84375,
           1
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar10": {
         "domain": {
          "x": [
           0,
           0.2888888888888889
          ],
          "y": [
           0,
           0.15625
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar11": {
         "domain": {
          "x": [
           0.35555555555555557,
           0.6444444444444445
          ],
          "y": [
           0,
           0.15625
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar12": {
         "domain": {
          "x": [
           0.7111111111111111,
           1
          ],
          "y": [
           0,
           0.15625
          ]
         }
        },
        "polar2": {
         "domain": {
          "x": [
           0.35555555555555557,
           0.6444444444444445
          ],
          "y": [
           0.84375,
           1
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar3": {
         "domain": {
          "x": [
           0.7111111111111111,
           1
          ],
          "y": [
           0.84375,
           1
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar4": {
         "domain": {
          "x": [
           0,
           0.2888888888888889
          ],
          "y": [
           0.5625,
           0.71875
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar5": {
         "domain": {
          "x": [
           0.35555555555555557,
           0.6444444444444445
          ],
          "y": [
           0.5625,
           0.71875
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar6": {
         "domain": {
          "x": [
           0.7111111111111111,
           1
          ],
          "y": [
           0.5625,
           0.71875
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar7": {
         "domain": {
          "x": [
           0,
           0.2888888888888889
          ],
          "y": [
           0.28125,
           0.4375
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar8": {
         "domain": {
          "x": [
           0.35555555555555557,
           0.6444444444444445
          ],
          "y": [
           0.28125,
           0.4375
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "polar9": {
         "domain": {
          "x": [
           0.7111111111111111,
           1
          ],
          "y": [
           0.28125,
           0.4375
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1200
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "red"
         },
         "text": [
          "93.8%",
          "93.8%",
          "92.6%",
          "63.3%",
          "46.3%",
          "40.2%",
          "39.5%",
          "34.9%",
          "27.4%",
          "20.8%",
          "17.4%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "spectrogram",
          "melspectrogram",
          "mfcc",
          "delta_mfcc",
          "spectral_contrast",
          "rms",
          "tonnetz",
          "chroma",
          "tempogram",
          "delta_tempogram",
          "zcr"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "WK9evXp1V0DAOtq8T3FXQIvhgiewJldArK+++uqrT0BuNHV+7SFHQM3Wod9sHURAt+aHRcrAQ0AVxOQKYnJBQKCu0dlEYjtAr0ie7PfRNEBrsskmm2wxQA==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "purple"
         },
         "text": [
          "95.9%",
          "95.7%",
          "91.6%",
          "61.5%",
          "57.4%",
          "51.9%",
          "37.3%",
          "27.7%",
          "23.1%",
          "19.7%",
          "13.2%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "mfcc",
          "melspectrogram",
          "spectrogram",
          "delta_mfcc",
          "chroma",
          "spectral_contrast",
          "tonnetz",
          "rms",
          "tempogram",
          "zcr",
          "delta_tempogram"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "yGfdYIr8V0Df9KY3velXQOjWjwji6FZA2ktoL6G9TkDRRRdddLFMQGblJ8RZ+UlA8asxkR6oQkBSGwkDAas7QKLTbyvNGjdAhXqoh3qoM0AYb2WfQ2oqQA==",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "yellow"
         },
         "text": [
          "91.1%",
          "88.0%",
          "77.0%",
          "53.4%",
          "38.4%",
          "33.7%",
          "32.1%",
          "29.9%",
          "22.9%",
          "22.5%",
          "20.3%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "mfcc",
          "melspectrogram",
          "spectrogram",
          "delta_mfcc",
          "spectral_contrast",
          "chroma",
          "zcr",
          "tonnetz",
          "rms",
          "delta_tempogram",
          "tempogram"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "YsSIESPGVkA6kGiFzQFWQBxMkc+6QVNA6Cmifr2wSkAzMzMzMzNDQHkN5TWU10BAdGt+WKQMQEDqpZdeeuk9QARV+pnT4DZAZzzjGc94NkDESd2Xx1Y0QA==",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "blue"
         },
         "text": [
          "94.4%",
          "92.6%",
          "87.8%",
          "65.3%",
          "37.5%",
          "37.1%",
          "34.8%",
          "33.2%",
          "30.3%",
          "25.8%",
          "18.2%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "mfcc",
          "melspectrogram",
          "spectrogram",
          "delta_mfcc",
          "tonnetz",
          "rms",
          "chroma",
          "spectral_contrast",
          "delta_tempogram",
          "tempogram",
          "zcr"
         ],
         "xaxis": "x4",
         "y": {
          "bdata": "x3Ecx3GcV0BgQnsJ7SVXQKQHKme38FVAvrH6Az1SUEAAAAAAAMBCQBNzsi4YkUJAkiRJkiRpQUCXSc+IZJlAQEw22WSTTT5A9+WxFUHDOUAuuuiiiy4yQA==",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "gray"
         },
         "text": [
          "96.3%",
          "96.2%",
          "94.1%",
          "74.6%",
          "66.1%",
          "58.9%",
          "56.5%",
          "48.7%",
          "41.0%",
          "40.9%",
          "38.1%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "mfcc",
          "melspectrogram",
          "spectrogram",
          "delta_mfcc",
          "chroma",
          "spectral_contrast",
          "rms",
          "tonnetz",
          "zcr",
          "tempogram",
          "delta_tempogram"
         ],
         "xaxis": "x5",
         "y": {
          "bdata": "hs+86hwWWECCJb38aQtYQFBeQ3kNhVdAWyaLHCCkUkDvy2MrgoZQQBYc49uSd01AZCELWchCTEC1faEwbV9IQH0MzsfgfERAdSiajZtvREC6MLUY7AhDQA==",
          "dtype": "f8"
         },
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "green"
         },
         "text": [
          "86.7%",
          "84.3%",
          "73.1%",
          "52.4%",
          "50.0%",
          "31.4%",
          "30.0%",
          "18.4%",
          "6.6%",
          "4.1%",
          "1.4%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "mfcc",
          "melspectrogram",
          "spectrogram",
          "delta_mfcc",
          "chroma",
          "tonnetz",
          "rms",
          "spectral_contrast",
          "tempogram",
          "zcr",
          "delta_tempogram"
         ],
         "xaxis": "x6",
         "y": {
          "bdata": "q6qqqqqqVUB+NSbSAxVVQLRb+NWYSFJAMlfKb2wzSkAAAAAAAABJQD0CJobocD9ADYo6ubwIPkD6uxhUhFsyQNP16fp0fRpAELycgpdTEECQbdu2bdv2Pw==",
          "dtype": "f8"
         },
         "yaxis": "y6"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "anger",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "fear",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "happiness",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6333333333333333,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "neutral",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6333333333333333,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "sadness",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.26666666666666666,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "surprised",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.26666666666666666,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 1000,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Porównanie F1-score dla różnych emocji według typu reprezentacji"
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "tickangle": -45
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "tickangle": -45
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ],
         "tickangle": -45
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ],
         "tickangle": -45
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.45
         ],
         "tickangle": -45
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.55,
          1
         ],
         "tickangle": -45
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.7333333333333334,
          1
         ],
         "range": [
          0,
          110
         ],
         "title": {
          "text": "F1-score (%)"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.7333333333333334,
          1
         ],
         "range": [
          0,
          110
         ],
         "title": {
          "text": "F1-score (%)"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.3666666666666667,
          0.6333333333333333
         ],
         "range": [
          0,
          110
         ],
         "title": {
          "text": "F1-score (%)"
         }
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.3666666666666667,
          0.6333333333333333
         ],
         "range": [
          0,
          110
         ],
         "title": {
          "text": "F1-score (%)"
         }
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.26666666666666666
         ],
         "range": [
          0,
          110
         ],
         "title": {
          "text": "F1-score (%)"
         }
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.26666666666666666
         ],
         "range": [
          0,
          110
         ],
         "title": {
          "text": "F1-score (%)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wygenerowane wizualizacje emocji:\n",
      "- heatmap: feature_comparison_results\\emotions_heatmap_auto.html\n",
      "- top_features: feature_comparison_results\\top_features_emotions_auto.html\n",
      "- radar: feature_comparison_results\\emotions_radar_auto.html\n",
      "- dashboard: feature_comparison_results\\emotions_dashboard_auto.html\n",
      "\n",
      "Generowanie wszystkich wizualizacji zakończone pomyślnie.\n"
     ]
    }
   ],
   "source": [
    "def generate_all_visualizations():\n",
    "    \"\"\"Generuje i zapisuje wszystkie wizualizacje wyników analizy.\"\"\"\n",
    "    # Wyszukiwanie katalogu z wynikami\n",
    "    base_dir = find_results_directory()\n",
    "    if base_dir is None:\n",
    "        return\n",
    "    \n",
    "    # Odczyt wyników z plików\n",
    "    results_df = read_results_from_files(base_dir)\n",
    "    emotions_df = read_emotion_results(base_dir)\n",
    "    \n",
    "    # Ustalenie katalogu do zapisu\n",
    "    save_dir = base_dir\n",
    "    \n",
    "    # Przetwarzanie wyników dokładności\n",
    "    if results_df is not None and not results_df.empty:\n",
    "        # Sortowanie wyników według dokładności w porządku malejącym\n",
    "        results_df = results_df.sort_values('Test Accuracy (%)', ascending=False)\n",
    "        \n",
    "        # Wyświetlenie DataFrame dla przeglądu wyników\n",
    "        print(f\"\\nZnalezione wyniki dokładności:\\n{results_df}\")\n",
    "        \n",
    "        # Zapis wyników do pliku CSV\n",
    "        csv_path = os.path.join(save_dir, 'feature_comparison_summary_auto.csv')\n",
    "        results_df.to_csv(csv_path, index=False)\n",
    "        print(f\"Zapisano wyniki dokładności do: {csv_path}\")\n",
    "        \n",
    "        # Generowanie wykresu porównania dokładności\n",
    "        combined_path = generate_accuracy_comparison_plot(results_df, save_dir)\n",
    "        print(f\"Zapisano wykres porównania dokładności do: {combined_path}\")\n",
    "    else:\n",
    "        print(\"Brak danych dokładności do wygenerowania wykresów.\")\n",
    "    \n",
    "    # Przetwarzanie wyników emocji\n",
    "    if emotions_df is not None and not emotions_df.empty:\n",
    "        # Zapis wyników emocji do pliku CSV\n",
    "        emotions_csv_path = os.path.join(save_dir, 'emotions_comparison_auto.csv')\n",
    "        emotions_df.to_csv(emotions_csv_path, index=False)\n",
    "        print(f\"\\nZapisano wyniki emocji do: {emotions_csv_path}\")\n",
    "        \n",
    "        # Generowanie wizualizacji emocji\n",
    "        emotion_paths = generate_emotion_visualizations(emotions_df, results_df, save_dir)\n",
    "        print(\"\\nWygenerowane wizualizacje emocji:\")\n",
    "        for name, path in emotion_paths.items():\n",
    "            if path:\n",
    "                print(f\"- {name}: {path}\")\n",
    "        \n",
    "        print(\"\\nGenerowanie wszystkich wizualizacji zakończone pomyślnie.\")\n",
    "    else:\n",
    "        print(\"Brak danych emocji do wygenerowania wykresów.\")\n",
    "\n",
    "# Uruchomienie generowania wszystkich wizualizacji\n",
    "generate_all_visualizations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statystyki dla chroma:\n",
      "Liczba próbek: 4481\n",
      "Kształt danych: (4481, 1, 12, 141)\n",
      "Średnia globalna: 0.0000\n",
      "Odchylenie standardowe: 1.0000\n",
      "Min: -0.8742\n",
      "Max: 2.2295\n",
      "Średnie per kanał: ['0.0000']\n",
      "Zapisano do: normalization_stats\\chroma_stats.json\n",
      "\n",
      "Statystyki dla delta_mfcc:\n",
      "Liczba próbek: 4481\n",
      "Kształt danych: (4481, 1, 40, 141)\n",
      "Średnia globalna: -0.0000\n",
      "Odchylenie standardowe: 1.0000\n",
      "Min: -4.1857\n",
      "Max: 4.1772\n",
      "Średnie per kanał: ['-0.0000']\n",
      "Zapisano do: normalization_stats\\delta_mfcc_stats.json\n",
      "\n",
      "Statystyki dla delta_tempogram:\n",
      "Liczba próbek: 4481\n",
      "Kształt danych: (4481, 1, 384, 141)\n",
      "Średnia globalna: -0.0000\n",
      "Odchylenie standardowe: 1.0000\n",
      "Min: -3.1362\n",
      "Max: 3.0167\n",
      "Średnie per kanał: ['-0.0000']\n",
      "Zapisano do: normalization_stats\\delta_tempogram_stats.json\n",
      "\n",
      "Statystyki dla melspectrogram:\n",
      "Liczba próbek: 4481\n",
      "Kształt danych: (4481, 1, 128, 141)\n",
      "Średnia globalna: -0.0000\n",
      "Odchylenie standardowe: 1.0000\n",
      "Min: -1.2534\n",
      "Max: 3.0191\n",
      "Średnie per kanał: ['-0.0000']\n",
      "Zapisano do: normalization_stats\\melspectrogram_stats.json\n",
      "\n",
      "Statystyki dla mfcc:\n",
      "Liczba próbek: 4481\n",
      "Kształt danych: (4481, 1, 40, 141)\n",
      "Średnia globalna: -0.0000\n",
      "Odchylenie standardowe: 1.0000\n",
      "Min: -5.4612\n",
      "Max: 5.7581\n",
      "Średnie per kanał: ['-0.0000']\n",
      "Zapisano do: normalization_stats\\mfcc_stats.json\n",
      "\n",
      "Statystyki dla rms:\n",
      "Liczba próbek: 4481\n",
      "Kształt danych: (4481, 1, 128, 141)\n",
      "Średnia globalna: -0.0000\n",
      "Odchylenie standardowe: 1.0000\n",
      "Min: -0.7043\n",
      "Max: 6.5546\n",
      "Średnie per kanał: ['-0.0000']\n",
      "Zapisano do: normalization_stats\\rms_stats.json\n",
      "\n",
      "Statystyki dla spectral_contrast:\n",
      "Liczba próbek: 4481\n",
      "Kształt danych: (4481, 1, 7, 141)\n",
      "Średnia globalna: 0.0000\n",
      "Odchylenie standardowe: 1.0000\n",
      "Min: -2.5445\n",
      "Max: 4.3194\n",
      "Średnie per kanał: ['0.0000']\n",
      "Zapisano do: normalization_stats\\spectral_contrast_stats.json\n",
      "\n",
      "Statystyki dla spectrogram:\n",
      "Liczba próbek: 4481\n",
      "Kształt danych: (4481, 1, 1025, 141)\n",
      "Średnia globalna: -0.0000\n",
      "Odchylenie standardowe: 1.0000\n",
      "Min: -0.9422\n",
      "Max: 4.4475\n",
      "Średnie per kanał: ['-0.0000']\n",
      "Zapisano do: normalization_stats\\spectrogram_stats.json\n",
      "\n",
      "Statystyki dla tempogram:\n",
      "Liczba próbek: 4481\n",
      "Kształt danych: (4481, 1, 384, 141)\n",
      "Średnia globalna: -0.0000\n",
      "Odchylenie standardowe: 1.0000\n",
      "Min: -0.4988\n",
      "Max: 6.1888\n",
      "Średnie per kanał: ['-0.0000']\n",
      "Zapisano do: normalization_stats\\tempogram_stats.json\n",
      "\n",
      "Statystyki dla tonnetz:\n",
      "Liczba próbek: 4481\n",
      "Kształt danych: (4481, 1, 6, 141)\n",
      "Średnia globalna: 0.0000\n",
      "Odchylenie standardowe: 1.0000\n",
      "Min: -3.1009\n",
      "Max: 3.2583\n",
      "Średnie per kanał: ['0.0000']\n",
      "Zapisano do: normalization_stats\\tonnetz_stats.json\n",
      "\n",
      "Statystyki dla zcr:\n",
      "Liczba próbek: 4481\n",
      "Kształt danych: (4481, 1, 128, 141)\n",
      "Średnia globalna: 0.0000\n",
      "Odchylenie standardowe: 1.0000\n",
      "Min: -0.6393\n",
      "Max: 6.6146\n",
      "Średnie per kanał: ['0.0000']\n",
      "Zapisano do: normalization_stats\\zcr_stats.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_feature_statistics(cache_dir=\"processed_features\", stats_dir=\"normalization_stats\"):\n",
    "    \"\"\"\n",
    "    Analizuje statystyki cech z zapisanych plików cache bez modyfikacji oryginalnego kodu.\n",
    "    \n",
    "    Args:\n",
    "        cache_dir: Katalog z zapisanymi cechami\n",
    "        stats_dir: Katalog do zapisania statystyk\n",
    "        \n",
    "    Returns:\n",
    "        dict: Słownik ze statystykami dla każdego typu cechy\n",
    "    \"\"\"\n",
    "    os.makedirs(stats_dir, exist_ok=True)\n",
    "    all_stats = {}\n",
    "    \n",
    "    # Wyszukiwanie plików cache\n",
    "    cache_files = glob.glob(os.path.join(cache_dir, \"*.pkl\"))\n",
    "    \n",
    "    for cache_file in cache_files:\n",
    "        try:\n",
    "            # Odczyt danych z cache\n",
    "            with open(cache_file, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            \n",
    "            feature_type = data['feature_type']\n",
    "            features = data['features']\n",
    "            \n",
    "            # Wyliczanie statystyk\n",
    "            stats = {\n",
    "                'feature_type': feature_type,\n",
    "                'mean': float(np.mean(features)),\n",
    "                'std': float(np.std(features)),\n",
    "                'min': float(np.min(features)),\n",
    "                'max': float(np.max(features)),\n",
    "                'shape': features.shape,\n",
    "                'n_samples': features.shape[0],\n",
    "                'timestamp': datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            }\n",
    "            \n",
    "            # Dodatkowe statystyki per kanał/wymiar\n",
    "            if features.ndim > 2:\n",
    "                stats['channel_means'] = [float(np.mean(features[:, i, :, :])) \n",
    "                                        for i in range(features.shape[1])]\n",
    "                stats['channel_stds'] = [float(np.std(features[:, i, :, :])) \n",
    "                                       for i in range(features.shape[1])]\n",
    "            \n",
    "            # Zapisywanie do pliku JSON\n",
    "            stats_file = os.path.join(stats_dir, f\"{feature_type}_stats.json\")\n",
    "            with open(stats_file, 'w') as f:\n",
    "                json.dump(stats, f, indent=4)\n",
    "            \n",
    "            all_stats[feature_type] = stats\n",
    "            \n",
    "            # Wyświetlanie podsumowania\n",
    "            print(f\"\\nStatystyki dla {feature_type}:\")\n",
    "            print(f\"Liczba próbek: {stats['n_samples']}\")\n",
    "            print(f\"Kształt danych: {stats['shape']}\")\n",
    "            print(f\"Średnia globalna: {stats['mean']:.4f}\")\n",
    "            print(f\"Odchylenie standardowe: {stats['std']:.4f}\")\n",
    "            print(f\"Min: {stats['min']:.4f}\")\n",
    "            print(f\"Max: {stats['max']:.4f}\")\n",
    "            if 'channel_means' in stats:\n",
    "                print(\"Średnie per kanał:\", \n",
    "                      [f\"{x:.4f}\" for x in stats['channel_means']])\n",
    "            print(f\"Zapisano do: {stats_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Błąd podczas przetwarzania {cache_file}: {str(e)}\")\n",
    "    \n",
    "    # Zapisywanie zbiorczego podsumowania\n",
    "    summary_file = os.path.join(stats_dir, \"all_features_summary.json\")\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(all_stats, f, indent=4)\n",
    "    \n",
    "    # Generowanie wykresu porównawczego\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    feature_types = list(all_stats.keys())\n",
    "    means = [all_stats[ft]['mean'] for ft in feature_types]\n",
    "    stds = [all_stats[ft]['std'] for ft in feature_types]\n",
    "    \n",
    "    x = np.arange(len(feature_types))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, means, width, label='Średnia')\n",
    "    plt.bar(x + width/2, stds, width, label='Odchylenie std.')\n",
    "    \n",
    "    plt.xlabel('Typ cechy')\n",
    "    plt.ylabel('Wartość')\n",
    "    plt.title('Porównanie statystyk dla różnych typów cech')\n",
    "    plt.xticks(x, feature_types, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Zapisywanie wykresu\n",
    "    plt.savefig(os.path.join(stats_dir, 'features_statistics_comparison.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    return all_stats\n",
    "\n",
    "# Po zakończeniu treningu wszystkich modeli\n",
    "stats = analyze_feature_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Audio Emotion Recognition)",
   "language": "python",
   "name": "audio-emotion-recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
