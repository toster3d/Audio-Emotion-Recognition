{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Nowoczesny eksport modelu ensemble do ONNX\n",
    "\n",
    "Ten notebook implementuje najlepsze praktyki eksportu do ONNX zgodne z PyTorch 2.7+ i najnowszymi standardami ONNX.\n",
    "\n",
    "## Funkcje:\n",
    "- ‚úÖ Bezpieczne ≈Çadowanie modeli\n",
    "- ‚úÖ Optymalizacja modeli ONNX\n",
    "- ‚úÖ Kwantyzacja (dynamiczna i statyczna)\n",
    "- ‚úÖ Weryfikacja zgodno≈õci\n",
    "- ‚úÖ Eksport metadanych\n",
    "- ‚úÖ Jednolite wej≈õcie tensorowe\n",
    "- ‚úÖ Obs≈Çuga dynamicznych rozmiar√≥w\n",
    "- ‚úÖ Obs≈Çuga 5 typ√≥w cech: chroma, tempogram, mfcc, melspectrogram, hpss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Wersje bibliotek:\n",
      "   PyTorch: 2.7.0+cpu\n",
      "   ONNX: 1.18.0\n",
      "   ONNX Runtime: 1.19.2\n",
      "   Python: 3.9.13\n"
     ]
    }
   ],
   "source": [
    "# Importy i konfiguracja\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Dodanie ≈õcie≈ºki do modu≈Ç√≥w\n",
    "sys.path.append(os.path.join(os.getcwd()))\n",
    "\n",
    "from export_scripts.modern_onnx_exporter import ModernONNXExporter, ExportConfig\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "print(f\"üîß Wersje bibliotek:\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   ONNX: {onnx.__version__}\")\n",
    "print(f\"   ONNX Runtime: {ort.__version__}\")\n",
    "print(f\"   Python: {sys.version.split()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Konfiguracja eksportu\n",
    "\n",
    "Ustaw parametry eksportu zgodnie z Twoimi potrzebami:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Konfiguracja eksportu:\n",
      "   Opset version: 19\n",
      "   Optymalizacja: True\n",
      "   Kwantyzacja: False\n",
      "   Typ kwantyzacji: dynamic\n",
      "   Weryfikacja: True\n"
     ]
    }
   ],
   "source": [
    "# Konfiguracja eksportu - dostosuj wed≈Çug potrzeb\n",
    "config = ExportConfig(\n",
    "    model_path=None,  # None = automatyczne wykrycie najnowszego modelu\n",
    "    output_dir=None,  # None = automatyczne tworzenie katalogu z timestamp\n",
    "    \n",
    "    # Parametry audio\n",
    "    sample_rate=22050,\n",
    "    max_length=3.0,  # sekundy\n",
    "    \n",
    "    # Parametry ONNX\n",
    "    opset_version=19,  # Najnowsza stabilna wersja\n",
    "    \n",
    "    # Optymalizacje\n",
    "    enable_optimization=True,     # W≈ÇƒÖcz optymalizacjƒô grafu ONNX\n",
    "    enable_quantization=False,    # W≈ÇƒÖcz kwantyzacjƒô (zmniejsza rozmiar)\n",
    "    quantization_type=\"dynamic\",  # \"dynamic\" lub \"static\"\n",
    "    \n",
    "    # Dodatkowe opcje\n",
    "    fp16_conversion=False,        # Konwersja do po≈Ç√≥wkowej precyzji\n",
    "    verify_model=True,            # Weryfikacja zgodno≈õci modeli\n",
    "    export_metadata=True          # Eksport metadanych\n",
    ")\n",
    "\n",
    "print(\"üìã Konfiguracja eksportu:\")\n",
    "print(f\"   Opset version: {config.opset_version}\")\n",
    "print(f\"   Optymalizacja: {config.enable_optimization}\")\n",
    "print(f\"   Kwantyzacja: {config.enable_quantization}\")\n",
    "print(f\"   Typ kwantyzacji: {config.quantization_type}\")\n",
    "print(f\"   Weryfikacja: {config.verify_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Wyszukiwanie dostƒôpnych modeli\n",
    "\n",
    "Sprawd≈∫my jakie modele ensemble sƒÖ dostƒôpne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Znaleziono 1 modeli ensemble:\n",
      "   1. ensemble_outputs\\ensemble_run_20250523_193302\\models\\ensemble_model.pt\n",
      "      Timestamp: 20250523_193302\\models\\ensemble_model.pt\n",
      "      Rozmiar: 213.51 MB\n",
      "      ‚≠ê Najnowszy model\n",
      "\n",
      "‚úÖ Automatycznie wybrano najnowszy model: ensemble_outputs\\ensemble_run_20250523_193302\\models\\ensemble_model.pt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# Wyszukiwanie modeli ensemble\n",
    "ensemble_models = glob.glob(\"ensemble_outputs/ensemble_run_*/models/ensemble_model.pt\")\n",
    "\n",
    "if ensemble_models:\n",
    "    print(f\"üîç Znaleziono {len(ensemble_models)} modeli ensemble:\")\n",
    "    \n",
    "    for i, model_path in enumerate(sorted(ensemble_models, reverse=True)):\n",
    "        # Ekstraktowanie timestamp z nazwy katalogu\n",
    "        timestamp_str = model_path.split('ensemble_run_')[1].split('/')[0]\n",
    "        \n",
    "        # Rozmiar pliku\n",
    "        size_mb = os.path.getsize(model_path) / (1024 * 1024)\n",
    "        \n",
    "        print(f\"   {i+1}. {model_path}\")\n",
    "        print(f\"      Timestamp: {timestamp_str}\")\n",
    "        print(f\"      Rozmiar: {size_mb:.2f} MB\")\n",
    "        \n",
    "        if i == 0:\n",
    "            latest_model = model_path\n",
    "            print(f\"      ‚≠ê Najnowszy model\")\n",
    "        print()\n",
    "    \n",
    "    # Automatyczne ustawienie najnowszego modelu\n",
    "    if not config.model_path:\n",
    "        config.model_path = latest_model\n",
    "        print(f\"‚úÖ Automatycznie wybrano najnowszy model: {config.model_path}\")\n",
    "else:\n",
    "    print(\"‚ùå Nie znaleziono ≈ºadnych modeli ensemble!\")\n",
    "    print(\"   Sprawd≈∫ czy folder ensemble_outputs/ zawiera wytrenowane modele.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ PROBLEM ZOSTA≈Å ROZWIƒÑZANY!\n",
    "\n",
    "B≈ÇƒÖd z ≈Çadowaniem modelu w PyTorch 2.7+ zosta≈Ç naprawiony poprzez implementacjƒô wielopoziomowej strategii ≈Çadowania:\n",
    "1. Najpierw pr√≥ba bezpiecznego ≈Çadowania (`weights_only=True`)\n",
    "2. Nastƒôpnie z dodanym `torch.version.TorchVersion` do safe_globals\n",
    "3. W ko≈Ñcu fallback do `weights_only=False` dla w≈Çasnych zaufanych modeli\n",
    "\n",
    "## üöÄ Eksport modelu do ONNX\n",
    "\n",
    "Wykonajmy eksport z wykorzystaniem nowoczesnego eksportera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Rozpoczynam eksport modelu ensemble do ONNX\n",
      "============================================================\n",
      "\n",
      "üì• Etap 1: ≈Åadowanie modelu ensemble...\n",
      "üì• ≈Åadowanie modelu: ensemble_outputs\\ensemble_run_20250523_193302\\models\\ensemble_model.pt\n",
      "‚ö†Ô∏è U≈ºywam fallback ≈Çadowania (weights_only=False)\n",
      "   B≈ÇƒÖd bezpiecznego ≈Çadowania: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those...\n",
      "‚úÖ Model za≈Çadowany z 5 typami cech: ['melspectrogram', 'mfcc', 'hpss', 'chroma', 'tempogram']\n",
      "‚úÖ Model za≈Çadowany pomy≈õlnie!\n",
      "   Typy cech: ['melspectrogram', 'mfcc', 'hpss', 'chroma', 'tempogram']\n",
      "   Liczba parametr√≥w: 55,866,596\n",
      "\n",
      "üì¶ Etap 2: Eksport do ONNX...\n",
      "\n",
      "üöÄ Rozpoczynam eksport do ONNX...\n",
      "üìä Wymiary wej≈õcia: torch.Size([1, 1, 692, 130])\n",
      "üìã Informacje o cechach: {'melspectrogram': 128, 'mfcc': 40, 'hpss': 128, 'chroma': 12, 'tempogram': 384}\n",
      "üî¢ Ca≈Çkowity rozmiar cech: 692\n",
      "üîç Test forward pass...\n",
      "‚úÖ Test uko≈Ñczony. Wymiary wyj≈õcia: torch.Size([1, 6])\n",
      "üì¶ Eksport do ONNX...\n",
      "‚úÖ Eksport uko≈Ñczony: exported_models\\onnx_20250523_220917\\ensemble_model.onnx\n",
      "üîç Weryfikacja modelu ONNX...\n",
      "‚úÖ Weryfikacja zako≈Ñczona. Max r√≥≈ºnica: 0.000000\n",
      "‚ö° Optymalizacja modelu ONNX...\n",
      "‚ö†Ô∏è Optymalizacja nieudana: cannot import name 'optimizer' from 'onnx' (c:\\Users\\kubas\\Desktop\\Projekt dyplomowy\\Audio-Emotion-Recognition\\.venv\\lib\\site-packages\\onnx\\__init__.py)\n",
      "üìã Metadane zapisane: exported_models\\onnx_20250523_220917\\export_metadata.json\n",
      "\n",
      "üéâ Eksport zako≈Ñczony sukcesem!\n",
      "   üìÅ Katalog wyj≈õciowy: exported_models/onnx_20250523_220917\n",
      "   üì¶ Podstawowy model: 213.09 MB\n",
      "   ‚ö° Zoptymalizowany model: 213.09 MB\n"
     ]
    }
   ],
   "source": [
    "# Tworzenie eksportera\n",
    "exporter = ModernONNXExporter(config)\n",
    "\n",
    "print(\"üéØ Rozpoczynam eksport modelu ensemble do ONNX\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ≈Åadowanie modelu\n",
    "    print(\"\\nüì• Etap 1: ≈Åadowanie modelu ensemble...\")\n",
    "    model, feature_types = exporter.load_ensemble_model()\n",
    "    \n",
    "    print(f\"‚úÖ Model za≈Çadowany pomy≈õlnie!\")\n",
    "    print(f\"   Typy cech: {feature_types}\")\n",
    "    print(f\"   Liczba parametr√≥w: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Eksport do ONNX\n",
    "    print(\"\\nüì¶ Etap 2: Eksport do ONNX...\")\n",
    "    result = exporter.export_to_onnx(model, feature_types)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        print(\"\\nüéâ Eksport zako≈Ñczony sukcesem!\")\n",
    "        print(f\"   üìÅ Katalog wyj≈õciowy: {config.output_dir}\")\n",
    "        print(f\"   üì¶ Podstawowy model: {result['size_mb']:.2f} MB\")\n",
    "        \n",
    "        if \"optimized_path\" in result:\n",
    "            opt_size = Path(result[\"optimized_path\"]).stat().st_size / (1024 * 1024)\n",
    "            print(f\"   ‚ö° Zoptymalizowany model: {opt_size:.2f} MB\")\n",
    "        \n",
    "        if \"quantized_path\" in result:\n",
    "            quant_size = Path(result[\"quantized_path\"]).stat().st_size / (1024 * 1024)\n",
    "            print(f\"   üî¢ Skwantyzowany model: {quant_size:.2f} MB\")\n",
    "            \n",
    "        export_result = result  # Zapisz wynik dla dalszych analiz\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Eksport nieudany: {result['error']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nüí• Krytyczny b≈ÇƒÖd: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Analiza wyeksportowanych modeli\n",
    "\n",
    "Sprawd≈∫my szczeg√≥≈Çy wyeksportowanych modeli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Analiza wyeksportowanych modeli:\n",
      "========================================\n",
      "\n",
      "üìÅ Zawarto≈õƒá katalogu: exported_models\\onnx_20250523_220917\n",
      "   üìÑ ensemble_model.onnx: 213.09 MB\n",
      "   üìÑ export_metadata.json: 0.00 MB\n",
      "\n",
      "üîç Analiza modelu ONNX: ensemble_model.onnx\n",
      "   Wersja ONNX: 9\n",
      "   Opset version: 19\n",
      "   Liczba wƒôz≈Ç√≥w: 292\n",
      "   Liczba inicjalizator√≥w: 216\n",
      "\n",
      "   üì• Wej≈õcia:\n",
      "      audio_features: ['dynamic(batch_size)', 1, 692, 'dynamic(time_steps)']\n",
      "\n",
      "   üì§ Wyj≈õcia:\n",
      "      output: ['dynamic(batch_size)', 6]\n"
     ]
    }
   ],
   "source": [
    "if 'export_result' in locals() and export_result[\"success\"]:\n",
    "    print(\"üìä Analiza wyeksportowanych modeli:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Lista wszystkich wyeksportowanych plik√≥w\n",
    "    output_dir = Path(config.output_dir)\n",
    "    \n",
    "    print(f\"\\nüìÅ Zawarto≈õƒá katalogu: {output_dir}\")\n",
    "    for file_path in sorted(output_dir.iterdir()):\n",
    "        if file_path.is_file():\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"   üìÑ {file_path.name}: {size_mb:.2f} MB\")\n",
    "    \n",
    "    # Analiza podstawowego modelu ONNX\n",
    "    main_model_path = output_dir / \"ensemble_model.onnx\"\n",
    "    if main_model_path.exists():\n",
    "        print(f\"\\nüîç Analiza modelu ONNX: {main_model_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            model_onnx = onnx.load(str(main_model_path))\n",
    "            \n",
    "            print(f\"   Wersja ONNX: {model_onnx.ir_version}\")\n",
    "            print(f\"   Opset version: {model_onnx.opset_import[0].version}\")\n",
    "            print(f\"   Liczba wƒôz≈Ç√≥w: {len(model_onnx.graph.node)}\")\n",
    "            print(f\"   Liczba inicjalizator√≥w: {len(model_onnx.graph.initializer)}\")\n",
    "            \n",
    "            # Informacje o wej≈õciach/wyj≈õciach\n",
    "            print(f\"\\n   üì• Wej≈õcia:\")\n",
    "            for input_info in model_onnx.graph.input:\n",
    "                name = input_info.name\n",
    "                shape = [dim.dim_value if dim.dim_value > 0 else f\"dynamic({dim.dim_param})\" \n",
    "                        for dim in input_info.type.tensor_type.shape.dim]\n",
    "                print(f\"      {name}: {shape}\")\n",
    "            \n",
    "            print(f\"\\n   üì§ Wyj≈õcia:\")\n",
    "            for output_info in model_onnx.graph.output:\n",
    "                name = output_info.name\n",
    "                shape = [dim.dim_value if dim.dim_value > 0 else f\"dynamic({dim.dim_param})\" \n",
    "                        for dim in output_info.type.tensor_type.shape.dim]\n",
    "                print(f\"      {name}: {shape}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå B≈ÇƒÖd analizy modelu: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Brak wyeksportowanych modeli do analizy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test inference modelu ONNX\n",
    "\n",
    "Sprawd≈∫my czy model ONNX dzia≈Ça poprawnie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Test inference modelu ONNX\n",
      "==============================\n",
      "üì¶ U≈ºywam zoptymalizowanego modelu\n",
      "   Model: ensemble_model.onnx\n",
      "‚úÖ Sesja ONNX Runtime utworzona\n",
      "   Provider: ['CPUExecutionProvider']\n",
      "\n",
      "üìä Generowanie testowych danych...\n",
      "üìä Wymiary wej≈õcia: torch.Size([1, 1, 692, 130])\n",
      "üìã Informacje o cechach: {'melspectrogram': 128, 'mfcc': 40, 'hpss': 128, 'chroma': 12, 'tempogram': 384}\n",
      "üî¢ Ca≈Çkowity rozmiar cech: 692\n",
      "üöÄ Test inference...\n",
      "‚úÖ Inference uko≈Ñczony w 31.16 ms\n",
      "   Wymiary wyj≈õcia: (1, 6)\n",
      "   Przewidywane klasy: [0]\n",
      "   Najwy≈ºsze prawdopodobie≈Ñstwo: 0.5327\n",
      "\n",
      "üîÑ Test z batch size = 4...\n",
      "‚úÖ Batch inference uko≈Ñczony w 129.94 ms\n",
      "   Wymiary wyj≈õcia: (4, 6)\n",
      "   Czas na pr√≥bkƒô: 32.48 ms\n"
     ]
    }
   ],
   "source": [
    "if 'export_result' in locals() and export_result[\"success\"]:\n",
    "    print(\"üß™ Test inference modelu ONNX\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    try:\n",
    "        # ≈öcie≈ºka do modelu (preferuj zoptymalizowany je≈õli istnieje)\n",
    "        if \"optimized_path\" in export_result:\n",
    "            test_model_path = export_result[\"optimized_path\"]\n",
    "            print(f\"üì¶ U≈ºywam zoptymalizowanego modelu\")\n",
    "        else:\n",
    "            test_model_path = export_result[\"path\"]\n",
    "            print(f\"üì¶ U≈ºywam podstawowego modelu\")\n",
    "        \n",
    "        print(f\"   Model: {Path(test_model_path).name}\")\n",
    "        \n",
    "        # Tworzenie sesji ONNX Runtime\n",
    "        session = ort.InferenceSession(\n",
    "            test_model_path,\n",
    "            providers=['CPUExecutionProvider']\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Sesja ONNX Runtime utworzona\")\n",
    "        print(f\"   Provider: {session.get_providers()}\")\n",
    "        \n",
    "        # Generowanie testowych danych\n",
    "        print(f\"\\nüìä Generowanie testowych danych...\")\n",
    "        test_input = exporter.generate_dummy_input(export_result['feature_types'])\n",
    "        \n",
    "        # Test inference\n",
    "        print(f\"üöÄ Test inference...\")\n",
    "        import time\n",
    "        \n",
    "        start_time = time.time()\n",
    "        onnx_output = session.run(\n",
    "            None,  # Wszystkie wyj≈õcia\n",
    "            {'audio_features': test_input.numpy()}\n",
    "        )\n",
    "        inference_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"‚úÖ Inference uko≈Ñczony w {inference_time*1000:.2f} ms\")\n",
    "        print(f\"   Wymiary wyj≈õcia: {onnx_output[0].shape}\")\n",
    "        print(f\"   Przewidywane klasy: {onnx_output[0].argmax(axis=1)}\")\n",
    "        print(f\"   Najwy≈ºsze prawdopodobie≈Ñstwo: {onnx_output[0].max():.4f}\")\n",
    "        \n",
    "        # Test z wieloma batch'ami\n",
    "        print(f\"\\nüîÑ Test z batch size = 4...\")\n",
    "        batch_input = test_input.repeat(4, 1, 1, 1)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        batch_output = session.run(\n",
    "            None,\n",
    "            {'audio_features': batch_input.numpy()}\n",
    "        )\n",
    "        batch_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"‚úÖ Batch inference uko≈Ñczony w {batch_time*1000:.2f} ms\")\n",
    "        print(f\"   Wymiary wyj≈õcia: {batch_output[0].shape}\")\n",
    "        print(f\"   Czas na pr√≥bkƒô: {batch_time/4*1000:.2f} ms\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå B≈ÇƒÖd testu inference: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"‚ùå Brak wyeksportowanego modelu do testowania\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Podsumowanie eksportu\n",
    "\n",
    "Podsumujmy wyniki eksportu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã PODSUMOWANIE EKSPORTU\n",
      "========================================\n",
      "‚úÖ Status: SUKCES\n",
      "üìÅ Katalog wyj≈õciowy: exported_models/onnx_20250523_220917\n",
      "üîß Typy cech: melspectrogram, mfcc, hpss, chroma, tempogram\n",
      "üì¶ Rozmiar podstawowego modelu: 213.09 MB\n",
      "\n",
      "üõ†Ô∏è Zastosowane optymalizacje:\n",
      "   ‚ö° Optymalizacja grafu: True\n",
      "   üî¢ Kwantyzacja: False\n",
      "   üîç Weryfikacja: True\n",
      "\n",
      "üìä Dostƒôpne pliki:\n",
      "   üìÑ ensemble_model.onnx: 213.09 MB\n",
      "   üìÑ export_metadata.json: 0.00 MB\n",
      "\n",
      "üéØ Model gotowy do wdro≈ºenia!\n",
      "   G≈Ç√≥wny model: ensemble_model.onnx\n",
      "   Zalecany do u≈ºycia: ensemble_model.onnx\n"
     ]
    }
   ],
   "source": [
    "if 'export_result' in locals() and export_result[\"success\"]:\n",
    "    print(\"üìã PODSUMOWANIE EKSPORTU\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    print(f\"‚úÖ Status: SUKCES\")\n",
    "    print(f\"üìÅ Katalog wyj≈õciowy: {config.output_dir}\")\n",
    "    print(f\"üîß Typy cech: {', '.join(export_result['feature_types'])}\")\n",
    "    print(f\"üì¶ Rozmiar podstawowego modelu: {export_result['size_mb']:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nüõ†Ô∏è Zastosowane optymalizacje:\")\n",
    "    print(f\"   ‚ö° Optymalizacja grafu: {config.enable_optimization}\")\n",
    "    print(f\"   üî¢ Kwantyzacja: {config.enable_quantization}\")\n",
    "    if config.enable_quantization:\n",
    "        print(f\"   üìè Typ kwantyzacji: {config.quantization_type}\")\n",
    "    print(f\"   üîç Weryfikacja: {config.verify_model}\")\n",
    "    \n",
    "    print(f\"\\nüìä Dostƒôpne pliki:\")\n",
    "    output_dir = Path(config.output_dir)\n",
    "    for file_path in sorted(output_dir.iterdir()):\n",
    "        if file_path.suffix in ['.onnx', '.json']:\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"   üìÑ {file_path.name}: {size_mb:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nüéØ Model gotowy do wdro≈ºenia!\")\n",
    "    print(f\"   G≈Ç√≥wny model: {Path(export_result['path']).name}\")\n",
    "    if \"optimized_path\" in export_result:\n",
    "        print(f\"   Zalecany do u≈ºycia: {Path(export_result['optimized_path']).name}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå EKSPORT NIEUDANY\")\n",
    "    print(\"   Sprawd≈∫ komunikaty b≈Çƒôd√≥w powy≈ºej\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Nastƒôpne kroki\n",
    "\n",
    "Po udanym eksporcie mo≈ºesz:\n",
    "\n",
    "1. **Wdro≈ºenie modelu**: U≈ºyj wyeksportowanego modelu ONNX w swojej aplikacji\n",
    "2. **Optymalizacja dalszej**: Przetestuj r√≥≈ºne konfiguracje optymalizacji\n",
    "3. **Kwantyzacja**: Je≈õli nie w≈ÇƒÖcza≈Çe≈õ kwantyzacji, rozwa≈º jej u≈ºycie dla zmniejszenia rozmiaru\n",
    "4. **Testy wydajno≈õci**: Zmierz wydajno≈õƒá na docelowym ≈õrodowisku\n",
    "5. **Integracja**: U≈ºyj modelu z bibliotekami takimi jak ONNX Runtime, OpenVINO, lub TensorRT\n",
    "\n",
    "### Przyk≈Çad u≈ºycia w produkcji:\n",
    "\n",
    "```python\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# ≈Åadowanie modelu\n",
    "session = ort.InferenceSession('ensemble_model_optimized.onnx')\n",
    "\n",
    "# Przygotowanie danych audio (zastƒÖp swojƒÖ logikƒÖ)\n",
    "audio_features = extract_features_from_audio(audio_file)\n",
    "\n",
    "# Inference\n",
    "predictions = session.run(None, {'audio_features': audio_features})\n",
    "predicted_emotion = np.argmax(predictions[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Nowoczesny eksport modelu ensemble do ONNX\n",
    "\n",
    "Ten notebook implementuje najlepsze praktyki eksportu do ONNX zgodne z PyTorch 2.7+ i najnowszymi standardami ONNX.\n",
    "\n",
    "## Funkcje:\n",
    "- ‚úÖ Bezpieczne ≈Çadowanie modeli\n",
    "- ‚úÖ Optymalizacja modeli ONNX\n",
    "- ‚úÖ Kwantyzacja (dynamiczna i statyczna)\n",
    "- ‚úÖ Weryfikacja zgodno≈õci\n",
    "- ‚úÖ Eksport metadanych\n",
    "- ‚úÖ Jednolite wej≈õcie tensorowe\n",
    "- ‚úÖ Obs≈Çuga dynamicznych rozmiar√≥w\n",
    "- ‚úÖ Obs≈Çuga 5 typ√≥w cech: chroma, tempogram, mfcc, melspectrogram, hpss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Wersje bibliotek:\n",
      "   PyTorch: 2.7.0+cpu\n",
      "   ONNX: 1.18.0\n",
      "   ONNX Runtime: 1.19.2\n",
      "   Python: 3.9.13\n"
     ]
    }
   ],
   "source": [
    "# Importy i konfiguracja\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Dodanie ≈õcie≈ºki do modu≈Ç√≥w\n",
    "sys.path.append(os.path.join(os.getcwd()))\n",
    "\n",
    "from export_scripts.modern_onnx_exporter import ModernONNXExporter, ExportConfig\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "print(f\"üîß Wersje bibliotek:\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   ONNX: {onnx.__version__}\")\n",
    "print(f\"   ONNX Runtime: {ort.__version__}\")\n",
    "print(f\"   Python: {sys.version.split()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Konfiguracja eksportu\n",
    "\n",
    "Ustaw parametry eksportu zgodnie z Twoimi potrzebami:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Konfiguracja eksportu:\n",
      "   Opset version: 19\n",
      "   Optymalizacja: True\n",
      "   Kwantyzacja: False\n",
      "   Typ kwantyzacji: dynamic\n",
      "   Weryfikacja: True\n"
     ]
    }
   ],
   "source": [
    "# Konfiguracja eksportu - dostosuj wed≈Çug potrzeb\n",
    "config = ExportConfig(\n",
    "    model_path=None,  # None = automatyczne wykrycie najnowszego modelu\n",
    "    output_dir=None,  # None = automatyczne tworzenie katalogu z timestamp\n",
    "    \n",
    "    # Parametry audio\n",
    "    sample_rate=22050,\n",
    "    max_length=3.0,  # sekundy\n",
    "    \n",
    "    # Parametry ONNX\n",
    "    opset_version=19,  # Najnowsza stabilna wersja\n",
    "    \n",
    "    # Optymalizacje\n",
    "    enable_optimization=True,     # W≈ÇƒÖcz optymalizacjƒô grafu ONNX\n",
    "    enable_quantization=False,    # W≈ÇƒÖcz kwantyzacjƒô (zmniejsza rozmiar)\n",
    "    quantization_type=\"dynamic\",  # \"dynamic\" lub \"static\"\n",
    "    \n",
    "    # Dodatkowe opcje\n",
    "    fp16_conversion=False,        # Konwersja do po≈Ç√≥wkowej precyzji\n",
    "    verify_model=True,            # Weryfikacja zgodno≈õci modeli\n",
    "    export_metadata=True          # Eksport metadanych\n",
    ")\n",
    "\n",
    "print(\"üìã Konfiguracja eksportu:\")\n",
    "print(f\"   Opset version: {config.opset_version}\")\n",
    "print(f\"   Optymalizacja: {config.enable_optimization}\")\n",
    "print(f\"   Kwantyzacja: {config.enable_quantization}\")\n",
    "print(f\"   Typ kwantyzacji: {config.quantization_type}\")\n",
    "print(f\"   Weryfikacja: {config.verify_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Wyszukiwanie dostƒôpnych modeli\n",
    "\n",
    "Sprawd≈∫my jakie modele ensemble sƒÖ dostƒôpne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Znaleziono 1 modeli ensemble:\n",
      "   1. ensemble_outputs\\ensemble_run_20250523_193302\\models\\ensemble_model.pt\n",
      "      Timestamp: 20250523_193302\\models\\ensemble_model.pt\n",
      "      Rozmiar: 213.51 MB\n",
      "      ‚≠ê Najnowszy model\n",
      "\n",
      "‚úÖ Automatycznie wybrano najnowszy model: ensemble_outputs\\ensemble_run_20250523_193302\\models\\ensemble_model.pt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# Wyszukiwanie modeli ensemble\n",
    "ensemble_models = glob.glob(\"ensemble_outputs/ensemble_run_*/models/ensemble_model.pt\")\n",
    "\n",
    "if ensemble_models:\n",
    "    print(f\"üîç Znaleziono {len(ensemble_models)} modeli ensemble:\")\n",
    "    \n",
    "    for i, model_path in enumerate(sorted(ensemble_models, reverse=True)):\n",
    "        # Ekstraktowanie timestamp z nazwy katalogu\n",
    "        timestamp_str = model_path.split('ensemble_run_')[1].split('/')[0]\n",
    "        \n",
    "        # Rozmiar pliku\n",
    "        size_mb = os.path.getsize(model_path) / (1024 * 1024)\n",
    "        \n",
    "        print(f\"   {i+1}. {model_path}\")\n",
    "        print(f\"      Timestamp: {timestamp_str}\")\n",
    "        print(f\"      Rozmiar: {size_mb:.2f} MB\")\n",
    "        \n",
    "        if i == 0:\n",
    "            latest_model = model_path\n",
    "            print(f\"      ‚≠ê Najnowszy model\")\n",
    "        print()\n",
    "    \n",
    "    # Automatyczne ustawienie najnowszego modelu\n",
    "    if not config.model_path:\n",
    "        config.model_path = latest_model\n",
    "        print(f\"‚úÖ Automatycznie wybrano najnowszy model: {config.model_path}\")\n",
    "else:\n",
    "    print(\"‚ùå Nie znaleziono ≈ºadnych modeli ensemble!\")\n",
    "    print(\"   Sprawd≈∫ czy folder ensemble_outputs/ zawiera wytrenowane modele.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Eksport modelu do ONNX\n",
    "\n",
    "Wykonajmy eksport z wykorzystaniem nowoczesnego eksportera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Rozpoczynam eksport modelu ensemble do ONNX\n",
      "============================================================\n",
      "\n",
      "üì• Etap 1: ≈Åadowanie modelu ensemble...\n",
      "üì• ≈Åadowanie modelu: ensemble_outputs\\ensemble_run_20250523_193302\\models\\ensemble_model.pt\n",
      "‚ö†Ô∏è U≈ºywam fallback ≈Çadowania (weights_only=False)\n",
      "   B≈ÇƒÖd bezpiecznego ≈Çadowania: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those...\n",
      "‚úÖ Model za≈Çadowany z 5 typami cech: ['melspectrogram', 'mfcc', 'hpss', 'chroma', 'tempogram']\n",
      "‚úÖ Model za≈Çadowany pomy≈õlnie!\n",
      "   Typy cech: ['melspectrogram', 'mfcc', 'hpss', 'chroma', 'tempogram']\n",
      "   Liczba parametr√≥w: 55,866,596\n",
      "\n",
      "üì¶ Etap 2: Eksport do ONNX...\n",
      "\n",
      "üöÄ Rozpoczynam eksport do ONNX...\n",
      "üìä Wymiary wej≈õcia: torch.Size([1, 1, 692, 130])\n",
      "üìã Informacje o cechach: {'melspectrogram': 128, 'mfcc': 40, 'hpss': 128, 'chroma': 12, 'tempogram': 384}\n",
      "üî¢ Ca≈Çkowity rozmiar cech: 692\n",
      "üîç Test forward pass...\n",
      "‚úÖ Test uko≈Ñczony. Wymiary wyj≈õcia: torch.Size([1, 6])\n",
      "üì¶ Eksport do ONNX...\n",
      "‚úÖ Eksport uko≈Ñczony: exported_models\\onnx_20250523_220923\\ensemble_model.onnx\n",
      "üîç Weryfikacja modelu ONNX...\n",
      "‚úÖ Weryfikacja zako≈Ñczona. Max r√≥≈ºnica: 0.000000\n",
      "‚ö° Optymalizacja modelu ONNX...\n",
      "‚ö†Ô∏è Optymalizacja nieudana: cannot import name 'optimizer' from 'onnx' (c:\\Users\\kubas\\Desktop\\Projekt dyplomowy\\Audio-Emotion-Recognition\\.venv\\lib\\site-packages\\onnx\\__init__.py)\n",
      "üìã Metadane zapisane: exported_models\\onnx_20250523_220923\\export_metadata.json\n",
      "\n",
      "üéâ Eksport zako≈Ñczony sukcesem!\n",
      "   üìÅ Katalog wyj≈õciowy: exported_models/onnx_20250523_220923\n",
      "   üì¶ Podstawowy model: 213.09 MB\n",
      "   ‚ö° Zoptymalizowany model: 213.09 MB\n"
     ]
    }
   ],
   "source": [
    "# Tworzenie eksportera\n",
    "exporter = ModernONNXExporter(config)\n",
    "\n",
    "print(\"üéØ Rozpoczynam eksport modelu ensemble do ONNX\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # ≈Åadowanie modelu\n",
    "    print(\"\\nüì• Etap 1: ≈Åadowanie modelu ensemble...\")\n",
    "    model, feature_types = exporter.load_ensemble_model()\n",
    "    \n",
    "    print(f\"‚úÖ Model za≈Çadowany pomy≈õlnie!\")\n",
    "    print(f\"   Typy cech: {feature_types}\")\n",
    "    print(f\"   Liczba parametr√≥w: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Eksport do ONNX\n",
    "    print(\"\\nüì¶ Etap 2: Eksport do ONNX...\")\n",
    "    result = exporter.export_to_onnx(model, feature_types)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        print(\"\\nüéâ Eksport zako≈Ñczony sukcesem!\")\n",
    "        print(f\"   üìÅ Katalog wyj≈õciowy: {config.output_dir}\")\n",
    "        print(f\"   üì¶ Podstawowy model: {result['size_mb']:.2f} MB\")\n",
    "        \n",
    "        if \"optimized_path\" in result:\n",
    "            opt_size = Path(result[\"optimized_path\"]).stat().st_size / (1024 * 1024)\n",
    "            print(f\"   ‚ö° Zoptymalizowany model: {opt_size:.2f} MB\")\n",
    "        \n",
    "        if \"quantized_path\" in result:\n",
    "            quant_size = Path(result[\"quantized_path\"]).stat().st_size / (1024 * 1024)\n",
    "            print(f\"   üî¢ Skwantyzowany model: {quant_size:.2f} MB\")\n",
    "            \n",
    "        export_result = result  # Zapisz wynik dla dalszych analiz\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Eksport nieudany: {result['error']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nüí• Krytyczny b≈ÇƒÖd: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Analiza wyeksportowanych modeli\n",
    "\n",
    "Sprawd≈∫my szczeg√≥≈Çy wyeksportowanych modeli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Analiza wyeksportowanych modeli:\n",
      "========================================\n",
      "\n",
      "üìÅ Zawarto≈õƒá katalogu: exported_models\\onnx_20250523_220923\n",
      "   üìÑ ensemble_model.onnx: 213.09 MB\n",
      "   üìÑ export_metadata.json: 0.00 MB\n",
      "\n",
      "üîç Analiza modelu ONNX: ensemble_model.onnx\n",
      "   Wersja ONNX: 9\n",
      "   Opset version: 19\n",
      "   Liczba wƒôz≈Ç√≥w: 292\n",
      "   Liczba inicjalizator√≥w: 216\n",
      "\n",
      "   üì• Wej≈õcia:\n",
      "      audio_features: ['dynamic(batch_size)', 1, 692, 'dynamic(time_steps)']\n",
      "\n",
      "   üì§ Wyj≈õcia:\n",
      "      output: ['dynamic(batch_size)', 6]\n"
     ]
    }
   ],
   "source": [
    "if 'export_result' in locals() and export_result[\"success\"]:\n",
    "    print(\"üìä Analiza wyeksportowanych modeli:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Lista wszystkich wyeksportowanych plik√≥w\n",
    "    output_dir = Path(config.output_dir)\n",
    "    \n",
    "    print(f\"\\nüìÅ Zawarto≈õƒá katalogu: {output_dir}\")\n",
    "    for file_path in sorted(output_dir.iterdir()):\n",
    "        if file_path.is_file():\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"   üìÑ {file_path.name}: {size_mb:.2f} MB\")\n",
    "    \n",
    "    # Analiza podstawowego modelu ONNX\n",
    "    main_model_path = output_dir / \"ensemble_model.onnx\"\n",
    "    if main_model_path.exists():\n",
    "        print(f\"\\nüîç Analiza modelu ONNX: {main_model_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            model_onnx = onnx.load(str(main_model_path))\n",
    "            \n",
    "            print(f\"   Wersja ONNX: {model_onnx.ir_version}\")\n",
    "            print(f\"   Opset version: {model_onnx.opset_import[0].version}\")\n",
    "            print(f\"   Liczba wƒôz≈Ç√≥w: {len(model_onnx.graph.node)}\")\n",
    "            print(f\"   Liczba inicjalizator√≥w: {len(model_onnx.graph.initializer)}\")\n",
    "            \n",
    "            # Informacje o wej≈õciach/wyj≈õciach\n",
    "            print(f\"\\n   üì• Wej≈õcia:\")\n",
    "            for input_info in model_onnx.graph.input:\n",
    "                name = input_info.name\n",
    "                shape = [dim.dim_value if dim.dim_value > 0 else f\"dynamic({dim.dim_param})\" \n",
    "                        for dim in input_info.type.tensor_type.shape.dim]\n",
    "                print(f\"      {name}: {shape}\")\n",
    "            \n",
    "            print(f\"\\n   üì§ Wyj≈õcia:\")\n",
    "            for output_info in model_onnx.graph.output:\n",
    "                name = output_info.name\n",
    "                shape = [dim.dim_value if dim.dim_value > 0 else f\"dynamic({dim.dim_param})\" \n",
    "                        for dim in output_info.type.tensor_type.shape.dim]\n",
    "                print(f\"      {name}: {shape}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå B≈ÇƒÖd analizy modelu: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Brak wyeksportowanych modeli do analizy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test inference modelu ONNX\n",
    "\n",
    "Sprawd≈∫my czy model ONNX dzia≈Ça poprawnie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Test inference modelu ONNX\n",
      "==============================\n",
      "üì¶ U≈ºywam zoptymalizowanego modelu\n",
      "   Model: ensemble_model.onnx\n",
      "‚úÖ Sesja ONNX Runtime utworzona\n",
      "   Provider: ['CPUExecutionProvider']\n",
      "\n",
      "üìä Generowanie testowych danych...\n",
      "üìä Wymiary wej≈õcia: torch.Size([1, 1, 692, 130])\n",
      "üìã Informacje o cechach: {'melspectrogram': 128, 'mfcc': 40, 'hpss': 128, 'chroma': 12, 'tempogram': 384}\n",
      "üî¢ Ca≈Çkowity rozmiar cech: 692\n",
      "üöÄ Test inference...\n",
      "‚úÖ Inference uko≈Ñczony w 24.72 ms\n",
      "   Wymiary wyj≈õcia: (1, 6)\n",
      "   Przewidywane klasy: [0]\n",
      "   Najwy≈ºsze prawdopodobie≈Ñstwo: 0.5120\n",
      "\n",
      "üîÑ Test z batch size = 4...\n",
      "‚úÖ Batch inference uko≈Ñczony w 111.85 ms\n",
      "   Wymiary wyj≈õcia: (4, 6)\n",
      "   Czas na pr√≥bkƒô: 27.96 ms\n"
     ]
    }
   ],
   "source": [
    "if 'export_result' in locals() and export_result[\"success\"]:\n",
    "    print(\"üß™ Test inference modelu ONNX\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    try:\n",
    "        # ≈öcie≈ºka do modelu (preferuj zoptymalizowany je≈õli istnieje)\n",
    "        if \"optimized_path\" in export_result:\n",
    "            test_model_path = export_result[\"optimized_path\"]\n",
    "            print(f\"üì¶ U≈ºywam zoptymalizowanego modelu\")\n",
    "        else:\n",
    "            test_model_path = export_result[\"path\"]\n",
    "            print(f\"üì¶ U≈ºywam podstawowego modelu\")\n",
    "        \n",
    "        print(f\"   Model: {Path(test_model_path).name}\")\n",
    "        \n",
    "        # Tworzenie sesji ONNX Runtime\n",
    "        session = ort.InferenceSession(\n",
    "            test_model_path,\n",
    "            providers=['CPUExecutionProvider']\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Sesja ONNX Runtime utworzona\")\n",
    "        print(f\"   Provider: {session.get_providers()}\")\n",
    "        \n",
    "        # Generowanie testowych danych\n",
    "        print(f\"\\nüìä Generowanie testowych danych...\")\n",
    "        test_input = exporter.generate_dummy_input(export_result['feature_types'])\n",
    "        \n",
    "        # Test inference\n",
    "        print(f\"üöÄ Test inference...\")\n",
    "        import time\n",
    "        \n",
    "        start_time = time.time()\n",
    "        onnx_output = session.run(\n",
    "            None,  # Wszystkie wyj≈õcia\n",
    "            {'audio_features': test_input.numpy()}\n",
    "        )\n",
    "        inference_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"‚úÖ Inference uko≈Ñczony w {inference_time*1000:.2f} ms\")\n",
    "        print(f\"   Wymiary wyj≈õcia: {onnx_output[0].shape}\")\n",
    "        print(f\"   Przewidywane klasy: {onnx_output[0].argmax(axis=1)}\")\n",
    "        print(f\"   Najwy≈ºsze prawdopodobie≈Ñstwo: {onnx_output[0].max():.4f}\")\n",
    "        \n",
    "        # Test z wieloma batch'ami\n",
    "        print(f\"\\nüîÑ Test z batch size = 4...\")\n",
    "        batch_input = test_input.repeat(4, 1, 1, 1)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        batch_output = session.run(\n",
    "            None,\n",
    "            {'audio_features': batch_input.numpy()}\n",
    "        )\n",
    "        batch_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"‚úÖ Batch inference uko≈Ñczony w {batch_time*1000:.2f} ms\")\n",
    "        print(f\"   Wymiary wyj≈õcia: {batch_output[0].shape}\")\n",
    "        print(f\"   Czas na pr√≥bkƒô: {batch_time/4*1000:.2f} ms\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå B≈ÇƒÖd testu inference: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"‚ùå Brak wyeksportowanego modelu do testowania\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Podsumowanie eksportu\n",
    "\n",
    "Podsumujmy wyniki eksportu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã PODSUMOWANIE EKSPORTU\n",
      "========================================\n",
      "‚úÖ Status: SUKCES\n",
      "üìÅ Katalog wyj≈õciowy: exported_models/onnx_20250523_220923\n",
      "üîß Typy cech: melspectrogram, mfcc, hpss, chroma, tempogram\n",
      "üì¶ Rozmiar podstawowego modelu: 213.09 MB\n",
      "\n",
      "üõ†Ô∏è Zastosowane optymalizacje:\n",
      "   ‚ö° Optymalizacja grafu: True\n",
      "   üî¢ Kwantyzacja: False\n",
      "   üîç Weryfikacja: True\n",
      "\n",
      "üìä Dostƒôpne pliki:\n",
      "   üìÑ ensemble_model.onnx: 213.09 MB\n",
      "   üìÑ export_metadata.json: 0.00 MB\n",
      "\n",
      "üéØ Model gotowy do wdro≈ºenia!\n",
      "   G≈Ç√≥wny model: ensemble_model.onnx\n",
      "   Zalecany do u≈ºycia: ensemble_model.onnx\n"
     ]
    }
   ],
   "source": [
    "if 'export_result' in locals() and export_result[\"success\"]:\n",
    "    print(\"üìã PODSUMOWANIE EKSPORTU\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    print(f\"‚úÖ Status: SUKCES\")\n",
    "    print(f\"üìÅ Katalog wyj≈õciowy: {config.output_dir}\")\n",
    "    print(f\"üîß Typy cech: {', '.join(export_result['feature_types'])}\")\n",
    "    print(f\"üì¶ Rozmiar podstawowego modelu: {export_result['size_mb']:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nüõ†Ô∏è Zastosowane optymalizacje:\")\n",
    "    print(f\"   ‚ö° Optymalizacja grafu: {config.enable_optimization}\")\n",
    "    print(f\"   üî¢ Kwantyzacja: {config.enable_quantization}\")\n",
    "    if config.enable_quantization:\n",
    "        print(f\"   üìè Typ kwantyzacji: {config.quantization_type}\")\n",
    "    print(f\"   üîç Weryfikacja: {config.verify_model}\")\n",
    "    \n",
    "    print(f\"\\nüìä Dostƒôpne pliki:\")\n",
    "    output_dir = Path(config.output_dir)\n",
    "    for file_path in sorted(output_dir.iterdir()):\n",
    "        if file_path.suffix in ['.onnx', '.json']:\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"   üìÑ {file_path.name}: {size_mb:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nüéØ Model gotowy do wdro≈ºenia!\")\n",
    "    print(f\"   G≈Ç√≥wny model: {Path(export_result['path']).name}\")\n",
    "    if \"optimized_path\" in export_result:\n",
    "        print(f\"   Zalecany do u≈ºycia: {Path(export_result['optimized_path']).name}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå EKSPORT NIEUDANY\")\n",
    "    print(\"   Sprawd≈∫ komunikaty b≈Çƒôd√≥w powy≈ºej\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Nastƒôpne kroki\n",
    "\n",
    "Po udanym eksporcie mo≈ºesz:\n",
    "\n",
    "1. **Wdro≈ºenie modelu**: U≈ºyj wyeksportowanego modelu ONNX w swojej aplikacji\n",
    "2. **Optymalizacja dalszej**: Przetestuj r√≥≈ºne konfiguracje optymalizacji\n",
    "3. **Kwantyzacja**: Je≈õli nie w≈ÇƒÖcza≈Çe≈õ kwantyzacji, rozwa≈º jej u≈ºycie dla zmniejszenia rozmiaru\n",
    "4. **Testy wydajno≈õci**: Zmierz wydajno≈õƒá na docelowym ≈õrodowisku\n",
    "5. **Integracja**: U≈ºyj modelu z bibliotekami takimi jak ONNX Runtime, OpenVINO, lub TensorRT\n",
    "\n",
    "### Przyk≈Çad u≈ºycia w produkcji:\n",
    "\n",
    "```python\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# ≈Åadowanie modelu\n",
    "session = ort.InferenceSession('ensemble_model_optimized.onnx')\n",
    "\n",
    "# Przygotowanie danych audio (zastƒÖp swojƒÖ logikƒÖ)\n",
    "audio_features = extract_features_from_audio(audio_file)\n",
    "\n",
    "# Inference\n",
    "predictions = session.run(None, {'audio_features': audio_features})\n",
    "predicted_emotion = np.argmax(predictions[0])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Audio Emotion Recognition)",
   "language": "python",
   "name": "audio-emotion-recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
