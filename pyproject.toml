[project]
name = "Audio_emotion_Recognition"
version = "0.1.0"
description = ""
requires-python = "==3.9.21"
dependencies = [
    "datasets>=3.4.1",
    "librosa>=0.11.0",
    "soundfile>=0.13.1",
    "requests>=2.32.3",
    "ruff>=0.11.0",
    "torch>=2.6.0",
    "torchvision>=0.21.0",
    "torchaudio>=2.6.0",
    "matplotlib>=3.9.4",
    "seaborn>=0.13.2",
    "numpy==1.23.5",
    "ipython>=8.18.1",
    "pandas>=2.2.3",
    "ipykernel>=6.29.5",
]

[project.optional-dependencies]
# Zależności używane tylko do rozwoju (linting, testy itp.)
dev = [
    "ruff>=0.11.0",
]

# Zależności związane z przetwarzaniem audio
audio = [
    "librosa>=0.11.0",
    "soundfile>=0.13.1",
    "soxr>=0.5.0.post1",
]

# Zależności związane z przetwarzaniem danych
data = [
    "datasets>=3.4.1",
    "scikit-learn>=1.6.1",
    "scipy>=1.13.1",
]
