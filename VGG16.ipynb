{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Input\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Parametry dla spektrogramów Mela\n",
    "SAMPLE_RATE = 16000  # Częstotliwość próbkowania\n",
    "N_MELS = 128  # Liczba filtrów Mela\n",
    "N_FFT = 2048  # Długość okna FFT\n",
    "HOP_LENGTH = 512  # Długość przeskoku między ramkami\n",
    "DURATION = 3  # Maksymalna długość nagrania w sekundach\n",
    "\n",
    "# Parametry dla modelu\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "NUM_CLASSES = 6  # 6 emocji: złość, strach, szczęście, smutek, zaskoczenie, neutralny\n",
    "\n",
    "def load_nemo_dataset():\n",
    "    \"\"\"\n",
    "    Ładowanie datasetu nEMO z Hugging Face\n",
    "    \"\"\"\n",
    "    print(\"Ładowanie datasetu nEMO...\")\n",
    "    dataset = load_dataset(\"amu-cai/nEMO\")\n",
    "    return dataset\n",
    "\n",
    "def extract_melspectrogram(audio, sr=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Ekstrakcja spektrogramu Mela z sygnału audio\n",
    "    \"\"\"\n",
    "    # Przycinanie lub paddowanie do stałej długości\n",
    "    if len(audio) > sr * DURATION:\n",
    "        audio = audio[:sr * DURATION]\n",
    "    else:\n",
    "        audio = np.pad(audio, (0, max(0, sr * DURATION - len(audio))), 'constant')\n",
    "\n",
    "    # Generowanie spektrogramu Mela\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(\n",
    "        y=audio,\n",
    "        sr=sr,\n",
    "        n_mels=N_MELS,\n",
    "        n_fft=N_FFT,\n",
    "        hop_length=HOP_LENGTH\n",
    "    )\n",
    "\n",
    "    # Konwersja do decybeli i normalizacja \n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    mel_spectrogram = (mel_spectrogram - np.min(mel_spectrogram)) / (np.max(mel_spectrogram) - np.min(mel_spectrogram))\n",
    "    return mel_spectrogram\n",
    "\n",
    "def prepare_data(dataset):\n",
    "    \"\"\"\n",
    "    Przygotowanie danych: ekstrakcja spektrogramów Mela i etykiet\n",
    "    \"\"\"\n",
    "    print(\"Przygotowywanie danych...\")\n",
    "\n",
    "    # Mapowanie etykiet na indeksy\n",
    "    emotion_mapping = {\n",
    "        'anger': 0,        # złość\n",
    "        'fear': 1,         # strach\n",
    "        'happiness': 2,    # szczęście\n",
    "        'sadness': 3,      # smutek\n",
    "        'surprised': 4,     # zaskoczenie\n",
    "        'neutral': 5       # neutralny\n",
    "    }\n",
    "\n",
    "    # Listy na dane\n",
    "    mel_spectrograms = []\n",
    "    labels = []\n",
    "\n",
    "    # Przetwarzanie zestawu treningowego\n",
    "    for sample in dataset['train']:\n",
    "        audio = np.array(sample['audio']['array'])\n",
    "        emotion = sample['emotion']\n",
    "\n",
    "        if emotion in emotion_mapping:\n",
    "            mel_spec = extract_melspectrogram(audio)\n",
    "            mel_spectrograms.append(mel_spec)\n",
    "            labels.append(emotion_mapping[emotion])\n",
    "\n",
    "    # Konwersja do numpy arrays\n",
    "    X = np.array(mel_spectrograms)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    # Dostosowanie wymiarów dla VGG16 (wymaga 3 kanałów kolorów)\n",
    "    # Replikacja spektrogramu Mela na 3 kanały (RGB)\n",
    "    X = np.repeat(X[:, :, :, np.newaxis], 3, axis=3)\n",
    "\n",
    "    # Podział na zbiory treningowe i testowe\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def visualize_melspectrogram(mel_spectrogram, title):\n",
    "    \"\"\"\n",
    "    Wizualizacja spektrogramu Mela\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(\n",
    "        mel_spectrogram[0, :, :, 0],  # Wybieramy pierwszy kanał z 3 kanałów RGB\n",
    "        y_axis='mel',\n",
    "        x_axis='time',\n",
    "        sr=SAMPLE_RATE,\n",
    "        hop_length=HOP_LENGTH\n",
    "    )\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def build_vgg16_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Budowanie modelu z wykorzystaniem pre-trenowanego VGG16\n",
    "    \"\"\"\n",
    "    print(\"Budowanie modelu z wykorzystaniem pre-trenowanego VGG16...\")\n",
    "\n",
    "    # Ładowanie pre-trenowanego modelu VGG16 bez warstw w pełni połączonych\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Zamrożenie wag pre-trenowanego modelu\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Dodanie własnych warstw klasyfikacyjnych\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Stworzenie finalnego modelu\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Kompilacja modelu\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Trenowanie modelu VGG16\n",
    "    \"\"\"\n",
    "    print(\"Trenowanie modelu...\")\n",
    "\n",
    "    # Generowanie dodatkowych danych treningowych\n",
    "    datagen = ImageDataGenerator(\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6),\n",
    "        ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "    ]\n",
    "\n",
    "    # Trenowanie\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        steps_per_epoch=len(X_train) // BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# Definicja emotion_names \n",
    "emotion_names = ['Złość', 'Strach', 'Szczęście', 'Smutek', 'Zaskoczenie', 'Neutralny']\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Ewaluacja modelu na zbiorze testowym z normalizowaną macierzą pomyłek\n",
    "    \"\"\"\n",
    "    print(\"Ewaluacja modelu...\")\n",
    "\n",
    "    # Ewaluacja\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Test loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Predykcje\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Macierz pomyłek\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "    # Normalizacja macierzy pomyłek (wartości między 0 a 1)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Raport klasyfikacji\n",
    "    print(\"Raport klasyfikacji:\")\n",
    "    print(classification_report(y_test, y_pred_classes, target_names=emotion_names))\n",
    "\n",
    "    # Wizualizacja znormalizowanej macierzy pomyłek\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Znormalizowana macierz pomyłek')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(emotion_names))\n",
    "    plt.xticks(tick_marks, emotion_names, rotation=45)\n",
    "    plt.yticks(tick_marks, emotion_names)\n",
    "\n",
    "    # Dodanie wartości do macierzy pomyłek\n",
    "    thresh = cm_normalized.max() / 2.\n",
    "    for i in range(cm_normalized.shape[0]):\n",
    "        for j in range(cm_normalized.shape[1]):\n",
    "            plt.text(j, i, format(cm_normalized[i, j], '.2f'),  # Wyświetlamy do 2 miejsc po przecinku\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm_normalized[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Rzeczywista etykieta')\n",
    "    plt.xlabel('Przewidziana etykieta')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return test_acc, test_loss, cm_normalized\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Wizualizacja historii treningu\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Wykres dokładności\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Dokładność treningowa')\n",
    "    plt.plot(history.history['val_accuracy'], label='Dokładność walidacyjna')\n",
    "    plt.title('Dokładność modelu')\n",
    "    plt.ylabel('Dokładność')\n",
    "    plt.xlabel('Epoka')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    # Wykres funkcji kosztu\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Koszt treningowy')\n",
    "    plt.plot(history.history['val_loss'], label='Koszt walidacyjny')\n",
    "    plt.title('Funkcja kosztu modelu')\n",
    "    plt.ylabel('Koszt')\n",
    "    plt.xlabel('Epoka')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def save_model(model, history, filename='emotion_detection_model.h5'):\n",
    "    \"\"\"\n",
    "    Zapisywanie modelu i historii\n",
    "    \"\"\"\n",
    "    print(f\"Zapisywanie modelu do pliku {filename}...\")\n",
    "    model.save(filename)\n",
    "\n",
    "    # Zapisywanie historii\n",
    "    history_dict = {\n",
    "        'accuracy': history.history['accuracy'],\n",
    "        'val_accuracy': history.history['val_accuracy'],\n",
    "        'loss': history.history['loss'],\n",
    "        'val_loss': history.history['val_loss']\n",
    "    }\n",
    "\n",
    "    np.save('training_history.npy', history_dict)\n",
    "    print(\"Model i historia zapisane pomyślnie.\")\n",
    "\n",
    "def predict_emotion(model, audio_path):\n",
    "    \"\"\"\n",
    "    Predykcja emocji dla nowego pliku audio\n",
    "    \"\"\"\n",
    "    \n",
    "    # Wczytanie audio\n",
    "    audio, sr = librosa.load(audio_path, sr=SAMPLE_RATE)\n",
    "\n",
    "    # Ekstrakcja spektrogramu Mela\n",
    "    mel_spec = extract_melspectrogram(audio)\n",
    "\n",
    "    # Przygotowanie do predykcji - replikacja na 3 kanały dla VGG16\n",
    "    mel_spec = np.repeat(mel_spec[:, :, np.newaxis], 3, axis=2)\n",
    "    mel_spec = mel_spec.reshape(1, N_MELS, mel_spec.shape[1], 3)\n",
    "\n",
    "    # Predykcja\n",
    "    prediction = model.predict(mel_spec)\n",
    "    predicted_class = np.argmax(prediction[0])\n",
    "\n",
    "    # Wyniki\n",
    "    print(f\"Przewidziana emocja: {emotion_names[predicted_class]}\")\n",
    "    print(\"Prawdopodobieństwa:\")\n",
    "    for i, emotion in enumerate(emotion_names):\n",
    "        print(f\"{emotion}: {prediction[0][i]:.4f}\")\n",
    "\n",
    "    return predicted_class, prediction[0]\n",
    "\n",
    "# Faktyczne wykonanie programu - uruchomienie całego procesu\n",
    "if __name__ == \"__main__\":\n",
    "    # Ładowanie datasetu\n",
    "    dataset = load_nemo_dataset()\n",
    "\n",
    "    # Przygotowanie danych\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(dataset)\n",
    "\n",
    "    # Sprawdzenie kształtu danych\n",
    "    print(f\"Kształt danych treningowych: {X_train.shape}\")\n",
    "    print(f\"Kształt danych walidacyjnych: {X_val.shape}\")\n",
    "    print(f\"Kształt danych testowych: {X_test.shape}\")\n",
    "\n",
    "    # Wizualizacja przykładowego spektrogramu Mela\n",
    "    visualize_melspectrogram(X_train[:1], \"Przykładowy spektrogram Mela\")\n",
    "\n",
    "    # Budowa modelu\n",
    "    input_shape = (N_MELS, X_train.shape[2], 3)  # 3 kanały dla VGG16\n",
    "    model = build_vgg16_model(input_shape, NUM_CLASSES)\n",
    "    model.summary()\n",
    "\n",
    "    # Trenowanie modelu\n",
    "    model, history = train_model(model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Ewaluacja modelu\n",
    "    test_acc, test_loss, confusion_matrix = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "    # Wizualizacja wyników\n",
    "    plot_training_history(history)\n",
    "\n",
    "    # Zapisanie modelu\n",
    "    save_model(model, history)\n",
    "\n",
    "    print(\"Proces zakończony!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
