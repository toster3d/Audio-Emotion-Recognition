{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook zawiera kod z atakiem adwersalnym na sieć ResNET-18 wytrenowaną na datasecie nEMO. \n",
    "### Atak adwersalny (ang. adversarial attack) na sieć neuronową to technika, która polega na celowym modyfikowaniu danych wejściowych w taki sposób, aby wprowadzić w błąd model uczenia maszynowego. Przekształcenia danych wejściowych są często niemal niewidoczne dla człowieka.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "# from datasets import load_from_disk\n",
    "# from create_data import download_and_save_dataset\n",
    "from heplers.early_stopping import EarlyStopping\n",
    "from heplers.augmentation import AugmentedAudioDataset\n",
    "from heplers.resnet_model_definition import AudioResNet\n",
    "from config import (BATCH_SIZE, NUM_EPOCHS, LEARNING_RATE, WEIGHT_DECAY,\n",
    "                    DROPOUT_RATE, EARLY_STOPPING_PATIENCE, MODEL_DIR,\n",
    "                    TIMESTAMP, MODEL_PATH, MAX_LENGTH, SEED, DATASET_PATH)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ładowanie datasetu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"amu-cai/nEMO\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Przetwarzanie próbek audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przetwarzanie próbek audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Przetwarzanie próbek audio: 100%|██████████████████████████████████████████████████| 4481/4481 [01:43<00:00, 43.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ustawienie seed dla powtarzalności wyników\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Przetwarzanie danych audio\n",
    "print(\"Przetwarzanie próbek audio...\")\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for sample in tqdm(dataset, desc=\"Przetwarzanie próbek audio\"):\n",
    "    audio_array = sample['audio']['array']\n",
    "    sr = sample['audio']['sampling_rate']\n",
    "    \n",
    "    # Ujednolicenie długości\n",
    "    target_length = int(MAX_LENGTH * sr)\n",
    "    if len(audio_array) > target_length:\n",
    "        audio_array = audio_array[:target_length]\n",
    "    else:\n",
    "        padding = np.zeros(target_length - len(audio_array))\n",
    "        audio_array = np.concatenate([audio_array, padding])\n",
    "    \n",
    "    # Ekstrakcja melspektrogramu\n",
    "    S = librosa.feature.melspectrogram(y=audio_array, sr=sr, n_mels=128)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "    features.append(S_db)\n",
    "    \n",
    "    # Dodanie etykiety\n",
    "    labels.append(sample['emotion'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Konwersja i normalizacja danych audio oraz etykiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba klas emocji: 6\n",
      "Mapowanie klas: {np.str_('anger'): np.int64(0), np.str_('fear'): np.int64(1), np.str_('happiness'): np.int64(2), np.str_('neutral'): np.int64(3), np.str_('sadness'): np.int64(4), np.str_('surprised'): np.int64(5)}\n"
     ]
    }
   ],
   "source": [
    "# Konwersja list na tablice numpy\n",
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], 1, features.shape[1], features.shape[2])\n",
    "\n",
    "# Normalizacja danych (standardyzacja)\n",
    "mean = np.mean(features)\n",
    "std = np.std(features)\n",
    "features = (features - mean) / std\n",
    "\n",
    "# Konwersja etykiet na liczby\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "num_classes = len(np.unique(labels))\n",
    "print(f\"Liczba klas emocji: {num_classes}\")\n",
    "print(f\"Mapowanie klas: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Podział danych na zbiory treningowe, walidacyjne i testowe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział na zbiory\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=SEED, stratify=labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=SEED, stratify=y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Inicjalizacja modelu i optymalizatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Używane urządzenie: cpu\n"
     ]
    }
   ],
   "source": [
    "# Inicjalizacja modelu, funkcji straty i optymalizatora\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Używane urządzenie: {device}\")\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = AudioResNet(num_classes=num_classes, dropout_rate=0.5)\n",
    "model = model.to(device)\n",
    "\n",
    "# Inicjalizacja funkcji straty i optymalizatora\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Dodanie regularyzacji L2\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Przygotowanie zestawów danych z augmentacją i ładowanie ich do DataLoaderów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotowanie zestawów danych z augmentacją\n",
    "train_dataset = AugmentedAudioDataset(X_train, y_train, augment=True)\n",
    "val_dataset = AugmentedAudioDataset(X_val, y_val, augment=False)\n",
    "test_dataset = AugmentedAudioDataset(X_test, y_test, augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Ścieżka do zapisywania modelu\n",
    "early_stopping = EarlyStopping(patience=EARLY_STOPPING_PATIENCE, path=MODEL_PATH)\n",
    "\n",
    "# Śledzenie historii treningu\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_accuracy': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Pętla treningowa i walidacja modelu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynanie treningu...\n",
      "Epoka 1/50, Strata treningu: 1.9047, Strata walidacji: 3.0729, Dokładność walidacji: 34.31%\n",
      "Validation loss decreased. Saving model to model_outputs\\best_model_20250420_115338.pt\n",
      "Epoka 2/50, Strata treningu: 1.3405, Strata walidacji: 1.0345, Dokładność walidacji: 61.79%\n",
      "Validation loss decreased. Saving model to model_outputs\\best_model_20250420_115338.pt\n",
      "Epoka 3/50, Strata treningu: 1.0259, Strata walidacji: 1.1134, Dokładność walidacji: 62.06%\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoka 4/50, Strata treningu: 0.8949, Strata walidacji: 2.0418, Dokładność walidacji: 44.63%\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoka 5/50, Strata treningu: 0.7370, Strata walidacji: 0.8845, Dokładność walidacji: 68.76%\n",
      "Validation loss decreased. Saving model to model_outputs\\best_model_20250420_115338.pt\n",
      "Epoka 6/50, Strata treningu: 0.5810, Strata walidacji: 0.9535, Dokładność walidacji: 69.60%\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoka 7/50, Strata treningu: 0.5733, Strata walidacji: 0.5610, Dokładność walidacji: 77.55%\n",
      "Validation loss decreased. Saving model to model_outputs\\best_model_20250420_115338.pt\n",
      "Epoka 8/50, Strata treningu: 0.4707, Strata walidacji: 0.5879, Dokładność walidacji: 78.24%\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoka 9/50, Strata treningu: 0.3763, Strata walidacji: 0.6823, Dokładność walidacji: 76.43%\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoka 10/50, Strata treningu: 0.3678, Strata walidacji: 1.0633, Dokładność walidacji: 71.97%\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoka 11/50, Strata treningu: 0.3438, Strata walidacji: 0.6108, Dokładność walidacji: 80.75%\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoka 12/50, Strata treningu: 0.1552, Strata walidacji: 0.3967, Dokładność walidacji: 86.33%\n",
      "Validation loss decreased. Saving model to model_outputs\\best_model_20250420_115338.pt\n",
      "Epoka 13/50, Strata treningu: 0.1109, Strata walidacji: 0.4337, Dokładność walidacji: 87.03%\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoka 14/50, Strata treningu: 0.1133, Strata walidacji: 0.3730, Dokładność walidacji: 87.59%\n",
      "Validation loss decreased. Saving model to model_outputs\\best_model_20250420_115338.pt\n",
      "Epoka 15/50, Strata treningu: 0.0949, Strata walidacji: 0.4041, Dokładność walidacji: 86.33%\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoka 16/50, Strata treningu: 0.0841, Strata walidacji: 0.4540, Dokładność walidacji: 86.61%\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoka 17/50, Strata treningu: 0.1075, Strata walidacji: 0.5492, Dokładność walidacji: 84.52%\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoka 18/50, Strata treningu: 0.0664, Strata walidacji: 0.3771, Dokładność walidacji: 89.40%\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoka 19/50, Strata treningu: 0.0330, Strata walidacji: 0.3043, Dokładność walidacji: 90.24%\n",
      "Validation loss decreased. Saving model to model_outputs\\best_model_20250420_115338.pt\n",
      "Epoka 20/50, Strata treningu: 0.0295, Strata walidacji: 0.2673, Dokładność walidacji: 91.49%\n",
      "Validation loss decreased. Saving model to model_outputs\\best_model_20250420_115338.pt\n",
      "Epoka 21/50, Strata treningu: 0.0365, Strata walidacji: 0.2955, Dokładność walidacji: 90.24%\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoka 22/50, Strata treningu: 0.0253, Strata walidacji: 0.2883, Dokładność walidacji: 91.77%\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoka 23/50, Strata treningu: 0.0239, Strata walidacji: 0.3080, Dokładność walidacji: 90.93%\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoka 24/50, Strata treningu: 0.0275, Strata walidacji: 0.2809, Dokładność walidacji: 91.91%\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoka 25/50, Strata treningu: 0.0179, Strata walidacji: 0.2668, Dokładność walidacji: 92.19%\n",
      "Validation loss decreased. Saving model to model_outputs\\best_model_20250420_115338.pt\n",
      "Epoka 26/50, Strata treningu: 0.0145, Strata walidacji: 0.2549, Dokładność walidacji: 91.35%\n",
      "Validation loss decreased. Saving model to model_outputs\\best_model_20250420_115338.pt\n",
      "Epoka 27/50, Strata treningu: 0.0128, Strata walidacji: 0.2535, Dokładność walidacji: 92.89%\n",
      "Validation loss decreased. Saving model to model_outputs\\best_model_20250420_115338.pt\n",
      "Epoka 28/50, Strata treningu: 0.0210, Strata walidacji: 0.2684, Dokładność walidacji: 91.35%\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoka 29/50, Strata treningu: 0.0165, Strata walidacji: 0.2536, Dokładność walidacji: 91.91%\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoka 30/50, Strata treningu: 0.0123, Strata walidacji: 0.2571, Dokładność walidacji: 92.33%\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoka 31/50, Strata treningu: 0.0161, Strata walidacji: 0.2743, Dokładność walidacji: 91.49%\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoka 32/50, Strata treningu: 0.0134, Strata walidacji: 0.2544, Dokładność walidacji: 91.91%\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoka 33/50, Strata treningu: 0.0122, Strata walidacji: 0.2599, Dokładność walidacji: 92.89%\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoka 34/50, Strata treningu: 0.0074, Strata walidacji: 0.2529, Dokładność walidacji: 92.47%\n",
      "Validation loss decreased. Saving model to model_outputs\\best_model_20250420_115338.pt\n",
      "Epoka 35/50, Strata treningu: 0.0104, Strata walidacji: 0.2549, Dokładność walidacji: 92.75%\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoka 36/50, Strata treningu: 0.0082, Strata walidacji: 0.2498, Dokładność walidacji: 92.33%\n",
      "Validation loss decreased. Saving model to model_outputs\\best_model_20250420_115338.pt\n",
      "Epoka 37/50, Strata treningu: 0.0100, Strata walidacji: 0.2612, Dokładność walidacji: 92.89%\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoka 38/50, Strata treningu: 0.0079, Strata walidacji: 0.2585, Dokładność walidacji: 91.91%\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoka 39/50, Strata treningu: 0.0080, Strata walidacji: 0.2803, Dokładność walidacji: 91.35%\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoka 40/50, Strata treningu: 0.0099, Strata walidacji: 0.2580, Dokładność walidacji: 92.47%\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoka 41/50, Strata treningu: 0.0115, Strata walidacji: 0.2795, Dokładność walidacji: 92.61%\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoka 42/50, Strata treningu: 0.0062, Strata walidacji: 0.2693, Dokładność walidacji: 92.33%\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoka 43/50, Strata treningu: 0.0066, Strata walidacji: 0.2614, Dokładność walidacji: 93.03%\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early stopping aktywowane!\n"
     ]
    }
   ],
   "source": [
    "#Pętla treningowa\n",
    "print(\"Rozpoczynanie treningu...\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Faza treningu\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    \n",
    "    # Faza walidacji\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Obliczanie straty walidacyjnej\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Obliczanie dokładności\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    \n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_accuracy'].append(val_accuracy)\n",
    "    \n",
    "    print(f'Epoka {epoch + 1}/{NUM_EPOCHS}, Strata treningu: {train_loss:.4f}, '\n",
    "          f'Strata walidacji: {val_loss:.4f}, Dokładność walidacji: {val_accuracy:.2f}%')\n",
    "    \n",
    "    # Aktualizacja schedulera\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Sprawdzenie warunku early stopping\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping aktywowane!\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Ewaluacja na zbiorze testowym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność testu: 93.09%, Strata testu: 0.2603\n"
     ]
    }
   ],
   "source": [
    "# Wczytanie najlepszego modelu\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "# Testowanie modelu\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Obliczanie straty testowej\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Obliczanie dokładności\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Zapisanie predykcji i rzeczywistych etykiet\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = 100 * test_correct / test_total\n",
    "print(f'Dokładność testu: {test_accuracy:.2f}%, Strata testu: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raport klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score     support\n",
      "anger          0.959184  0.940000  0.949495  150.000000\n",
      "fear           0.953333  0.972789  0.962963  147.000000\n",
      "happiness      0.873333  0.873333  0.873333  150.000000\n",
      "neutral        0.945455  0.962963  0.954128  162.000000\n",
      "sadness        0.980392  0.974026  0.977199  154.000000\n",
      "surprised      0.863636  0.850746  0.857143  134.000000\n",
      "accuracy       0.930881  0.930881  0.930881    0.930881\n",
      "macro avg      0.929222  0.928976  0.929044  897.000000\n",
      "weighted avg   0.930757  0.930881  0.930763  897.000000\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "print(report_df)\n",
    "report_df.to_csv(os.path.join(MODEL_DIR, f'classification_report_{TIMESTAMP}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATAK ADWERSALNY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wykorzystaną metodą ataku adwersalnego jest Fast Gradient Sign Method (FGSM).\n",
    "Jest to jedna z najprostszych i najszybszych metod. FGSM modyfikuje wejście tak, aby maksymalizować stratę, czyli wprowadza model w błąd.  \n",
    "Etapy ataku:\n",
    "1. Obliczamy gradient funkcji straty względem danych wejściowych.\n",
    "2. Tworzymy perturbację (zakłócenie) poprzez pomnożenie znaku gradientu przez niski parametr ε.\n",
    "3. Dodajemy perturbację do oryginalnego obrazu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie funkcji do zastosowania ataku adwersalnego na utworzony model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, data, target, epsilon, device, criterion):\n",
    "    \"\"\"\n",
    "    Implementacja ataku Fast Gradient Sign Method (FGSM)\n",
    "    \n",
    "    Parametry:\n",
    "    - model: model docelowy do ataku\n",
    "    - data: tensor wejściowy (melspektrogramy audio)\n",
    "    - target: prawdziwa etykieta\n",
    "    - epsilon: współczynnik siły ataku\n",
    "    - device: urządzenie (CPU/GPU)\n",
    "    - criterion: funkcja straty\n",
    "    \n",
    "    Zwraca:\n",
    "    - zaburzony przykład (przykład adwersalny)\n",
    "    \"\"\"\n",
    "    # Ustawienie danych jako wymagających gradientu\n",
    "    data.requires_grad = True\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(data)\n",
    "    \n",
    "    # Obliczenie straty\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    # Zerowanie wszystkich poprzednich gradientów\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # Obliczenie gradientów straty względem danych wejściowych\n",
    "    loss.backward()\n",
    "    \n",
    "    # Pobranie znaku gradientu dla uzyskania kierunku\n",
    "    data_grad = data.grad.data.sign()\n",
    "    \n",
    "    # Tworzenie przykładu adwersalnego\n",
    "    perturbed_data = data + epsilon * data_grad\n",
    "    \n",
    "    # Dodanie clippingu, aby dane pozostały w prawidłowym zakresie (zazwyczaj [0,1] lub [-1,1])\n",
    "    # W zależności od zakresu danych możesz dostosować te wartości\n",
    "    perturbed_data = torch.clamp(perturbed_data, -3, 3)  # Zakładam znormalizowane dane ~ N(0,1)\n",
    "    \n",
    "    return perturbed_data\n",
    "\n",
    "def test_fgsm(model, test_loader, epsilons, device, criterion, label_encoder, model_dir):\n",
    "    \"\"\"\n",
    "    Testuje skuteczność ataku FGSM dla różnych wartości epsilon\n",
    "    \n",
    "    Parametry:\n",
    "    - model: model docelowy do ataku\n",
    "    - test_loader: DataLoader zawierający zbiór testowy\n",
    "    - epsilons: lista wartości epsilon do przetestowania\n",
    "    - device: urządzenie (CPU/GPU)\n",
    "    - criterion: funkcja straty\n",
    "    - label_encoder: enkoder etykiet\n",
    "    - model_dir: katalog do zapisywania wyników\n",
    "    \"\"\"\n",
    "    # Przełączenie modelu w tryb ewaluacji\n",
    "    model.eval()\n",
    "    \n",
    "    # Przygotowanie list do przechowywania wyników\n",
    "    accuracies = []\n",
    "    examples = []\n",
    "    \n",
    "    # Testowanie dla każdej wartości epsilon\n",
    "    for eps in epsilons:\n",
    "        print(f\"\\nTestowanie dla epsilon = {eps}\")\n",
    "        correct = 0\n",
    "        adv_examples = []\n",
    "        batch_count = 0\n",
    "        \n",
    "        for data, target in tqdm(test_loader, desc=f\"Atak FGSM (eps={eps})\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Przeprowadzenie ataku FGSM\n",
    "            perturbed_data = fgsm_attack(model, data.clone(), target, eps, device, criterion)\n",
    "            \n",
    "            # Predykcja na przykładach adwersalnych\n",
    "            with torch.no_grad():\n",
    "                output = model(perturbed_data)\n",
    "            \n",
    "            # Wyznaczenie predykcji\n",
    "            _, final_pred = torch.max(output.data, 1)\n",
    "            \n",
    "            # Zliczenie poprawnych klasyfikacji (tzn. takich, które nie zostały zmylone przez atak)\n",
    "            correct += (final_pred == target).sum().item()\n",
    "            \n",
    "            # Zapisanie kilku przykładów do wizualizacji\n",
    "            if batch_count < 5:\n",
    "                for i in range(min(len(data), 3)):  # Zapisz max 3 przykłady z każdej partii\n",
    "                    if len(adv_examples) < 10 and eps > 0:  # Ogranicz do 10 przykładów\n",
    "                        orig = data[i].detach().cpu().numpy()\n",
    "                        pert = perturbed_data[i].detach().cpu().numpy()\n",
    "                        adv_pred = final_pred[i].item()\n",
    "                        orig_pred = target[i].item()\n",
    "                        adv_examples.append((orig, pert, orig_pred, adv_pred))\n",
    "            batch_count += 1\n",
    "        \n",
    "        # Obliczenie dokładności\n",
    "        final_acc = correct / len(test_loader.dataset)\n",
    "        print(f\"Dokładność po ataku: {final_acc * 100:.2f}%\")\n",
    "        \n",
    "        # Zapisanie wyników\n",
    "        accuracies.append(final_acc)\n",
    "        examples.append(adv_examples)\n",
    "    \n",
    "    # Wizualizacja wyników\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epsilons, accuracies, \"*-\")\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.xticks(epsilons)\n",
    "    plt.xlabel(\"Epsilon\")\n",
    "    plt.ylabel(\"Dokładność\")\n",
    "    plt.title(\"Dokładność modelu pod wpływem ataku FGSM\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(model_dir, \"fgsm_accuracy_plot.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Wizualizacja przykładów adwersalnych (dla melspektrogramów)\n",
    "    visualize_adversarial_examples(examples, epsilons, label_encoder, model_dir)\n",
    "    \n",
    "    return accuracies, examples\n",
    "\n",
    "def visualize_adversarial_examples(examples, epsilons, label_encoder, model_dir):\n",
    "    \"\"\"\n",
    "    Wizualizuje przykłady adwersalne dla melspektrogramów\n",
    "    \n",
    "    Parametry:\n",
    "    - examples: lista przykładów adwersalnych\n",
    "    - epsilons: lista wartości epsilon\n",
    "    - label_encoder: enkoder etykiet\n",
    "    - model_dir: katalog do zapisywania wyników\n",
    "    \"\"\"\n",
    "    class_names = label_encoder.classes_\n",
    "    \n",
    "    # Dla każdej wartości epsilon (oprócz 0)\n",
    "    cnt = 0\n",
    "    for i, eps in enumerate(epsilons):\n",
    "        if eps == 0 or not examples[i]:\n",
    "            continue\n",
    "            \n",
    "        # Wybierz maksymalnie 5 przykładów\n",
    "        for j in range(min(len(examples[i]), 5)):\n",
    "            cnt += 1\n",
    "            orig, adv, orig_label, adv_label = examples[i][j]\n",
    "            \n",
    "            # Zamiana z formatu tensora (1, height, width) na format obrazu (height, width)\n",
    "            orig = orig.squeeze(0)\n",
    "            adv = adv.squeeze(0)\n",
    "            \n",
    "            # Obliczenie perturbacji (różnicy)\n",
    "            diff = adv - orig\n",
    "            \n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            \n",
    "            # Oryginalny melspektrogram\n",
    "            im0 = axes[0].imshow(orig, aspect='auto', origin='lower', cmap='viridis')\n",
    "            axes[0].set_title(f\"Oryginalny\\nKlasa: {class_names[orig_label]}\")\n",
    "            axes[0].set_ylabel(\"Mel Bins\")\n",
    "            axes[0].set_xlabel(\"Frames\")\n",
    "            \n",
    "            # Perturbacja (różnica)\n",
    "            im1 = axes[1].imshow(diff, aspect='auto', origin='lower', cmap='coolwarm')\n",
    "            axes[1].set_title(f\"Perturbacja\\nEpsilon: {eps}\")\n",
    "            axes[1].set_xlabel(\"Frames\")\n",
    "            \n",
    "            # Przykład adwersalny\n",
    "            im2 = axes[2].imshow(adv, aspect='auto', origin='lower', cmap='viridis')\n",
    "            axes[2].set_title(f\"Adwersalny\\nKlasa: {class_names[adv_label]}\")\n",
    "            axes[2].set_xlabel(\"Frames\")\n",
    "            \n",
    "            # Dodaj paski kolorów\n",
    "            plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "            plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "            plt.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(model_dir, f\"adversarial_example_{eps}_{j}.png\"))\n",
    "            plt.close()\n",
    "            \n",
    "            if cnt >= 15:  # Ograniczenie do 15 przykładów\n",
    "                return\n",
    "\n",
    "# Funkcja do przeprowadzenia całego eksperymentu\n",
    "def run_fgsm_experiment(model, test_loader, device, criterion, label_encoder, model_dir):\n",
    "    \"\"\"\n",
    "    Przeprowadza pełny eksperyment z atakiem FGSM\n",
    "    \n",
    "    Parametry:\n",
    "    - model: model docelowy do ataku\n",
    "    - test_loader: DataLoader zawierający zbiór testowy\n",
    "    - device: urządzenie (CPU/GPU)\n",
    "    - criterion: funkcja straty\n",
    "    - label_encoder: enkoder etykiet\n",
    "    - model_dir: katalog do zapisywania wyników\n",
    "    \"\"\"\n",
    "    print(\"Rozpoczynam eksperyment z atakiem FGSM...\")\n",
    "    \n",
    "    # Testowanie modelu na oryginalnych (niezakłóconych) danych\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc=\"Ewaluacja na oryginalnych danych\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            correct += (pred == target).sum().item()\n",
    "    \n",
    "    baseline_acc = correct / len(test_loader.dataset)\n",
    "    print(f\"Bazowa dokładność (bez ataku): {baseline_acc * 100:.2f}%\")\n",
    "    \n",
    "    # Wartości epsilon do przetestowania\n",
    "    epsilons = [0, 0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2]\n",
    "    \n",
    "    # Przeprowadzenie ataku FGSM dla różnych wartości epsilon\n",
    "    accuracies, examples = test_fgsm(model, test_loader, epsilons, device, criterion, label_encoder, model_dir)\n",
    "    \n",
    "    # Zapisanie wyników do pliku CSV\n",
    "    import pandas as pd\n",
    "    results = pd.DataFrame({\n",
    "        'epsilon': epsilons,\n",
    "        'accuracy': accuracies\n",
    "    })\n",
    "    results.to_csv(os.path.join(model_dir, \"fgsm_results.csv\"), index=False)\n",
    "    \n",
    "    print(\"\\nEksperyment z atakiem FGSM zakończony.\")\n",
    "    print(f\"Wyniki zostały zapisane w katalogu: {model_dir}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zapisanie wyników i wizualizacja ataku adwersalnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam testowanie odporności modelu na atak FGSM...\n",
      "Rozpoczynam eksperyment z atakiem FGSM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ewaluacja na oryginalnych danych: 100%|████████████████████████████████████████████████| 29/29 [00:45<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bazowa dokładność (bez ataku): 93.09%\n",
      "\n",
      "Testowanie dla epsilon = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atak FGSM (eps=0): 100%|███████████████████████████████████████████████████████████████| 29/29 [03:05<00:00,  6.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność po ataku: 93.09%\n",
      "\n",
      "Testowanie dla epsilon = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atak FGSM (eps=0.001): 100%|███████████████████████████████████████████████████████████| 29/29 [02:24<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność po ataku: 91.42%\n",
      "\n",
      "Testowanie dla epsilon = 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atak FGSM (eps=0.005): 100%|███████████████████████████████████████████████████████████| 29/29 [03:12<00:00,  6.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność po ataku: 81.94%\n",
      "\n",
      "Testowanie dla epsilon = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atak FGSM (eps=0.01): 100%|████████████████████████████████████████████████████████████| 29/29 [02:18<00:00,  4.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność po ataku: 66.56%\n",
      "\n",
      "Testowanie dla epsilon = 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atak FGSM (eps=0.02): 100%|████████████████████████████████████████████████████████████| 29/29 [02:07<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność po ataku: 35.23%\n",
      "\n",
      "Testowanie dla epsilon = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atak FGSM (eps=0.05): 100%|████████████████████████████████████████████████████████████| 29/29 [02:12<00:00,  4.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność po ataku: 3.23%\n",
      "\n",
      "Testowanie dla epsilon = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atak FGSM (eps=0.1): 100%|█████████████████████████████████████████████████████████████| 29/29 [02:07<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność po ataku: 0.45%\n",
      "\n",
      "Testowanie dla epsilon = 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atak FGSM (eps=0.2): 100%|█████████████████████████████████████████████████████████████| 29/29 [02:06<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność po ataku: 0.00%\n",
      "\n",
      "Eksperyment z atakiem FGSM zakończony.\n",
      "Wyniki zostały zapisane w katalogu: model_outputs\\fgsm_results_20250420_115338\n",
      "\n",
      "Wyniki ataku FGSM:\n",
      "   epsilon  accuracy\n",
      "0    0.000  0.930881\n",
      "1    0.001  0.914158\n",
      "2    0.005  0.819398\n",
      "3    0.010  0.665552\n",
      "4    0.020  0.352285\n",
      "5    0.050  0.032330\n",
      "6    0.100  0.004459\n",
      "7    0.200  0.000000\n",
      "\n",
      "Analizuję podatność poszczególnych klas na atak FGSM dla różnych wartości epsilon...\n",
      "\n",
      "Analiza dla epsilon = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atak FGSM (eps=0.001): 100%|███████████████████████████████████████████████████████████| 29/29 [02:10<00:00,  4.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raport klasyfikacji po ataku FGSM (epsilon=0.001):\n",
      "              precision    recall  f1-score     support\n",
      "anger          0.945578  0.926667  0.936027  150.000000\n",
      "fear           0.934641  0.972789  0.953333  147.000000\n",
      "happiness      0.851351  0.840000  0.845638  150.000000\n",
      "neutral        0.928571  0.962963  0.945455  162.000000\n",
      "sadness        0.980132  0.961039  0.970492  154.000000\n",
      "surprised      0.830769  0.805970  0.818182  134.000000\n",
      "accuracy       0.914158  0.914158  0.914158    0.914158\n",
      "macro avg      0.911841  0.911571  0.911521  897.000000\n",
      "weighted avg   0.913739  0.914158  0.913763  897.000000\n",
      "\n",
      "Analiza dla epsilon = 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atak FGSM (eps=0.005): 100%|███████████████████████████████████████████████████████████| 29/29 [02:06<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raport klasyfikacji po ataku FGSM (epsilon=0.005):\n",
      "              precision    recall  f1-score     support\n",
      "anger          0.895522  0.800000  0.845070  150.000000\n",
      "fear           0.883117  0.925170  0.903654  147.000000\n",
      "happiness      0.700000  0.746667  0.722581  150.000000\n",
      "neutral        0.842105  0.888889  0.864865  162.000000\n",
      "sadness        0.933775  0.915584  0.924590  154.000000\n",
      "surprised      0.645669  0.611940  0.628352  134.000000\n",
      "accuracy       0.819398  0.819398  0.819398    0.819398\n",
      "macro avg      0.816698  0.814708  0.814852  897.000000\n",
      "weighted avg   0.820389  0.819398  0.819040  897.000000\n",
      "\n",
      "Analiza dla epsilon = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atak FGSM (eps=0.01): 100%|████████████████████████████████████████████████████████████| 29/29 [02:06<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raport klasyfikacji po ataku FGSM (epsilon=0.01):\n",
      "              precision    recall  f1-score     support\n",
      "anger          0.813008  0.666667  0.732601  150.000000\n",
      "fear           0.783439  0.836735  0.809211  147.000000\n",
      "happiness      0.522727  0.613333  0.564417  150.000000\n",
      "neutral        0.685185  0.685185  0.685185  162.000000\n",
      "sadness        0.813333  0.792208  0.802632  154.000000\n",
      "surprised      0.379845  0.365672  0.372624  134.000000\n",
      "accuracy       0.665552  0.665552  0.665552    0.665552\n",
      "macro avg      0.666256  0.659967  0.661111  897.000000\n",
      "weighted avg   0.671882  0.665552  0.666715  897.000000\n",
      "\n",
      "Porównanie dokładności klas przed i po ataku FGSM dla różnych wartości epsilon:\n",
      "           Dokładność bazowa  Dokładność (ε=0.001)  Spadek (ε=0.001)  \\\n",
      "surprised           0.850746              0.805970          0.044776   \n",
      "anger               0.940000              0.926667          0.013333   \n",
      "happiness           0.873333              0.840000          0.033333   \n",
      "neutral             0.962963              0.962963          0.000000   \n",
      "sadness             0.974026              0.961039          0.012987   \n",
      "fear                0.972789              0.972789          0.000000   \n",
      "\n",
      "           Dokładność (ε=0.005)  Spadek (ε=0.005)  Dokładność (ε=0.01)  \\\n",
      "surprised              0.611940          0.238806             0.365672   \n",
      "anger                  0.800000          0.140000             0.666667   \n",
      "happiness              0.746667          0.126667             0.613333   \n",
      "neutral                0.888889          0.074074             0.685185   \n",
      "sadness                0.915584          0.058442             0.792208   \n",
      "fear                   0.925170          0.047619             0.836735   \n",
      "\n",
      "           Spadek (ε=0.01)  Średni spadek  \n",
      "surprised         0.485075       0.256219  \n",
      "anger             0.273333       0.142222  \n",
      "happiness         0.260000       0.140000  \n",
      "neutral           0.277778       0.117284  \n",
      "sadness           0.181818       0.084416  \n",
      "fear              0.136054       0.061224  \n",
      "\n",
      "Analiza zakończona. Wszystkie wyniki zostały zapisane w katalogu: model_outputs\\fgsm_results_20250420_115338\n"
     ]
    }
   ],
   "source": [
    "# Utworzenie katalogu dla wyników ataku FGSM\n",
    "FGSM_DIR = os.path.join(MODEL_DIR, f'fgsm_results_{TIMESTAMP}')\n",
    "os.makedirs(FGSM_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Rozpoczynam testowanie odporności modelu na atak FGSM...\")\n",
    "\n",
    "# Uruchomienie eksperymentu z atakiem FGSM\n",
    "results = run_fgsm_experiment(model, test_loader, device, criterion, label_encoder, FGSM_DIR)\n",
    "\n",
    "# Wyświetlenie tabeli wyników\n",
    "print(\"\\nWyniki ataku FGSM:\")\n",
    "print(results)\n",
    "\n",
    "# Analiza najbardziej podatnych klas na atak dla wielu wartości epsilon\n",
    "print(\"\\nAnalizuję podatność poszczególnych klas na atak FGSM dla różnych wartości epsilon...\")\n",
    "\n",
    "# Lista wartości epsilon do analizy podatności klas\n",
    "target_epsilons = [0.001, 0.005, 0.01]  \n",
    "\n",
    "# Słownik do przechowywania wyników dla każdej wartości epsilon\n",
    "class_accuracy_results = {}\n",
    "\n",
    "# Dla każdej wartości epsilon wykonaj analizę\n",
    "for target_epsilon in target_epsilons:\n",
    "    print(f\"\\nAnaliza dla epsilon = {target_epsilon}\")\n",
    "    \n",
    "    # Przechowywanie macierzy konfuzji dla ataku\n",
    "    all_preds_adv = []\n",
    "    all_labels_adv = []\n",
    "    \n",
    "    # Uruchomienie ataku z wybraną wartością epsilon\n",
    "    model.eval()\n",
    "    for data, target in tqdm(test_loader, desc=f\"Atak FGSM (eps={target_epsilon})\"):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Przeprowadzenie ataku FGSM\n",
    "        perturbed_data = fgsm_attack(model, data.clone(), target, target_epsilon, device, criterion)\n",
    "        \n",
    "        # Predykcja na przykładach adwersalnych\n",
    "        with torch.no_grad():\n",
    "            output = model(perturbed_data)\n",
    "        \n",
    "        # Wyznaczenie predykcji\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        \n",
    "        # Zapisanie predykcji i rzeczywistych etykiet\n",
    "        all_preds_adv.extend(predicted.cpu().numpy())\n",
    "        all_labels_adv.extend(target.cpu().numpy())\n",
    "    \n",
    "    # Macierz konfuzji dla ataku\n",
    "    cm_adv = confusion_matrix(all_labels_adv, all_preds_adv)\n",
    "    class_names = label_encoder.classes_\n",
    "    \n",
    "    # Wizualizacja macierzy konfuzji dla ataku\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm_normalized_adv = cm_adv.astype('float') / cm_adv.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cm_normalized_adv, annot=True, fmt='.2f', cmap='Reds', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Znormalizowana macierz konfuzji po ataku FGSM (ε={target_epsilon})')\n",
    "    plt.ylabel('Rzeczywista etykieta')\n",
    "    plt.xlabel('Przewidziana etykieta')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FGSM_DIR, f'confusion_matrix_fgsm_{target_epsilon}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Raport klasyfikacji dla ataku\n",
    "    report_adv = classification_report(all_labels_adv, all_preds_adv, target_names=class_names, output_dict=True)\n",
    "    report_df_adv = pd.DataFrame(report_adv).transpose()\n",
    "    print(f\"\\nRaport klasyfikacji po ataku FGSM (epsilon={target_epsilon}):\")\n",
    "    print(report_df_adv)\n",
    "    report_df_adv.to_csv(os.path.join(FGSM_DIR, f'classification_report_fgsm_{target_epsilon}.csv'))\n",
    "    \n",
    "    # Zapisanie dokładności dla każdej klasy przy danej wartości epsilon\n",
    "    class_accuracies = {name: report_adv[name]['recall'] for name in class_names}\n",
    "    class_accuracy_results[target_epsilon] = class_accuracies\n",
    "\n",
    "# Utworzenie DataFrame z wynikami dla wszystkich wartości epsilon\n",
    "comparison_df = pd.DataFrame(index=class_names)\n",
    "\n",
    "# Bazowa dokładność (bez ataku)\n",
    "baseline_accuracies = {name: report[name]['recall'] for name in class_names}\n",
    "comparison_df['Dokładność bazowa'] = pd.Series(baseline_accuracies)\n",
    "\n",
    "# Dodanie kolumn dla każdej wartości epsilon\n",
    "for eps in target_epsilons:\n",
    "    comparison_df[f'Dokładność (ε={eps})'] = pd.Series(class_accuracy_results[eps])\n",
    "    comparison_df[f'Spadek (ε={eps})'] = comparison_df['Dokładność bazowa'] - comparison_df[f'Dokładność (ε={eps})']\n",
    "\n",
    "# Sortowanie według średniego spadku dokładności\n",
    "comparison_df['Średni spadek'] = comparison_df[[f'Spadek (ε={eps})' for eps in target_epsilons]].mean(axis=1)\n",
    "comparison_df = comparison_df.sort_values('Średni spadek', ascending=False)\n",
    "\n",
    "print(\"\\nPorównanie dokładności klas przed i po ataku FGSM dla różnych wartości epsilon:\")\n",
    "print(comparison_df)\n",
    "comparison_df.to_csv(os.path.join(FGSM_DIR, 'accuracy_comparison_all_epsilons.csv'))\n",
    "\n",
    "# Wizualizacja spadku dokładności dla każdej klasy w funkcji epsilon\n",
    "plt.figure(figsize=(12, 8))\n",
    "for class_name in class_names:\n",
    "    accuracies = [baseline_accuracies[class_name]] + [class_accuracy_results[eps][class_name] for eps in target_epsilons]\n",
    "    plt.plot([0] + target_epsilons, accuracies, marker='o', linewidth=2, label=class_name)\n",
    "\n",
    "plt.xlabel('Epsilon (siła ataku)')\n",
    "plt.ylabel('Dokładność klasyfikacji')\n",
    "plt.title('Spadek dokładności klasyfikacji emocji pod wpływem ataku FGSM')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.savefig(os.path.join(FGSM_DIR, 'accuracy_vs_epsilon_by_class.png'))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nAnaliza zakończona. Wszystkie wyniki zostały zapisane w katalogu: {FGSM_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PODSUMOWANIE\n",
    "#### Przy wartości epsilon = 0.01 dokładność modelu znacznie spada; do 66.56%. Od wartości epsilon = 0.05 dokładność modelu oscyluje w graniach kilku procent. Najbardziej podatną na wprowadzane zakłócenia emocją jest zaskoczenie (największy spadek w klasyfikowaniu tej emocji), a najmniej strach.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (projekt_emocje)",
   "language": "python",
   "name": "emocje_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
